<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>Part2_PercentTraining</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Part-2:-Percentage-of-Training-Dataset">Part 2: Percentage of Training Dataset<a class="anchor-link" href="#Part-2:-Percentage-of-Training-Dataset">&#182;</a></h1><h3 id="Goal:">Goal:<a class="anchor-link" href="#Goal:">&#182;</a></h3><p>Use 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, and 100% of the total training dataset to train the neural work and test on it, respectively. You build 9 systems. Plot a graph where the axis indicate the percentage of the training set you used to train a system, and y-axis indicate the accuracy on the test set of each system</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span> 
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> <span class="c1"># feel free to comment this out </span>

<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 

<span class="kn">import</span> <span class="nn">sklearn</span> 
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">models</span> 
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">optimizers</span> 
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">dataProcessing</span><span class="p">():</span> 
    <span class="n">wine</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_wine</span><span class="p">()</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">feature_names</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">target</span>
    
    <span class="n">labels</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s2">&quot;class&quot;</span><span class="p">]]</span> 
    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;class&quot;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">xtrain</span><span class="p">,</span> <span class="n">xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">ytrain</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">ytrain</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">ytest</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
    
    <span class="n">scale</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">xtrain</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span>
    <span class="n">xtest</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">xtrain</span><span class="p">,</span> <span class="n">xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Discussion:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I used the training set percentage to find the compliment(validation split). In other words, if I want 20% of the training set to be used during training, I'll just utilize validation_split attribute in model.fit() with the compliment, 80%.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">trainModel</span><span class="p">(</span><span class="n">val_split</span><span class="p">,</span> <span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Builds and runs training model </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training the Model&quot;</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">xtrain</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">),</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;acc&quot;</span><span class="p">])</span>
    
    <span class="c1"># Save weights </span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;model_part2.hdf5&quot;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Apply early stopping to prevent overfitting </span>
    <span class="n">monitor</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Run Model </span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">val_split</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint</span><span class="p">,</span><span class="n">monitor</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">testModel</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">):</span> 
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Builds and runs testing model </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing the model&quot;</span><span class="p">)</span>
    
    <span class="n">evalModel</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">evalModel</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">evalModel</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">evalModel</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">evalModel</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">evalModel</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">evalModel</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>


    <span class="n">evalModel</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;model_part2.hdf5&#39;</span><span class="p">)</span>
    <span class="n">evalModel</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">),</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;acc&quot;</span><span class="p">])</span>
    
    <span class="n">lossAndAcc</span> <span class="o">=</span> <span class="n">evalModel</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">lossAndAcc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">):</span> 
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Main driver for program </span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">xtrain</span><span class="p">,</span> <span class="n">xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">dataProcessing</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">)):</span> 
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;====================================================&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Percent Training Size &quot;</span><span class="p">,</span> <span class="n">train_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        
        <span class="n">validation_split</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">train_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Train Model</span>
        <span class="n">trainModel</span><span class="p">(</span><span class="n">validation_split</span><span class="p">,</span> <span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
        
        <span class="c1"># Test Model </span>
        <span class="n">currAcc</span> <span class="o">=</span> <span class="n">testModel</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
        
        <span class="c1"># Add accuracy to our list </span>
        <span class="n">accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">currAcc</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;====================================================</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span> 
        
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.20</span><span class="p">,</span> <span class="mf">0.30</span><span class="p">,</span> <span class="mf">0.40</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">main</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>====================================================
Percent Training Size  0.2
Training the Model
WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.

Epoch 00001: loss improved from inf to 1.09674, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.09674 to 1.09497, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.09497 to 1.09381, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.09381 to 1.09282, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.09282 to 1.09192, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.09192 to 1.09115, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.09115 to 1.09035, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.09035 to 1.08948, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.08948 to 1.08871, saving model to model_part2.hdf5

Epoch 00010: loss improved from 1.08871 to 1.08800, saving model to model_part2.hdf5

Epoch 00011: loss improved from 1.08800 to 1.08730, saving model to model_part2.hdf5

Epoch 00012: loss improved from 1.08730 to 1.08664, saving model to model_part2.hdf5

Epoch 00013: loss improved from 1.08664 to 1.08598, saving model to model_part2.hdf5

Epoch 00014: loss improved from 1.08598 to 1.08531, saving model to model_part2.hdf5

Epoch 00015: loss improved from 1.08531 to 1.08468, saving model to model_part2.hdf5

Epoch 00016: loss improved from 1.08468 to 1.08397, saving model to model_part2.hdf5

Epoch 00017: loss improved from 1.08397 to 1.08332, saving model to model_part2.hdf5

Epoch 00018: loss improved from 1.08332 to 1.08267, saving model to model_part2.hdf5

Epoch 00019: loss improved from 1.08267 to 1.08197, saving model to model_part2.hdf5

Epoch 00020: loss improved from 1.08197 to 1.08131, saving model to model_part2.hdf5

Epoch 00021: loss improved from 1.08131 to 1.08065, saving model to model_part2.hdf5

Epoch 00022: loss improved from 1.08065 to 1.07991, saving model to model_part2.hdf5

Epoch 00023: loss improved from 1.07991 to 1.07920, saving model to model_part2.hdf5

Epoch 00024: loss improved from 1.07920 to 1.07845, saving model to model_part2.hdf5

Epoch 00025: loss improved from 1.07845 to 1.07773, saving model to model_part2.hdf5

Epoch 00026: loss improved from 1.07773 to 1.07698, saving model to model_part2.hdf5

Epoch 00027: loss improved from 1.07698 to 1.07620, saving model to model_part2.hdf5

Epoch 00028: loss improved from 1.07620 to 1.07537, saving model to model_part2.hdf5

Epoch 00029: loss improved from 1.07537 to 1.07446, saving model to model_part2.hdf5

Epoch 00030: loss improved from 1.07446 to 1.07333, saving model to model_part2.hdf5

Epoch 00031: loss improved from 1.07333 to 1.07222, saving model to model_part2.hdf5

Epoch 00032: loss improved from 1.07222 to 1.07119, saving model to model_part2.hdf5

Epoch 00033: loss improved from 1.07119 to 1.07020, saving model to model_part2.hdf5

Epoch 00034: loss improved from 1.07020 to 1.06925, saving model to model_part2.hdf5

Epoch 00035: loss improved from 1.06925 to 1.06836, saving model to model_part2.hdf5

Epoch 00036: loss improved from 1.06836 to 1.06727, saving model to model_part2.hdf5

Epoch 00037: loss improved from 1.06727 to 1.06639, saving model to model_part2.hdf5

Epoch 00038: loss improved from 1.06639 to 1.06540, saving model to model_part2.hdf5

Epoch 00039: loss improved from 1.06540 to 1.06437, saving model to model_part2.hdf5

Epoch 00040: loss improved from 1.06437 to 1.06332, saving model to model_part2.hdf5

Epoch 00041: loss improved from 1.06332 to 1.06195, saving model to model_part2.hdf5

Epoch 00042: loss improved from 1.06195 to 1.06046, saving model to model_part2.hdf5

Epoch 00043: loss improved from 1.06046 to 1.05891, saving model to model_part2.hdf5

Epoch 00044: loss improved from 1.05891 to 1.05745, saving model to model_part2.hdf5

Epoch 00045: loss improved from 1.05745 to 1.05575, saving model to model_part2.hdf5

Epoch 00046: loss improved from 1.05575 to 1.05405, saving model to model_part2.hdf5

Epoch 00047: loss improved from 1.05405 to 1.05223, saving model to model_part2.hdf5

Epoch 00048: loss improved from 1.05223 to 1.05045, saving model to model_part2.hdf5

Epoch 00049: loss improved from 1.05045 to 1.04858, saving model to model_part2.hdf5

Epoch 00050: loss improved from 1.04858 to 1.04687, saving model to model_part2.hdf5

Epoch 00051: loss improved from 1.04687 to 1.04509, saving model to model_part2.hdf5

Epoch 00052: loss improved from 1.04509 to 1.04344, saving model to model_part2.hdf5

Epoch 00053: loss improved from 1.04344 to 1.04188, saving model to model_part2.hdf5

Epoch 00054: loss improved from 1.04188 to 1.04044, saving model to model_part2.hdf5

Epoch 00055: loss improved from 1.04044 to 1.03898, saving model to model_part2.hdf5

Epoch 00056: loss improved from 1.03898 to 1.03745, saving model to model_part2.hdf5

Epoch 00057: loss improved from 1.03745 to 1.03592, saving model to model_part2.hdf5

Epoch 00058: loss improved from 1.03592 to 1.03438, saving model to model_part2.hdf5

Epoch 00059: loss improved from 1.03438 to 1.03287, saving model to model_part2.hdf5

Epoch 00060: loss improved from 1.03287 to 1.03129, saving model to model_part2.hdf5

Epoch 00061: loss improved from 1.03129 to 1.02948, saving model to model_part2.hdf5

Epoch 00062: loss improved from 1.02948 to 1.02783, saving model to model_part2.hdf5

Epoch 00063: loss improved from 1.02783 to 1.02616, saving model to model_part2.hdf5

Epoch 00064: loss improved from 1.02616 to 1.02447, saving model to model_part2.hdf5

Epoch 00065: loss improved from 1.02447 to 1.02276, saving model to model_part2.hdf5

Epoch 00066: loss improved from 1.02276 to 1.02095, saving model to model_part2.hdf5

Epoch 00067: loss improved from 1.02095 to 1.01925, saving model to model_part2.hdf5

Epoch 00068: loss improved from 1.01925 to 1.01735, saving model to model_part2.hdf5

Epoch 00069: loss improved from 1.01735 to 1.01555, saving model to model_part2.hdf5

Epoch 00070: loss improved from 1.01555 to 1.01384, saving model to model_part2.hdf5

Epoch 00071: loss improved from 1.01384 to 1.01190, saving model to model_part2.hdf5

Epoch 00072: loss improved from 1.01190 to 1.01030, saving model to model_part2.hdf5

Epoch 00073: loss improved from 1.01030 to 1.00833, saving model to model_part2.hdf5

Epoch 00074: loss improved from 1.00833 to 1.00647, saving model to model_part2.hdf5

Epoch 00075: loss improved from 1.00647 to 1.00465, saving model to model_part2.hdf5

Epoch 00076: loss improved from 1.00465 to 1.00287, saving model to model_part2.hdf5

Epoch 00077: loss improved from 1.00287 to 1.00101, saving model to model_part2.hdf5

Epoch 00078: loss improved from 1.00101 to 0.99925, saving model to model_part2.hdf5

Epoch 00079: loss improved from 0.99925 to 0.99748, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.99748 to 0.99548, saving model to model_part2.hdf5

Epoch 00081: loss improved from 0.99548 to 0.99363, saving model to model_part2.hdf5

Epoch 00082: loss improved from 0.99363 to 0.99187, saving model to model_part2.hdf5

Epoch 00083: loss improved from 0.99187 to 0.98987, saving model to model_part2.hdf5

Epoch 00084: loss improved from 0.98987 to 0.98799, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.98799 to 0.98607, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.98607 to 0.98444, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.98444 to 0.98219, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.98219 to 0.98018, saving model to model_part2.hdf5

Epoch 00089: loss improved from 0.98018 to 0.97851, saving model to model_part2.hdf5

Epoch 00090: loss improved from 0.97851 to 0.97647, saving model to model_part2.hdf5

Epoch 00091: loss improved from 0.97647 to 0.97405, saving model to model_part2.hdf5

Epoch 00092: loss improved from 0.97405 to 0.97202, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.97202 to 0.97006, saving model to model_part2.hdf5

Epoch 00094: loss improved from 0.97006 to 0.96787, saving model to model_part2.hdf5

Epoch 00095: loss improved from 0.96787 to 0.96606, saving model to model_part2.hdf5

Epoch 00096: loss improved from 0.96606 to 0.96409, saving model to model_part2.hdf5

Epoch 00097: loss improved from 0.96409 to 0.96202, saving model to model_part2.hdf5

Epoch 00098: loss improved from 0.96202 to 0.96016, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.96016 to 0.95832, saving model to model_part2.hdf5

Epoch 00100: loss improved from 0.95832 to 0.95655, saving model to model_part2.hdf5

Epoch 00101: loss improved from 0.95655 to 0.95450, saving model to model_part2.hdf5

Epoch 00102: loss improved from 0.95450 to 0.95282, saving model to model_part2.hdf5

Epoch 00103: loss improved from 0.95282 to 0.95077, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.95077 to 0.94907, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.94907 to 0.94718, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.94718 to 0.94546, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.94546 to 0.94331, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.94331 to 0.94146, saving model to model_part2.hdf5

Epoch 00109: loss improved from 0.94146 to 0.93962, saving model to model_part2.hdf5

Epoch 00110: loss improved from 0.93962 to 0.93795, saving model to model_part2.hdf5

Epoch 00111: loss improved from 0.93795 to 0.93575, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.93575 to 0.93390, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.93390 to 0.93204, saving model to model_part2.hdf5

Epoch 00114: loss improved from 0.93204 to 0.93013, saving model to model_part2.hdf5

Epoch 00115: loss improved from 0.93013 to 0.92810, saving model to model_part2.hdf5

Epoch 00116: loss improved from 0.92810 to 0.92609, saving model to model_part2.hdf5

Epoch 00117: loss improved from 0.92609 to 0.92407, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.92407 to 0.92209, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.92209 to 0.92027, saving model to model_part2.hdf5

Epoch 00120: loss improved from 0.92027 to 0.91864, saving model to model_part2.hdf5

Epoch 00121: loss improved from 0.91864 to 0.91632, saving model to model_part2.hdf5

Epoch 00122: loss improved from 0.91632 to 0.91422, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.91422 to 0.91227, saving model to model_part2.hdf5

Epoch 00124: loss improved from 0.91227 to 0.91028, saving model to model_part2.hdf5

Epoch 00125: loss improved from 0.91028 to 0.90852, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.90852 to 0.90651, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.90651 to 0.90437, saving model to model_part2.hdf5

Epoch 00128: loss improved from 0.90437 to 0.90224, saving model to model_part2.hdf5

Epoch 00129: loss improved from 0.90224 to 0.90016, saving model to model_part2.hdf5

Epoch 00130: loss improved from 0.90016 to 0.89840, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.89840 to 0.89628, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.89628 to 0.89420, saving model to model_part2.hdf5

Epoch 00133: loss improved from 0.89420 to 0.89218, saving model to model_part2.hdf5

Epoch 00134: loss improved from 0.89218 to 0.89018, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.89018 to 0.88849, saving model to model_part2.hdf5

Epoch 00136: loss improved from 0.88849 to 0.88614, saving model to model_part2.hdf5

Epoch 00137: loss improved from 0.88614 to 0.88413, saving model to model_part2.hdf5

Epoch 00138: loss improved from 0.88413 to 0.88235, saving model to model_part2.hdf5

Epoch 00139: loss improved from 0.88235 to 0.88014, saving model to model_part2.hdf5

Epoch 00140: loss improved from 0.88014 to 0.87823, saving model to model_part2.hdf5

Epoch 00141: loss improved from 0.87823 to 0.87622, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.87622 to 0.87422, saving model to model_part2.hdf5

Epoch 00143: loss improved from 0.87422 to 0.87218, saving model to model_part2.hdf5

Epoch 00144: loss improved from 0.87218 to 0.87066, saving model to model_part2.hdf5

Epoch 00145: loss improved from 0.87066 to 0.86814, saving model to model_part2.hdf5

Epoch 00146: loss improved from 0.86814 to 0.86621, saving model to model_part2.hdf5

Epoch 00147: loss improved from 0.86621 to 0.86416, saving model to model_part2.hdf5

Epoch 00148: loss improved from 0.86416 to 0.86256, saving model to model_part2.hdf5

Epoch 00149: loss improved from 0.86256 to 0.86029, saving model to model_part2.hdf5

Epoch 00150: loss improved from 0.86029 to 0.85830, saving model to model_part2.hdf5

Epoch 00151: loss improved from 0.85830 to 0.85664, saving model to model_part2.hdf5

Epoch 00152: loss improved from 0.85664 to 0.85415, saving model to model_part2.hdf5

Epoch 00153: loss improved from 0.85415 to 0.85195, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.85195 to 0.84977, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.84977 to 0.84764, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.84764 to 0.84581, saving model to model_part2.hdf5

Epoch 00157: loss improved from 0.84581 to 0.84324, saving model to model_part2.hdf5

Epoch 00158: loss improved from 0.84324 to 0.84096, saving model to model_part2.hdf5

Epoch 00159: loss improved from 0.84096 to 0.83879, saving model to model_part2.hdf5

Epoch 00160: loss improved from 0.83879 to 0.83683, saving model to model_part2.hdf5

Epoch 00161: loss improved from 0.83683 to 0.83442, saving model to model_part2.hdf5

Epoch 00162: loss improved from 0.83442 to 0.83226, saving model to model_part2.hdf5

Epoch 00163: loss improved from 0.83226 to 0.83030, saving model to model_part2.hdf5

Epoch 00164: loss improved from 0.83030 to 0.82789, saving model to model_part2.hdf5

Epoch 00165: loss improved from 0.82789 to 0.82569, saving model to model_part2.hdf5

Epoch 00166: loss improved from 0.82569 to 0.82340, saving model to model_part2.hdf5

Epoch 00167: loss improved from 0.82340 to 0.82173, saving model to model_part2.hdf5

Epoch 00168: loss improved from 0.82173 to 0.81912, saving model to model_part2.hdf5

Epoch 00169: loss improved from 0.81912 to 0.81686, saving model to model_part2.hdf5

Epoch 00170: loss improved from 0.81686 to 0.81467, saving model to model_part2.hdf5

Epoch 00171: loss improved from 0.81467 to 0.81266, saving model to model_part2.hdf5

Epoch 00172: loss improved from 0.81266 to 0.81028, saving model to model_part2.hdf5

Epoch 00173: loss improved from 0.81028 to 0.80809, saving model to model_part2.hdf5

Epoch 00174: loss improved from 0.80809 to 0.80583, saving model to model_part2.hdf5

Epoch 00175: loss improved from 0.80583 to 0.80363, saving model to model_part2.hdf5

Epoch 00176: loss improved from 0.80363 to 0.80140, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.80140 to 0.79914, saving model to model_part2.hdf5

Epoch 00178: loss improved from 0.79914 to 0.79701, saving model to model_part2.hdf5

Epoch 00179: loss improved from 0.79701 to 0.79483, saving model to model_part2.hdf5

Epoch 00180: loss improved from 0.79483 to 0.79238, saving model to model_part2.hdf5

Epoch 00181: loss improved from 0.79238 to 0.79011, saving model to model_part2.hdf5

Epoch 00182: loss improved from 0.79011 to 0.78784, saving model to model_part2.hdf5

Epoch 00183: loss improved from 0.78784 to 0.78553, saving model to model_part2.hdf5

Epoch 00184: loss improved from 0.78553 to 0.78326, saving model to model_part2.hdf5

Epoch 00185: loss improved from 0.78326 to 0.78129, saving model to model_part2.hdf5

Epoch 00186: loss improved from 0.78129 to 0.77927, saving model to model_part2.hdf5

Epoch 00187: loss improved from 0.77927 to 0.77661, saving model to model_part2.hdf5

Epoch 00188: loss improved from 0.77661 to 0.77419, saving model to model_part2.hdf5

Epoch 00189: loss improved from 0.77419 to 0.77161, saving model to model_part2.hdf5

Epoch 00190: loss improved from 0.77161 to 0.76922, saving model to model_part2.hdf5

Epoch 00191: loss improved from 0.76922 to 0.76689, saving model to model_part2.hdf5

Epoch 00192: loss improved from 0.76689 to 0.76430, saving model to model_part2.hdf5

Epoch 00193: loss improved from 0.76430 to 0.76183, saving model to model_part2.hdf5

Epoch 00194: loss improved from 0.76183 to 0.75961, saving model to model_part2.hdf5

Epoch 00195: loss improved from 0.75961 to 0.75714, saving model to model_part2.hdf5

Epoch 00196: loss improved from 0.75714 to 0.75474, saving model to model_part2.hdf5

Epoch 00197: loss improved from 0.75474 to 0.75281, saving model to model_part2.hdf5

Epoch 00198: loss improved from 0.75281 to 0.75007, saving model to model_part2.hdf5

Epoch 00199: loss improved from 0.75007 to 0.74781, saving model to model_part2.hdf5

Epoch 00200: loss improved from 0.74781 to 0.74546, saving model to model_part2.hdf5

Epoch 00201: loss improved from 0.74546 to 0.74303, saving model to model_part2.hdf5

Epoch 00202: loss improved from 0.74303 to 0.74073, saving model to model_part2.hdf5

Epoch 00203: loss improved from 0.74073 to 0.73849, saving model to model_part2.hdf5

Epoch 00204: loss improved from 0.73849 to 0.73617, saving model to model_part2.hdf5

Epoch 00205: loss improved from 0.73617 to 0.73400, saving model to model_part2.hdf5

Epoch 00206: loss improved from 0.73400 to 0.73138, saving model to model_part2.hdf5

Epoch 00207: loss improved from 0.73138 to 0.72901, saving model to model_part2.hdf5

Epoch 00208: loss improved from 0.72901 to 0.72661, saving model to model_part2.hdf5

Epoch 00209: loss improved from 0.72661 to 0.72427, saving model to model_part2.hdf5

Epoch 00210: loss improved from 0.72427 to 0.72209, saving model to model_part2.hdf5

Epoch 00211: loss improved from 0.72209 to 0.71954, saving model to model_part2.hdf5

Epoch 00212: loss improved from 0.71954 to 0.71717, saving model to model_part2.hdf5

Epoch 00213: loss improved from 0.71717 to 0.71510, saving model to model_part2.hdf5

Epoch 00214: loss improved from 0.71510 to 0.71257, saving model to model_part2.hdf5

Epoch 00215: loss improved from 0.71257 to 0.71073, saving model to model_part2.hdf5

Epoch 00216: loss improved from 0.71073 to 0.70803, saving model to model_part2.hdf5

Epoch 00217: loss improved from 0.70803 to 0.70586, saving model to model_part2.hdf5

Epoch 00218: loss improved from 0.70586 to 0.70353, saving model to model_part2.hdf5

Epoch 00219: loss improved from 0.70353 to 0.70147, saving model to model_part2.hdf5

Epoch 00220: loss improved from 0.70147 to 0.69892, saving model to model_part2.hdf5

Epoch 00221: loss improved from 0.69892 to 0.69678, saving model to model_part2.hdf5

Epoch 00222: loss improved from 0.69678 to 0.69438, saving model to model_part2.hdf5

Epoch 00223: loss improved from 0.69438 to 0.69307, saving model to model_part2.hdf5

Epoch 00224: loss improved from 0.69307 to 0.69040, saving model to model_part2.hdf5

Epoch 00225: loss improved from 0.69040 to 0.68788, saving model to model_part2.hdf5

Epoch 00226: loss improved from 0.68788 to 0.68586, saving model to model_part2.hdf5

Epoch 00227: loss improved from 0.68586 to 0.68351, saving model to model_part2.hdf5

Epoch 00228: loss improved from 0.68351 to 0.68153, saving model to model_part2.hdf5

Epoch 00229: loss improved from 0.68153 to 0.67924, saving model to model_part2.hdf5

Epoch 00230: loss improved from 0.67924 to 0.67730, saving model to model_part2.hdf5

Epoch 00231: loss improved from 0.67730 to 0.67510, saving model to model_part2.hdf5

Epoch 00232: loss improved from 0.67510 to 0.67308, saving model to model_part2.hdf5

Epoch 00233: loss improved from 0.67308 to 0.67113, saving model to model_part2.hdf5

Epoch 00234: loss improved from 0.67113 to 0.66920, saving model to model_part2.hdf5

Epoch 00235: loss improved from 0.66920 to 0.66673, saving model to model_part2.hdf5

Epoch 00236: loss improved from 0.66673 to 0.66462, saving model to model_part2.hdf5

Epoch 00237: loss improved from 0.66462 to 0.66263, saving model to model_part2.hdf5

Epoch 00238: loss improved from 0.66263 to 0.66091, saving model to model_part2.hdf5

Epoch 00239: loss improved from 0.66091 to 0.65864, saving model to model_part2.hdf5

Epoch 00240: loss improved from 0.65864 to 0.65673, saving model to model_part2.hdf5

Epoch 00241: loss improved from 0.65673 to 0.65469, saving model to model_part2.hdf5

Epoch 00242: loss improved from 0.65469 to 0.65261, saving model to model_part2.hdf5

Epoch 00243: loss improved from 0.65261 to 0.65039, saving model to model_part2.hdf5

Epoch 00244: loss improved from 0.65039 to 0.64824, saving model to model_part2.hdf5

Epoch 00245: loss improved from 0.64824 to 0.64642, saving model to model_part2.hdf5

Epoch 00246: loss improved from 0.64642 to 0.64445, saving model to model_part2.hdf5

Epoch 00247: loss improved from 0.64445 to 0.64249, saving model to model_part2.hdf5

Epoch 00248: loss improved from 0.64249 to 0.64052, saving model to model_part2.hdf5

Epoch 00249: loss improved from 0.64052 to 0.63895, saving model to model_part2.hdf5

Epoch 00250: loss improved from 0.63895 to 0.63623, saving model to model_part2.hdf5

Epoch 00251: loss improved from 0.63623 to 0.63402, saving model to model_part2.hdf5

Epoch 00252: loss improved from 0.63402 to 0.63226, saving model to model_part2.hdf5

Epoch 00253: loss improved from 0.63226 to 0.63080, saving model to model_part2.hdf5

Epoch 00254: loss improved from 0.63080 to 0.62808, saving model to model_part2.hdf5

Epoch 00255: loss improved from 0.62808 to 0.62609, saving model to model_part2.hdf5

Epoch 00256: loss improved from 0.62609 to 0.62399, saving model to model_part2.hdf5

Epoch 00257: loss improved from 0.62399 to 0.62190, saving model to model_part2.hdf5

Epoch 00258: loss improved from 0.62190 to 0.62011, saving model to model_part2.hdf5

Epoch 00259: loss improved from 0.62011 to 0.61783, saving model to model_part2.hdf5

Epoch 00260: loss improved from 0.61783 to 0.61580, saving model to model_part2.hdf5

Epoch 00261: loss improved from 0.61580 to 0.61435, saving model to model_part2.hdf5

Epoch 00262: loss improved from 0.61435 to 0.61315, saving model to model_part2.hdf5

Epoch 00263: loss improved from 0.61315 to 0.61020, saving model to model_part2.hdf5

Epoch 00264: loss improved from 0.61020 to 0.60832, saving model to model_part2.hdf5

Epoch 00265: loss improved from 0.60832 to 0.60616, saving model to model_part2.hdf5

Epoch 00266: loss improved from 0.60616 to 0.60413, saving model to model_part2.hdf5

Epoch 00267: loss improved from 0.60413 to 0.60268, saving model to model_part2.hdf5

Epoch 00268: loss improved from 0.60268 to 0.60178, saving model to model_part2.hdf5

Epoch 00269: loss improved from 0.60178 to 0.59850, saving model to model_part2.hdf5

Epoch 00270: loss improved from 0.59850 to 0.59688, saving model to model_part2.hdf5

Epoch 00271: loss improved from 0.59688 to 0.59478, saving model to model_part2.hdf5

Epoch 00272: loss improved from 0.59478 to 0.59344, saving model to model_part2.hdf5

Epoch 00273: loss improved from 0.59344 to 0.59114, saving model to model_part2.hdf5

Epoch 00274: loss improved from 0.59114 to 0.58971, saving model to model_part2.hdf5

Epoch 00275: loss improved from 0.58971 to 0.58757, saving model to model_part2.hdf5

Epoch 00276: loss improved from 0.58757 to 0.58556, saving model to model_part2.hdf5

Epoch 00277: loss improved from 0.58556 to 0.58454, saving model to model_part2.hdf5

Epoch 00278: loss improved from 0.58454 to 0.58213, saving model to model_part2.hdf5

Epoch 00279: loss improved from 0.58213 to 0.58099, saving model to model_part2.hdf5

Epoch 00280: loss improved from 0.58099 to 0.57883, saving model to model_part2.hdf5

Epoch 00281: loss improved from 0.57883 to 0.57684, saving model to model_part2.hdf5

Epoch 00282: loss improved from 0.57684 to 0.57486, saving model to model_part2.hdf5

Epoch 00283: loss improved from 0.57486 to 0.57377, saving model to model_part2.hdf5

Epoch 00284: loss improved from 0.57377 to 0.57166, saving model to model_part2.hdf5

Epoch 00285: loss improved from 0.57166 to 0.57090, saving model to model_part2.hdf5

Epoch 00286: loss improved from 0.57090 to 0.56822, saving model to model_part2.hdf5

Epoch 00287: loss improved from 0.56822 to 0.56659, saving model to model_part2.hdf5

Epoch 00288: loss improved from 0.56659 to 0.56465, saving model to model_part2.hdf5

Epoch 00289: loss improved from 0.56465 to 0.56282, saving model to model_part2.hdf5

Epoch 00290: loss improved from 0.56282 to 0.56124, saving model to model_part2.hdf5

Epoch 00291: loss improved from 0.56124 to 0.56042, saving model to model_part2.hdf5

Epoch 00292: loss improved from 0.56042 to 0.55774, saving model to model_part2.hdf5

Epoch 00293: loss improved from 0.55774 to 0.55611, saving model to model_part2.hdf5

Epoch 00294: loss improved from 0.55611 to 0.55441, saving model to model_part2.hdf5

Epoch 00295: loss improved from 0.55441 to 0.55299, saving model to model_part2.hdf5

Epoch 00296: loss improved from 0.55299 to 0.55103, saving model to model_part2.hdf5

Epoch 00297: loss improved from 0.55103 to 0.54978, saving model to model_part2.hdf5

Epoch 00298: loss improved from 0.54978 to 0.54792, saving model to model_part2.hdf5

Epoch 00299: loss did not improve from 0.54792

Epoch 00300: loss improved from 0.54792 to 0.54473, saving model to model_part2.hdf5

Epoch 00301: loss improved from 0.54473 to 0.54286, saving model to model_part2.hdf5

Epoch 00302: loss improved from 0.54286 to 0.54137, saving model to model_part2.hdf5

Epoch 00303: loss improved from 0.54137 to 0.54005, saving model to model_part2.hdf5

Epoch 00304: loss improved from 0.54005 to 0.53861, saving model to model_part2.hdf5

Epoch 00305: loss improved from 0.53861 to 0.53861, saving model to model_part2.hdf5

Epoch 00306: loss improved from 0.53861 to 0.53533, saving model to model_part2.hdf5

Epoch 00307: loss improved from 0.53533 to 0.53338, saving model to model_part2.hdf5

Epoch 00308: loss improved from 0.53338 to 0.53168, saving model to model_part2.hdf5

Epoch 00309: loss improved from 0.53168 to 0.52999, saving model to model_part2.hdf5

Epoch 00310: loss improved from 0.52999 to 0.52836, saving model to model_part2.hdf5

Epoch 00311: loss improved from 0.52836 to 0.52701, saving model to model_part2.hdf5

Epoch 00312: loss improved from 0.52701 to 0.52695, saving model to model_part2.hdf5

Epoch 00313: loss improved from 0.52695 to 0.52389, saving model to model_part2.hdf5

Epoch 00314: loss improved from 0.52389 to 0.52209, saving model to model_part2.hdf5

Epoch 00315: loss improved from 0.52209 to 0.52101, saving model to model_part2.hdf5

Epoch 00316: loss improved from 0.52101 to 0.51894, saving model to model_part2.hdf5

Epoch 00317: loss improved from 0.51894 to 0.51807, saving model to model_part2.hdf5

Epoch 00318: loss improved from 0.51807 to 0.51578, saving model to model_part2.hdf5

Epoch 00319: loss improved from 0.51578 to 0.51470, saving model to model_part2.hdf5

Epoch 00320: loss improved from 0.51470 to 0.51248, saving model to model_part2.hdf5

Epoch 00321: loss improved from 0.51248 to 0.51091, saving model to model_part2.hdf5

Epoch 00322: loss improved from 0.51091 to 0.51002, saving model to model_part2.hdf5

Epoch 00323: loss improved from 0.51002 to 0.50968, saving model to model_part2.hdf5

Epoch 00324: loss improved from 0.50968 to 0.50666, saving model to model_part2.hdf5

Epoch 00325: loss improved from 0.50666 to 0.50455, saving model to model_part2.hdf5

Epoch 00326: loss improved from 0.50455 to 0.50296, saving model to model_part2.hdf5

Epoch 00327: loss improved from 0.50296 to 0.50217, saving model to model_part2.hdf5

Epoch 00328: loss improved from 0.50217 to 0.50145, saving model to model_part2.hdf5

Epoch 00329: loss improved from 0.50145 to 0.49866, saving model to model_part2.hdf5

Epoch 00330: loss improved from 0.49866 to 0.49664, saving model to model_part2.hdf5

Epoch 00331: loss improved from 0.49664 to 0.49520, saving model to model_part2.hdf5

Epoch 00332: loss improved from 0.49520 to 0.49397, saving model to model_part2.hdf5

Epoch 00333: loss improved from 0.49397 to 0.49360, saving model to model_part2.hdf5

Epoch 00334: loss improved from 0.49360 to 0.49082, saving model to model_part2.hdf5

Epoch 00335: loss improved from 0.49082 to 0.48888, saving model to model_part2.hdf5

Epoch 00336: loss improved from 0.48888 to 0.48729, saving model to model_part2.hdf5

Epoch 00337: loss improved from 0.48729 to 0.48606, saving model to model_part2.hdf5

Epoch 00338: loss improved from 0.48606 to 0.48487, saving model to model_part2.hdf5

Epoch 00339: loss improved from 0.48487 to 0.48249, saving model to model_part2.hdf5

Epoch 00340: loss improved from 0.48249 to 0.48122, saving model to model_part2.hdf5

Epoch 00341: loss did not improve from 0.48122

Epoch 00342: loss improved from 0.48122 to 0.47833, saving model to model_part2.hdf5

Epoch 00343: loss improved from 0.47833 to 0.47618, saving model to model_part2.hdf5

Epoch 00344: loss improved from 0.47618 to 0.47468, saving model to model_part2.hdf5

Epoch 00345: loss improved from 0.47468 to 0.47326, saving model to model_part2.hdf5

Epoch 00346: loss improved from 0.47326 to 0.47132, saving model to model_part2.hdf5

Epoch 00347: loss improved from 0.47132 to 0.46992, saving model to model_part2.hdf5

Epoch 00348: loss improved from 0.46992 to 0.46833, saving model to model_part2.hdf5

Epoch 00349: loss improved from 0.46833 to 0.46716, saving model to model_part2.hdf5

Epoch 00350: loss improved from 0.46716 to 0.46491, saving model to model_part2.hdf5

Epoch 00351: loss improved from 0.46491 to 0.46312, saving model to model_part2.hdf5

Epoch 00352: loss improved from 0.46312 to 0.46162, saving model to model_part2.hdf5

Epoch 00353: loss improved from 0.46162 to 0.46056, saving model to model_part2.hdf5

Epoch 00354: loss did not improve from 0.46056

Epoch 00355: loss improved from 0.46056 to 0.45764, saving model to model_part2.hdf5

Epoch 00356: loss improved from 0.45764 to 0.45538, saving model to model_part2.hdf5

Epoch 00357: loss improved from 0.45538 to 0.45368, saving model to model_part2.hdf5

Epoch 00358: loss improved from 0.45368 to 0.45279, saving model to model_part2.hdf5

Epoch 00359: loss improved from 0.45279 to 0.45040, saving model to model_part2.hdf5

Epoch 00360: loss improved from 0.45040 to 0.44862, saving model to model_part2.hdf5

Epoch 00361: loss improved from 0.44862 to 0.44709, saving model to model_part2.hdf5

Epoch 00362: loss improved from 0.44709 to 0.44615, saving model to model_part2.hdf5

Epoch 00363: loss improved from 0.44615 to 0.44503, saving model to model_part2.hdf5

Epoch 00364: loss improved from 0.44503 to 0.44245, saving model to model_part2.hdf5

Epoch 00365: loss improved from 0.44245 to 0.44046, saving model to model_part2.hdf5

Epoch 00366: loss improved from 0.44046 to 0.43899, saving model to model_part2.hdf5

Epoch 00367: loss did not improve from 0.43899

Epoch 00368: loss improved from 0.43899 to 0.43640, saving model to model_part2.hdf5

Epoch 00369: loss improved from 0.43640 to 0.43417, saving model to model_part2.hdf5

Epoch 00370: loss improved from 0.43417 to 0.43240, saving model to model_part2.hdf5

Epoch 00371: loss improved from 0.43240 to 0.43159, saving model to model_part2.hdf5

Epoch 00372: loss improved from 0.43159 to 0.42932, saving model to model_part2.hdf5

Epoch 00373: loss improved from 0.42932 to 0.42738, saving model to model_part2.hdf5

Epoch 00374: loss improved from 0.42738 to 0.42571, saving model to model_part2.hdf5

Epoch 00375: loss improved from 0.42571 to 0.42457, saving model to model_part2.hdf5

Epoch 00376: loss improved from 0.42457 to 0.42241, saving model to model_part2.hdf5

Epoch 00377: loss improved from 0.42241 to 0.42093, saving model to model_part2.hdf5

Epoch 00378: loss did not improve from 0.42093

Epoch 00379: loss improved from 0.42093 to 0.41819, saving model to model_part2.hdf5

Epoch 00380: loss improved from 0.41819 to 0.41580, saving model to model_part2.hdf5

Epoch 00381: loss improved from 0.41580 to 0.41415, saving model to model_part2.hdf5

Epoch 00382: loss improved from 0.41415 to 0.41260, saving model to model_part2.hdf5

Epoch 00383: loss improved from 0.41260 to 0.41186, saving model to model_part2.hdf5

Epoch 00384: loss improved from 0.41186 to 0.40944, saving model to model_part2.hdf5

Epoch 00385: loss improved from 0.40944 to 0.40756, saving model to model_part2.hdf5

Epoch 00386: loss improved from 0.40756 to 0.40647, saving model to model_part2.hdf5

Epoch 00387: loss improved from 0.40647 to 0.40449, saving model to model_part2.hdf5

Epoch 00388: loss improved from 0.40449 to 0.40440, saving model to model_part2.hdf5

Epoch 00389: loss improved from 0.40440 to 0.40177, saving model to model_part2.hdf5

Epoch 00390: loss improved from 0.40177 to 0.39931, saving model to model_part2.hdf5

Epoch 00391: loss improved from 0.39931 to 0.39762, saving model to model_part2.hdf5

Epoch 00392: loss improved from 0.39762 to 0.39663, saving model to model_part2.hdf5

Epoch 00393: loss improved from 0.39663 to 0.39457, saving model to model_part2.hdf5

Epoch 00394: loss improved from 0.39457 to 0.39380, saving model to model_part2.hdf5

Epoch 00395: loss improved from 0.39380 to 0.39115, saving model to model_part2.hdf5

Epoch 00396: loss improved from 0.39115 to 0.39058, saving model to model_part2.hdf5

Epoch 00397: loss did not improve from 0.39058

Epoch 00398: loss improved from 0.39058 to 0.38734, saving model to model_part2.hdf5

Epoch 00399: loss improved from 0.38734 to 0.38493, saving model to model_part2.hdf5

Epoch 00400: loss improved from 0.38493 to 0.38375, saving model to model_part2.hdf5

Epoch 00401: loss improved from 0.38375 to 0.38272, saving model to model_part2.hdf5

Epoch 00402: loss improved from 0.38272 to 0.38027, saving model to model_part2.hdf5

Epoch 00403: loss improved from 0.38027 to 0.37847, saving model to model_part2.hdf5

Epoch 00404: loss improved from 0.37847 to 0.37716, saving model to model_part2.hdf5

Epoch 00405: loss improved from 0.37716 to 0.37545, saving model to model_part2.hdf5

Epoch 00406: loss improved from 0.37545 to 0.37483, saving model to model_part2.hdf5

Epoch 00407: loss improved from 0.37483 to 0.37211, saving model to model_part2.hdf5

Epoch 00408: loss improved from 0.37211 to 0.37092, saving model to model_part2.hdf5

Epoch 00409: loss improved from 0.37092 to 0.37023, saving model to model_part2.hdf5

Epoch 00410: loss improved from 0.37023 to 0.36742, saving model to model_part2.hdf5

Epoch 00411: loss improved from 0.36742 to 0.36679, saving model to model_part2.hdf5

Epoch 00412: loss improved from 0.36679 to 0.36442, saving model to model_part2.hdf5

Epoch 00413: loss improved from 0.36442 to 0.36272, saving model to model_part2.hdf5

Epoch 00414: loss improved from 0.36272 to 0.36270, saving model to model_part2.hdf5

Epoch 00415: loss improved from 0.36270 to 0.36013, saving model to model_part2.hdf5

Epoch 00416: loss improved from 0.36013 to 0.35850, saving model to model_part2.hdf5

Epoch 00417: loss improved from 0.35850 to 0.35666, saving model to model_part2.hdf5

Epoch 00418: loss improved from 0.35666 to 0.35534, saving model to model_part2.hdf5

Epoch 00419: loss improved from 0.35534 to 0.35502, saving model to model_part2.hdf5

Epoch 00420: loss improved from 0.35502 to 0.35198, saving model to model_part2.hdf5

Epoch 00421: loss improved from 0.35198 to 0.35065, saving model to model_part2.hdf5

Epoch 00422: loss improved from 0.35065 to 0.35011, saving model to model_part2.hdf5

Epoch 00423: loss did not improve from 0.35011

Epoch 00424: loss improved from 0.35011 to 0.34671, saving model to model_part2.hdf5

Epoch 00425: loss improved from 0.34671 to 0.34448, saving model to model_part2.hdf5

Epoch 00426: loss improved from 0.34448 to 0.34317, saving model to model_part2.hdf5

Epoch 00427: loss improved from 0.34317 to 0.34209, saving model to model_part2.hdf5

Epoch 00428: loss did not improve from 0.34209

Epoch 00429: loss improved from 0.34209 to 0.33862, saving model to model_part2.hdf5

Epoch 00430: loss improved from 0.33862 to 0.33723, saving model to model_part2.hdf5

Epoch 00431: loss improved from 0.33723 to 0.33594, saving model to model_part2.hdf5

Epoch 00432: loss improved from 0.33594 to 0.33531, saving model to model_part2.hdf5

Epoch 00433: loss improved from 0.33531 to 0.33303, saving model to model_part2.hdf5

Epoch 00434: loss did not improve from 0.33303

Epoch 00435: loss improved from 0.33303 to 0.33008, saving model to model_part2.hdf5

Epoch 00436: loss improved from 0.33008 to 0.32829, saving model to model_part2.hdf5

Epoch 00437: loss improved from 0.32829 to 0.32756, saving model to model_part2.hdf5

Epoch 00438: loss did not improve from 0.32756

Epoch 00439: loss improved from 0.32756 to 0.32442, saving model to model_part2.hdf5

Epoch 00440: loss improved from 0.32442 to 0.32265, saving model to model_part2.hdf5

Epoch 00441: loss improved from 0.32265 to 0.32184, saving model to model_part2.hdf5

Epoch 00442: loss improved from 0.32184 to 0.32036, saving model to model_part2.hdf5

Epoch 00443: loss improved from 0.32036 to 0.31839, saving model to model_part2.hdf5

Epoch 00444: loss improved from 0.31839 to 0.31725, saving model to model_part2.hdf5

Epoch 00445: loss improved from 0.31725 to 0.31609, saving model to model_part2.hdf5

Epoch 00446: loss improved from 0.31609 to 0.31547, saving model to model_part2.hdf5

Epoch 00447: loss improved from 0.31547 to 0.31305, saving model to model_part2.hdf5

Epoch 00448: loss improved from 0.31305 to 0.31137, saving model to model_part2.hdf5

Epoch 00449: loss improved from 0.31137 to 0.30987, saving model to model_part2.hdf5

Epoch 00450: loss improved from 0.30987 to 0.30944, saving model to model_part2.hdf5

Epoch 00451: loss improved from 0.30944 to 0.30794, saving model to model_part2.hdf5

Epoch 00452: loss did not improve from 0.30794

Epoch 00453: loss improved from 0.30794 to 0.30498, saving model to model_part2.hdf5

Epoch 00454: loss improved from 0.30498 to 0.30336, saving model to model_part2.hdf5

Epoch 00455: loss improved from 0.30336 to 0.30186, saving model to model_part2.hdf5

Epoch 00456: loss improved from 0.30186 to 0.30105, saving model to model_part2.hdf5

Epoch 00457: loss improved from 0.30105 to 0.29967, saving model to model_part2.hdf5

Epoch 00458: loss improved from 0.29967 to 0.29843, saving model to model_part2.hdf5

Epoch 00459: loss improved from 0.29843 to 0.29712, saving model to model_part2.hdf5

Epoch 00460: loss improved from 0.29712 to 0.29691, saving model to model_part2.hdf5

Epoch 00461: loss improved from 0.29691 to 0.29442, saving model to model_part2.hdf5

Epoch 00462: loss improved from 0.29442 to 0.29291, saving model to model_part2.hdf5

Epoch 00463: loss improved from 0.29291 to 0.29144, saving model to model_part2.hdf5

Epoch 00464: loss improved from 0.29144 to 0.29039, saving model to model_part2.hdf5

Epoch 00465: loss did not improve from 0.29039

Epoch 00466: loss improved from 0.29039 to 0.28826, saving model to model_part2.hdf5

Epoch 00467: loss improved from 0.28826 to 0.28665, saving model to model_part2.hdf5

Epoch 00468: loss improved from 0.28665 to 0.28534, saving model to model_part2.hdf5

Epoch 00469: loss improved from 0.28534 to 0.28420, saving model to model_part2.hdf5

Epoch 00470: loss improved from 0.28420 to 0.28343, saving model to model_part2.hdf5

Epoch 00471: loss improved from 0.28343 to 0.28208, saving model to model_part2.hdf5

Epoch 00472: loss improved from 0.28208 to 0.28070, saving model to model_part2.hdf5

Epoch 00473: loss improved from 0.28070 to 0.28015, saving model to model_part2.hdf5

Epoch 00474: loss improved from 0.28015 to 0.27817, saving model to model_part2.hdf5

Epoch 00475: loss improved from 0.27817 to 0.27692, saving model to model_part2.hdf5

Epoch 00476: loss improved from 0.27692 to 0.27571, saving model to model_part2.hdf5

Epoch 00477: loss improved from 0.27571 to 0.27476, saving model to model_part2.hdf5

Epoch 00478: loss improved from 0.27476 to 0.27330, saving model to model_part2.hdf5

Epoch 00479: loss improved from 0.27330 to 0.27237, saving model to model_part2.hdf5

Epoch 00480: loss improved from 0.27237 to 0.27166, saving model to model_part2.hdf5

Epoch 00481: loss improved from 0.27166 to 0.27081, saving model to model_part2.hdf5

Epoch 00482: loss improved from 0.27081 to 0.26910, saving model to model_part2.hdf5

Epoch 00483: loss improved from 0.26910 to 0.26806, saving model to model_part2.hdf5

Epoch 00484: loss improved from 0.26806 to 0.26697, saving model to model_part2.hdf5

Epoch 00485: loss improved from 0.26697 to 0.26632, saving model to model_part2.hdf5

Epoch 00486: loss improved from 0.26632 to 0.26467, saving model to model_part2.hdf5

Epoch 00487: loss improved from 0.26467 to 0.26461, saving model to model_part2.hdf5

Epoch 00488: loss improved from 0.26461 to 0.26289, saving model to model_part2.hdf5

Epoch 00489: loss improved from 0.26289 to 0.26156, saving model to model_part2.hdf5

Epoch 00490: loss improved from 0.26156 to 0.26030, saving model to model_part2.hdf5

Epoch 00491: loss improved from 0.26030 to 0.25926, saving model to model_part2.hdf5

Epoch 00492: loss improved from 0.25926 to 0.25825, saving model to model_part2.hdf5

Epoch 00493: loss improved from 0.25825 to 0.25797, saving model to model_part2.hdf5

Epoch 00494: loss improved from 0.25797 to 0.25649, saving model to model_part2.hdf5

Epoch 00495: loss improved from 0.25649 to 0.25574, saving model to model_part2.hdf5

Epoch 00496: loss improved from 0.25574 to 0.25420, saving model to model_part2.hdf5

Epoch 00497: loss improved from 0.25420 to 0.25362, saving model to model_part2.hdf5

Epoch 00498: loss improved from 0.25362 to 0.25246, saving model to model_part2.hdf5

Epoch 00499: loss improved from 0.25246 to 0.25138, saving model to model_part2.hdf5

Epoch 00500: loss improved from 0.25138 to 0.25040, saving model to model_part2.hdf5

Epoch 00501: loss improved from 0.25040 to 0.24968, saving model to model_part2.hdf5

Epoch 00502: loss improved from 0.24968 to 0.24937, saving model to model_part2.hdf5

Epoch 00503: loss improved from 0.24937 to 0.24774, saving model to model_part2.hdf5

Epoch 00504: loss improved from 0.24774 to 0.24676, saving model to model_part2.hdf5

Epoch 00505: loss did not improve from 0.24676

Epoch 00506: loss improved from 0.24676 to 0.24526, saving model to model_part2.hdf5

Epoch 00507: loss improved from 0.24526 to 0.24420, saving model to model_part2.hdf5

Epoch 00508: loss improved from 0.24420 to 0.24329, saving model to model_part2.hdf5

Epoch 00509: loss improved from 0.24329 to 0.24258, saving model to model_part2.hdf5

Epoch 00510: loss improved from 0.24258 to 0.24242, saving model to model_part2.hdf5

Epoch 00511: loss improved from 0.24242 to 0.24079, saving model to model_part2.hdf5

Epoch 00512: loss improved from 0.24079 to 0.23992, saving model to model_part2.hdf5

Epoch 00513: loss improved from 0.23992 to 0.23929, saving model to model_part2.hdf5

Epoch 00514: loss improved from 0.23929 to 0.23863, saving model to model_part2.hdf5

Epoch 00515: loss improved from 0.23863 to 0.23768, saving model to model_part2.hdf5

Epoch 00516: loss improved from 0.23768 to 0.23713, saving model to model_part2.hdf5

Epoch 00517: loss improved from 0.23713 to 0.23620, saving model to model_part2.hdf5

Epoch 00518: loss improved from 0.23620 to 0.23532, saving model to model_part2.hdf5

Epoch 00519: loss improved from 0.23532 to 0.23440, saving model to model_part2.hdf5

Epoch 00520: loss improved from 0.23440 to 0.23368, saving model to model_part2.hdf5

Epoch 00521: loss improved from 0.23368 to 0.23306, saving model to model_part2.hdf5

Epoch 00522: loss improved from 0.23306 to 0.23304, saving model to model_part2.hdf5

Epoch 00523: loss improved from 0.23304 to 0.23193, saving model to model_part2.hdf5

Epoch 00524: loss improved from 0.23193 to 0.23101, saving model to model_part2.hdf5

Epoch 00525: loss improved from 0.23101 to 0.23011, saving model to model_part2.hdf5

Epoch 00526: loss improved from 0.23011 to 0.22930, saving model to model_part2.hdf5

Epoch 00527: loss improved from 0.22930 to 0.22858, saving model to model_part2.hdf5

Epoch 00528: loss improved from 0.22858 to 0.22821, saving model to model_part2.hdf5

Epoch 00529: loss improved from 0.22821 to 0.22801, saving model to model_part2.hdf5

Epoch 00530: loss improved from 0.22801 to 0.22653, saving model to model_part2.hdf5

Epoch 00531: loss improved from 0.22653 to 0.22579, saving model to model_part2.hdf5

Epoch 00532: loss improved from 0.22579 to 0.22553, saving model to model_part2.hdf5

Epoch 00533: loss improved from 0.22553 to 0.22514, saving model to model_part2.hdf5

Epoch 00534: loss improved from 0.22514 to 0.22426, saving model to model_part2.hdf5

Epoch 00535: loss improved from 0.22426 to 0.22353, saving model to model_part2.hdf5

Epoch 00536: loss improved from 0.22353 to 0.22284, saving model to model_part2.hdf5

Epoch 00537: loss improved from 0.22284 to 0.22219, saving model to model_part2.hdf5
Testing the model
45/45 [==============================] - 0s 647us/step
====================================================

====================================================
Percent Training Size  0.3
Training the Model

Epoch 00001: loss improved from inf to 1.09885, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.09885 to 1.09634, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.09634 to 1.09513, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.09513 to 1.09408, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.09408 to 1.09277, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.09277 to 1.09172, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.09172 to 1.09075, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.09075 to 1.08967, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.08967 to 1.08888, saving model to model_part2.hdf5

Epoch 00010: loss improved from 1.08888 to 1.08871, saving model to model_part2.hdf5

Epoch 00011: loss improved from 1.08871 to 1.08743, saving model to model_part2.hdf5

Epoch 00012: loss improved from 1.08743 to 1.08656, saving model to model_part2.hdf5

Epoch 00013: loss improved from 1.08656 to 1.08590, saving model to model_part2.hdf5

Epoch 00014: loss improved from 1.08590 to 1.08518, saving model to model_part2.hdf5

Epoch 00015: loss improved from 1.08518 to 1.08407, saving model to model_part2.hdf5

Epoch 00016: loss improved from 1.08407 to 1.08343, saving model to model_part2.hdf5

Epoch 00017: loss improved from 1.08343 to 1.08229, saving model to model_part2.hdf5

Epoch 00018: loss improved from 1.08229 to 1.08131, saving model to model_part2.hdf5

Epoch 00019: loss improved from 1.08131 to 1.08053, saving model to model_part2.hdf5

Epoch 00020: loss improved from 1.08053 to 1.07926, saving model to model_part2.hdf5

Epoch 00021: loss improved from 1.07926 to 1.07834, saving model to model_part2.hdf5

Epoch 00022: loss improved from 1.07834 to 1.07731, saving model to model_part2.hdf5

Epoch 00023: loss improved from 1.07731 to 1.07613, saving model to model_part2.hdf5

Epoch 00024: loss improved from 1.07613 to 1.07555, saving model to model_part2.hdf5

Epoch 00025: loss improved from 1.07555 to 1.07419, saving model to model_part2.hdf5

Epoch 00026: loss improved from 1.07419 to 1.07377, saving model to model_part2.hdf5

Epoch 00027: loss improved from 1.07377 to 1.07210, saving model to model_part2.hdf5

Epoch 00028: loss improved from 1.07210 to 1.07120, saving model to model_part2.hdf5

Epoch 00029: loss improved from 1.07120 to 1.07053, saving model to model_part2.hdf5

Epoch 00030: loss improved from 1.07053 to 1.06998, saving model to model_part2.hdf5

Epoch 00031: loss improved from 1.06998 to 1.06818, saving model to model_part2.hdf5

Epoch 00032: loss improved from 1.06818 to 1.06701, saving model to model_part2.hdf5

Epoch 00033: loss improved from 1.06701 to 1.06661, saving model to model_part2.hdf5

Epoch 00034: loss improved from 1.06661 to 1.06619, saving model to model_part2.hdf5

Epoch 00035: loss improved from 1.06619 to 1.06404, saving model to model_part2.hdf5

Epoch 00036: loss improved from 1.06404 to 1.06314, saving model to model_part2.hdf5

Epoch 00037: loss improved from 1.06314 to 1.06211, saving model to model_part2.hdf5

Epoch 00038: loss improved from 1.06211 to 1.06159, saving model to model_part2.hdf5

Epoch 00039: loss improved from 1.06159 to 1.05989, saving model to model_part2.hdf5

Epoch 00040: loss improved from 1.05989 to 1.05922, saving model to model_part2.hdf5

Epoch 00041: loss improved from 1.05922 to 1.05785, saving model to model_part2.hdf5

Epoch 00042: loss improved from 1.05785 to 1.05729, saving model to model_part2.hdf5

Epoch 00043: loss improved from 1.05729 to 1.05547, saving model to model_part2.hdf5

Epoch 00044: loss improved from 1.05547 to 1.05452, saving model to model_part2.hdf5

Epoch 00045: loss improved from 1.05452 to 1.05398, saving model to model_part2.hdf5

Epoch 00046: loss improved from 1.05398 to 1.05204, saving model to model_part2.hdf5

Epoch 00047: loss improved from 1.05204 to 1.05079, saving model to model_part2.hdf5

Epoch 00048: loss improved from 1.05079 to 1.04988, saving model to model_part2.hdf5

Epoch 00049: loss improved from 1.04988 to 1.04947, saving model to model_part2.hdf5

Epoch 00050: loss improved from 1.04947 to 1.04731, saving model to model_part2.hdf5

Epoch 00051: loss improved from 1.04731 to 1.04634, saving model to model_part2.hdf5

Epoch 00052: loss improved from 1.04634 to 1.04501, saving model to model_part2.hdf5

Epoch 00053: loss improved from 1.04501 to 1.04425, saving model to model_part2.hdf5

Epoch 00054: loss improved from 1.04425 to 1.04211, saving model to model_part2.hdf5

Epoch 00055: loss improved from 1.04211 to 1.04051, saving model to model_part2.hdf5

Epoch 00056: loss improved from 1.04051 to 1.03931, saving model to model_part2.hdf5

Epoch 00057: loss improved from 1.03931 to 1.03829, saving model to model_part2.hdf5

Epoch 00058: loss improved from 1.03829 to 1.03620, saving model to model_part2.hdf5

Epoch 00059: loss improved from 1.03620 to 1.03509, saving model to model_part2.hdf5

Epoch 00060: loss improved from 1.03509 to 1.03345, saving model to model_part2.hdf5

Epoch 00061: loss improved from 1.03345 to 1.03234, saving model to model_part2.hdf5

Epoch 00062: loss improved from 1.03234 to 1.03009, saving model to model_part2.hdf5

Epoch 00063: loss improved from 1.03009 to 1.02854, saving model to model_part2.hdf5

Epoch 00064: loss improved from 1.02854 to 1.02713, saving model to model_part2.hdf5

Epoch 00065: loss improved from 1.02713 to 1.02545, saving model to model_part2.hdf5

Epoch 00066: loss improved from 1.02545 to 1.02363, saving model to model_part2.hdf5

Epoch 00067: loss improved from 1.02363 to 1.02163, saving model to model_part2.hdf5

Epoch 00068: loss improved from 1.02163 to 1.01973, saving model to model_part2.hdf5

Epoch 00069: loss improved from 1.01973 to 1.01767, saving model to model_part2.hdf5

Epoch 00070: loss improved from 1.01767 to 1.01562, saving model to model_part2.hdf5

Epoch 00071: loss improved from 1.01562 to 1.01331, saving model to model_part2.hdf5

Epoch 00072: loss improved from 1.01331 to 1.01118, saving model to model_part2.hdf5

Epoch 00073: loss improved from 1.01118 to 1.00885, saving model to model_part2.hdf5

Epoch 00074: loss improved from 1.00885 to 1.00597, saving model to model_part2.hdf5

Epoch 00075: loss improved from 1.00597 to 1.00317, saving model to model_part2.hdf5

Epoch 00076: loss improved from 1.00317 to 0.99983, saving model to model_part2.hdf5

Epoch 00077: loss improved from 0.99983 to 0.99735, saving model to model_part2.hdf5

Epoch 00078: loss improved from 0.99735 to 0.99451, saving model to model_part2.hdf5

Epoch 00079: loss improved from 0.99451 to 0.99215, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.99215 to 0.98880, saving model to model_part2.hdf5

Epoch 00081: loss improved from 0.98880 to 0.98674, saving model to model_part2.hdf5

Epoch 00082: loss improved from 0.98674 to 0.98498, saving model to model_part2.hdf5

Epoch 00083: loss improved from 0.98498 to 0.98171, saving model to model_part2.hdf5

Epoch 00084: loss improved from 0.98171 to 0.97921, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.97921 to 0.97698, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.97698 to 0.97500, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.97500 to 0.97260, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.97260 to 0.97060, saving model to model_part2.hdf5

Epoch 00089: loss improved from 0.97060 to 0.96759, saving model to model_part2.hdf5

Epoch 00090: loss improved from 0.96759 to 0.96562, saving model to model_part2.hdf5

Epoch 00091: loss improved from 0.96562 to 0.96254, saving model to model_part2.hdf5

Epoch 00092: loss improved from 0.96254 to 0.96035, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.96035 to 0.95857, saving model to model_part2.hdf5

Epoch 00094: loss improved from 0.95857 to 0.95693, saving model to model_part2.hdf5

Epoch 00095: loss improved from 0.95693 to 0.95303, saving model to model_part2.hdf5

Epoch 00096: loss improved from 0.95303 to 0.95068, saving model to model_part2.hdf5

Epoch 00097: loss improved from 0.95068 to 0.94798, saving model to model_part2.hdf5

Epoch 00098: loss improved from 0.94798 to 0.94574, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.94574 to 0.94296, saving model to model_part2.hdf5

Epoch 00100: loss improved from 0.94296 to 0.94063, saving model to model_part2.hdf5

Epoch 00101: loss improved from 0.94063 to 0.93787, saving model to model_part2.hdf5

Epoch 00102: loss improved from 0.93787 to 0.93536, saving model to model_part2.hdf5

Epoch 00103: loss improved from 0.93536 to 0.93237, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.93237 to 0.92959, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.92959 to 0.92664, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.92664 to 0.92399, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.92399 to 0.92092, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.92092 to 0.91820, saving model to model_part2.hdf5

Epoch 00109: loss improved from 0.91820 to 0.91496, saving model to model_part2.hdf5

Epoch 00110: loss improved from 0.91496 to 0.91169, saving model to model_part2.hdf5

Epoch 00111: loss improved from 0.91169 to 0.90891, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.90891 to 0.90514, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.90514 to 0.90254, saving model to model_part2.hdf5

Epoch 00114: loss improved from 0.90254 to 0.89923, saving model to model_part2.hdf5

Epoch 00115: loss improved from 0.89923 to 0.89600, saving model to model_part2.hdf5

Epoch 00116: loss improved from 0.89600 to 0.89272, saving model to model_part2.hdf5

Epoch 00117: loss improved from 0.89272 to 0.88993, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.88993 to 0.88688, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.88688 to 0.88433, saving model to model_part2.hdf5

Epoch 00120: loss improved from 0.88433 to 0.88130, saving model to model_part2.hdf5

Epoch 00121: loss improved from 0.88130 to 0.87931, saving model to model_part2.hdf5

Epoch 00122: loss improved from 0.87931 to 0.87536, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.87536 to 0.87181, saving model to model_part2.hdf5

Epoch 00124: loss improved from 0.87181 to 0.86847, saving model to model_part2.hdf5

Epoch 00125: loss improved from 0.86847 to 0.86536, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.86536 to 0.86192, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.86192 to 0.85869, saving model to model_part2.hdf5

Epoch 00128: loss improved from 0.85869 to 0.85538, saving model to model_part2.hdf5

Epoch 00129: loss improved from 0.85538 to 0.85206, saving model to model_part2.hdf5

Epoch 00130: loss improved from 0.85206 to 0.84864, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.84864 to 0.84515, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.84515 to 0.84163, saving model to model_part2.hdf5

Epoch 00133: loss improved from 0.84163 to 0.83806, saving model to model_part2.hdf5

Epoch 00134: loss improved from 0.83806 to 0.83528, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.83528 to 0.83228, saving model to model_part2.hdf5

Epoch 00136: loss improved from 0.83228 to 0.82984, saving model to model_part2.hdf5

Epoch 00137: loss improved from 0.82984 to 0.82528, saving model to model_part2.hdf5

Epoch 00138: loss improved from 0.82528 to 0.82258, saving model to model_part2.hdf5

Epoch 00139: loss improved from 0.82258 to 0.81926, saving model to model_part2.hdf5

Epoch 00140: loss improved from 0.81926 to 0.81539, saving model to model_part2.hdf5

Epoch 00141: loss improved from 0.81539 to 0.81187, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.81187 to 0.80717, saving model to model_part2.hdf5

Epoch 00143: loss improved from 0.80717 to 0.80381, saving model to model_part2.hdf5

Epoch 00144: loss improved from 0.80381 to 0.79965, saving model to model_part2.hdf5

Epoch 00145: loss improved from 0.79965 to 0.79632, saving model to model_part2.hdf5

Epoch 00146: loss improved from 0.79632 to 0.79254, saving model to model_part2.hdf5

Epoch 00147: loss improved from 0.79254 to 0.78991, saving model to model_part2.hdf5

Epoch 00148: loss improved from 0.78991 to 0.78539, saving model to model_part2.hdf5

Epoch 00149: loss improved from 0.78539 to 0.78218, saving model to model_part2.hdf5

Epoch 00150: loss improved from 0.78218 to 0.77892, saving model to model_part2.hdf5

Epoch 00151: loss improved from 0.77892 to 0.77523, saving model to model_part2.hdf5

Epoch 00152: loss improved from 0.77523 to 0.77196, saving model to model_part2.hdf5

Epoch 00153: loss improved from 0.77196 to 0.76979, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.76979 to 0.76439, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.76439 to 0.76097, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.76097 to 0.75791, saving model to model_part2.hdf5

Epoch 00157: loss improved from 0.75791 to 0.75447, saving model to model_part2.hdf5

Epoch 00158: loss improved from 0.75447 to 0.75035, saving model to model_part2.hdf5

Epoch 00159: loss improved from 0.75035 to 0.74737, saving model to model_part2.hdf5

Epoch 00160: loss improved from 0.74737 to 0.74309, saving model to model_part2.hdf5

Epoch 00161: loss improved from 0.74309 to 0.73968, saving model to model_part2.hdf5

Epoch 00162: loss improved from 0.73968 to 0.73589, saving model to model_part2.hdf5

Epoch 00163: loss improved from 0.73589 to 0.73233, saving model to model_part2.hdf5

Epoch 00164: loss improved from 0.73233 to 0.72893, saving model to model_part2.hdf5

Epoch 00165: loss improved from 0.72893 to 0.72577, saving model to model_part2.hdf5

Epoch 00166: loss improved from 0.72577 to 0.72257, saving model to model_part2.hdf5

Epoch 00167: loss improved from 0.72257 to 0.71935, saving model to model_part2.hdf5

Epoch 00168: loss improved from 0.71935 to 0.71638, saving model to model_part2.hdf5

Epoch 00169: loss improved from 0.71638 to 0.71276, saving model to model_part2.hdf5

Epoch 00170: loss improved from 0.71276 to 0.70947, saving model to model_part2.hdf5

Epoch 00171: loss improved from 0.70947 to 0.70625, saving model to model_part2.hdf5

Epoch 00172: loss improved from 0.70625 to 0.70309, saving model to model_part2.hdf5

Epoch 00173: loss improved from 0.70309 to 0.70036, saving model to model_part2.hdf5

Epoch 00174: loss improved from 0.70036 to 0.69733, saving model to model_part2.hdf5

Epoch 00175: loss did not improve from 0.69733

Epoch 00176: loss improved from 0.69733 to 0.69111, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.69111 to 0.68820, saving model to model_part2.hdf5

Epoch 00178: loss improved from 0.68820 to 0.68484, saving model to model_part2.hdf5

Epoch 00179: loss improved from 0.68484 to 0.68180, saving model to model_part2.hdf5

Epoch 00180: loss improved from 0.68180 to 0.67879, saving model to model_part2.hdf5

Epoch 00181: loss improved from 0.67879 to 0.67569, saving model to model_part2.hdf5

Epoch 00182: loss improved from 0.67569 to 0.67260, saving model to model_part2.hdf5

Epoch 00183: loss improved from 0.67260 to 0.66954, saving model to model_part2.hdf5

Epoch 00184: loss improved from 0.66954 to 0.66642, saving model to model_part2.hdf5

Epoch 00185: loss improved from 0.66642 to 0.66333, saving model to model_part2.hdf5

Epoch 00186: loss improved from 0.66333 to 0.66022, saving model to model_part2.hdf5

Epoch 00187: loss improved from 0.66022 to 0.65730, saving model to model_part2.hdf5

Epoch 00188: loss improved from 0.65730 to 0.65648, saving model to model_part2.hdf5

Epoch 00189: loss improved from 0.65648 to 0.65593, saving model to model_part2.hdf5

Epoch 00190: loss improved from 0.65593 to 0.64878, saving model to model_part2.hdf5

Epoch 00191: loss improved from 0.64878 to 0.64574, saving model to model_part2.hdf5

Epoch 00192: loss improved from 0.64574 to 0.64278, saving model to model_part2.hdf5

Epoch 00193: loss improved from 0.64278 to 0.63985, saving model to model_part2.hdf5

Epoch 00194: loss improved from 0.63985 to 0.63688, saving model to model_part2.hdf5

Epoch 00195: loss improved from 0.63688 to 0.63391, saving model to model_part2.hdf5

Epoch 00196: loss improved from 0.63391 to 0.63093, saving model to model_part2.hdf5

Epoch 00197: loss improved from 0.63093 to 0.62797, saving model to model_part2.hdf5

Epoch 00198: loss improved from 0.62797 to 0.62460, saving model to model_part2.hdf5

Epoch 00199: loss improved from 0.62460 to 0.62190, saving model to model_part2.hdf5

Epoch 00200: loss improved from 0.62190 to 0.61939, saving model to model_part2.hdf5

Epoch 00201: loss improved from 0.61939 to 0.61578, saving model to model_part2.hdf5

Epoch 00202: loss improved from 0.61578 to 0.61276, saving model to model_part2.hdf5

Epoch 00203: loss improved from 0.61276 to 0.60927, saving model to model_part2.hdf5

Epoch 00204: loss improved from 0.60927 to 0.60653, saving model to model_part2.hdf5

Epoch 00205: loss improved from 0.60653 to 0.60351, saving model to model_part2.hdf5

Epoch 00206: loss improved from 0.60351 to 0.60065, saving model to model_part2.hdf5

Epoch 00207: loss improved from 0.60065 to 0.59784, saving model to model_part2.hdf5

Epoch 00208: loss improved from 0.59784 to 0.59480, saving model to model_part2.hdf5

Epoch 00209: loss improved from 0.59480 to 0.59149, saving model to model_part2.hdf5

Epoch 00210: loss improved from 0.59149 to 0.58848, saving model to model_part2.hdf5

Epoch 00211: loss improved from 0.58848 to 0.58552, saving model to model_part2.hdf5

Epoch 00212: loss improved from 0.58552 to 0.58269, saving model to model_part2.hdf5

Epoch 00213: loss improved from 0.58269 to 0.58049, saving model to model_part2.hdf5

Epoch 00214: loss improved from 0.58049 to 0.57799, saving model to model_part2.hdf5

Epoch 00215: loss improved from 0.57799 to 0.57534, saving model to model_part2.hdf5

Epoch 00216: loss improved from 0.57534 to 0.57209, saving model to model_part2.hdf5

Epoch 00217: loss improved from 0.57209 to 0.56970, saving model to model_part2.hdf5

Epoch 00218: loss improved from 0.56970 to 0.56666, saving model to model_part2.hdf5

Epoch 00219: loss improved from 0.56666 to 0.56483, saving model to model_part2.hdf5

Epoch 00220: loss improved from 0.56483 to 0.56344, saving model to model_part2.hdf5

Epoch 00221: loss improved from 0.56344 to 0.55921, saving model to model_part2.hdf5

Epoch 00222: loss improved from 0.55921 to 0.55641, saving model to model_part2.hdf5

Epoch 00223: loss improved from 0.55641 to 0.55450, saving model to model_part2.hdf5

Epoch 00224: loss improved from 0.55450 to 0.55284, saving model to model_part2.hdf5

Epoch 00225: loss improved from 0.55284 to 0.54892, saving model to model_part2.hdf5

Epoch 00226: loss improved from 0.54892 to 0.54631, saving model to model_part2.hdf5

Epoch 00227: loss improved from 0.54631 to 0.54360, saving model to model_part2.hdf5

Epoch 00228: loss improved from 0.54360 to 0.54112, saving model to model_part2.hdf5

Epoch 00229: loss improved from 0.54112 to 0.53850, saving model to model_part2.hdf5

Epoch 00230: loss improved from 0.53850 to 0.53815, saving model to model_part2.hdf5

Epoch 00231: loss improved from 0.53815 to 0.53428, saving model to model_part2.hdf5

Epoch 00232: loss improved from 0.53428 to 0.53278, saving model to model_part2.hdf5

Epoch 00233: loss improved from 0.53278 to 0.52872, saving model to model_part2.hdf5

Epoch 00234: loss improved from 0.52872 to 0.52737, saving model to model_part2.hdf5

Epoch 00235: loss improved from 0.52737 to 0.52338, saving model to model_part2.hdf5

Epoch 00236: loss improved from 0.52338 to 0.52211, saving model to model_part2.hdf5

Epoch 00237: loss improved from 0.52211 to 0.51866, saving model to model_part2.hdf5

Epoch 00238: loss improved from 0.51866 to 0.51743, saving model to model_part2.hdf5

Epoch 00239: loss improved from 0.51743 to 0.51386, saving model to model_part2.hdf5

Epoch 00240: loss improved from 0.51386 to 0.51256, saving model to model_part2.hdf5

Epoch 00241: loss improved from 0.51256 to 0.50918, saving model to model_part2.hdf5

Epoch 00242: loss improved from 0.50918 to 0.50768, saving model to model_part2.hdf5

Epoch 00243: loss improved from 0.50768 to 0.50433, saving model to model_part2.hdf5

Epoch 00244: loss improved from 0.50433 to 0.50294, saving model to model_part2.hdf5

Epoch 00245: loss improved from 0.50294 to 0.49946, saving model to model_part2.hdf5

Epoch 00246: loss improved from 0.49946 to 0.49753, saving model to model_part2.hdf5

Epoch 00247: loss improved from 0.49753 to 0.49453, saving model to model_part2.hdf5

Epoch 00248: loss improved from 0.49453 to 0.49281, saving model to model_part2.hdf5

Epoch 00249: loss improved from 0.49281 to 0.48986, saving model to model_part2.hdf5

Epoch 00250: loss improved from 0.48986 to 0.48806, saving model to model_part2.hdf5

Epoch 00251: loss improved from 0.48806 to 0.48514, saving model to model_part2.hdf5

Epoch 00252: loss improved from 0.48514 to 0.48327, saving model to model_part2.hdf5

Epoch 00253: loss improved from 0.48327 to 0.48093, saving model to model_part2.hdf5

Epoch 00254: loss improved from 0.48093 to 0.48041, saving model to model_part2.hdf5

Epoch 00255: loss improved from 0.48041 to 0.47587, saving model to model_part2.hdf5

Epoch 00256: loss improved from 0.47587 to 0.47367, saving model to model_part2.hdf5

Epoch 00257: loss improved from 0.47367 to 0.47109, saving model to model_part2.hdf5

Epoch 00258: loss improved from 0.47109 to 0.47068, saving model to model_part2.hdf5

Epoch 00259: loss improved from 0.47068 to 0.46649, saving model to model_part2.hdf5

Epoch 00260: loss improved from 0.46649 to 0.46356, saving model to model_part2.hdf5

Epoch 00261: loss improved from 0.46356 to 0.46110, saving model to model_part2.hdf5

Epoch 00262: loss improved from 0.46110 to 0.45861, saving model to model_part2.hdf5

Epoch 00263: loss improved from 0.45861 to 0.45609, saving model to model_part2.hdf5

Epoch 00264: loss improved from 0.45609 to 0.45354, saving model to model_part2.hdf5

Epoch 00265: loss improved from 0.45354 to 0.45104, saving model to model_part2.hdf5

Epoch 00266: loss improved from 0.45104 to 0.44961, saving model to model_part2.hdf5

Epoch 00267: loss improved from 0.44961 to 0.44926, saving model to model_part2.hdf5

Epoch 00268: loss improved from 0.44926 to 0.44853, saving model to model_part2.hdf5

Epoch 00269: loss improved from 0.44853 to 0.44381, saving model to model_part2.hdf5

Epoch 00270: loss improved from 0.44381 to 0.44209, saving model to model_part2.hdf5

Epoch 00271: loss improved from 0.44209 to 0.43795, saving model to model_part2.hdf5

Epoch 00272: loss improved from 0.43795 to 0.43565, saving model to model_part2.hdf5

Epoch 00273: loss improved from 0.43565 to 0.43278, saving model to model_part2.hdf5

Epoch 00274: loss improved from 0.43278 to 0.43031, saving model to model_part2.hdf5

Epoch 00275: loss improved from 0.43031 to 0.42790, saving model to model_part2.hdf5

Epoch 00276: loss improved from 0.42790 to 0.42550, saving model to model_part2.hdf5

Epoch 00277: loss improved from 0.42550 to 0.42354, saving model to model_part2.hdf5

Epoch 00278: loss improved from 0.42354 to 0.42108, saving model to model_part2.hdf5

Epoch 00279: loss improved from 0.42108 to 0.41963, saving model to model_part2.hdf5

Epoch 00280: loss improved from 0.41963 to 0.41685, saving model to model_part2.hdf5

Epoch 00281: loss improved from 0.41685 to 0.41533, saving model to model_part2.hdf5

Epoch 00282: loss improved from 0.41533 to 0.41419, saving model to model_part2.hdf5

Epoch 00283: loss improved from 0.41419 to 0.41294, saving model to model_part2.hdf5

Epoch 00284: loss improved from 0.41294 to 0.40894, saving model to model_part2.hdf5

Epoch 00285: loss improved from 0.40894 to 0.40684, saving model to model_part2.hdf5

Epoch 00286: loss improved from 0.40684 to 0.40349, saving model to model_part2.hdf5

Epoch 00287: loss improved from 0.40349 to 0.40108, saving model to model_part2.hdf5

Epoch 00288: loss improved from 0.40108 to 0.39815, saving model to model_part2.hdf5

Epoch 00289: loss improved from 0.39815 to 0.39619, saving model to model_part2.hdf5

Epoch 00290: loss improved from 0.39619 to 0.39353, saving model to model_part2.hdf5

Epoch 00291: loss improved from 0.39353 to 0.39158, saving model to model_part2.hdf5

Epoch 00292: loss improved from 0.39158 to 0.38897, saving model to model_part2.hdf5

Epoch 00293: loss improved from 0.38897 to 0.38713, saving model to model_part2.hdf5

Epoch 00294: loss improved from 0.38713 to 0.38453, saving model to model_part2.hdf5

Epoch 00295: loss improved from 0.38453 to 0.38305, saving model to model_part2.hdf5

Epoch 00296: loss improved from 0.38305 to 0.38049, saving model to model_part2.hdf5

Epoch 00297: loss improved from 0.38049 to 0.37877, saving model to model_part2.hdf5

Epoch 00298: loss improved from 0.37877 to 0.37510, saving model to model_part2.hdf5

Epoch 00299: loss improved from 0.37510 to 0.37289, saving model to model_part2.hdf5

Epoch 00300: loss improved from 0.37289 to 0.36993, saving model to model_part2.hdf5

Epoch 00301: loss improved from 0.36993 to 0.36752, saving model to model_part2.hdf5

Epoch 00302: loss improved from 0.36752 to 0.36483, saving model to model_part2.hdf5

Epoch 00303: loss improved from 0.36483 to 0.36274, saving model to model_part2.hdf5

Epoch 00304: loss improved from 0.36274 to 0.35989, saving model to model_part2.hdf5

Epoch 00305: loss improved from 0.35989 to 0.35804, saving model to model_part2.hdf5

Epoch 00306: loss improved from 0.35804 to 0.35517, saving model to model_part2.hdf5

Epoch 00307: loss improved from 0.35517 to 0.35256, saving model to model_part2.hdf5

Epoch 00308: loss improved from 0.35256 to 0.34951, saving model to model_part2.hdf5

Epoch 00309: loss improved from 0.34951 to 0.34711, saving model to model_part2.hdf5

Epoch 00310: loss improved from 0.34711 to 0.34398, saving model to model_part2.hdf5

Epoch 00311: loss improved from 0.34398 to 0.34160, saving model to model_part2.hdf5

Epoch 00312: loss improved from 0.34160 to 0.33837, saving model to model_part2.hdf5

Epoch 00313: loss improved from 0.33837 to 0.33594, saving model to model_part2.hdf5

Epoch 00314: loss improved from 0.33594 to 0.33297, saving model to model_part2.hdf5

Epoch 00315: loss improved from 0.33297 to 0.33065, saving model to model_part2.hdf5

Epoch 00316: loss improved from 0.33065 to 0.32782, saving model to model_part2.hdf5

Epoch 00317: loss improved from 0.32782 to 0.32581, saving model to model_part2.hdf5

Epoch 00318: loss improved from 0.32581 to 0.32283, saving model to model_part2.hdf5

Epoch 00319: loss improved from 0.32283 to 0.32071, saving model to model_part2.hdf5

Epoch 00320: loss improved from 0.32071 to 0.31779, saving model to model_part2.hdf5

Epoch 00321: loss improved from 0.31779 to 0.31561, saving model to model_part2.hdf5

Epoch 00322: loss improved from 0.31561 to 0.31282, saving model to model_part2.hdf5

Epoch 00323: loss improved from 0.31282 to 0.31056, saving model to model_part2.hdf5

Epoch 00324: loss improved from 0.31056 to 0.30759, saving model to model_part2.hdf5

Epoch 00325: loss improved from 0.30759 to 0.30544, saving model to model_part2.hdf5

Epoch 00326: loss improved from 0.30544 to 0.30260, saving model to model_part2.hdf5

Epoch 00327: loss improved from 0.30260 to 0.30051, saving model to model_part2.hdf5

Epoch 00328: loss improved from 0.30051 to 0.29772, saving model to model_part2.hdf5

Epoch 00329: loss improved from 0.29772 to 0.29566, saving model to model_part2.hdf5

Epoch 00330: loss improved from 0.29566 to 0.29283, saving model to model_part2.hdf5

Epoch 00331: loss improved from 0.29283 to 0.29083, saving model to model_part2.hdf5

Epoch 00332: loss improved from 0.29083 to 0.28803, saving model to model_part2.hdf5

Epoch 00333: loss improved from 0.28803 to 0.28599, saving model to model_part2.hdf5

Epoch 00334: loss improved from 0.28599 to 0.28322, saving model to model_part2.hdf5

Epoch 00335: loss improved from 0.28322 to 0.28119, saving model to model_part2.hdf5

Epoch 00336: loss improved from 0.28119 to 0.27847, saving model to model_part2.hdf5

Epoch 00337: loss improved from 0.27847 to 0.27660, saving model to model_part2.hdf5

Epoch 00338: loss improved from 0.27660 to 0.27378, saving model to model_part2.hdf5

Epoch 00339: loss improved from 0.27378 to 0.27205, saving model to model_part2.hdf5

Epoch 00340: loss improved from 0.27205 to 0.26904, saving model to model_part2.hdf5

Epoch 00341: loss improved from 0.26904 to 0.26705, saving model to model_part2.hdf5

Epoch 00342: loss improved from 0.26705 to 0.26435, saving model to model_part2.hdf5

Epoch 00343: loss improved from 0.26435 to 0.26245, saving model to model_part2.hdf5

Epoch 00344: loss improved from 0.26245 to 0.25983, saving model to model_part2.hdf5

Epoch 00345: loss improved from 0.25983 to 0.25832, saving model to model_part2.hdf5

Epoch 00346: loss improved from 0.25832 to 0.25546, saving model to model_part2.hdf5

Epoch 00347: loss improved from 0.25546 to 0.25359, saving model to model_part2.hdf5

Epoch 00348: loss improved from 0.25359 to 0.25083, saving model to model_part2.hdf5

Epoch 00349: loss improved from 0.25083 to 0.24935, saving model to model_part2.hdf5

Epoch 00350: loss improved from 0.24935 to 0.24638, saving model to model_part2.hdf5

Epoch 00351: loss improved from 0.24638 to 0.24453, saving model to model_part2.hdf5

Epoch 00352: loss improved from 0.24453 to 0.24176, saving model to model_part2.hdf5

Epoch 00353: loss improved from 0.24176 to 0.24049, saving model to model_part2.hdf5

Epoch 00354: loss improved from 0.24049 to 0.23768, saving model to model_part2.hdf5

Epoch 00355: loss improved from 0.23768 to 0.23602, saving model to model_part2.hdf5

Epoch 00356: loss improved from 0.23602 to 0.23339, saving model to model_part2.hdf5

Epoch 00357: loss improved from 0.23339 to 0.23247, saving model to model_part2.hdf5

Epoch 00358: loss improved from 0.23247 to 0.22914, saving model to model_part2.hdf5

Epoch 00359: loss improved from 0.22914 to 0.22749, saving model to model_part2.hdf5

Epoch 00360: loss improved from 0.22749 to 0.22454, saving model to model_part2.hdf5

Epoch 00361: loss improved from 0.22454 to 0.22281, saving model to model_part2.hdf5

Epoch 00362: loss improved from 0.22281 to 0.22019, saving model to model_part2.hdf5

Epoch 00363: loss improved from 0.22019 to 0.21931, saving model to model_part2.hdf5

Epoch 00364: loss improved from 0.21931 to 0.21652, saving model to model_part2.hdf5

Epoch 00365: loss improved from 0.21652 to 0.21501, saving model to model_part2.hdf5

Epoch 00366: loss improved from 0.21501 to 0.21233, saving model to model_part2.hdf5

Epoch 00367: loss improved from 0.21233 to 0.21102, saving model to model_part2.hdf5

Epoch 00368: loss improved from 0.21102 to 0.20805, saving model to model_part2.hdf5

Epoch 00369: loss improved from 0.20805 to 0.20722, saving model to model_part2.hdf5

Epoch 00370: loss improved from 0.20722 to 0.20403, saving model to model_part2.hdf5

Epoch 00371: loss improved from 0.20403 to 0.20259, saving model to model_part2.hdf5

Epoch 00372: loss improved from 0.20259 to 0.19966, saving model to model_part2.hdf5

Epoch 00373: loss improved from 0.19966 to 0.19824, saving model to model_part2.hdf5

Epoch 00374: loss improved from 0.19824 to 0.19553, saving model to model_part2.hdf5

Epoch 00375: loss improved from 0.19553 to 0.19486, saving model to model_part2.hdf5

Epoch 00376: loss improved from 0.19486 to 0.19185, saving model to model_part2.hdf5

Epoch 00377: loss improved from 0.19185 to 0.19081, saving model to model_part2.hdf5

Epoch 00378: loss improved from 0.19081 to 0.18782, saving model to model_part2.hdf5

Epoch 00379: loss improved from 0.18782 to 0.18583, saving model to model_part2.hdf5

Epoch 00380: loss improved from 0.18583 to 0.18331, saving model to model_part2.hdf5

Epoch 00381: loss improved from 0.18331 to 0.18109, saving model to model_part2.hdf5

Epoch 00382: loss improved from 0.18109 to 0.17909, saving model to model_part2.hdf5
Testing the model
45/45 [==============================] - 0s 823us/step
====================================================

====================================================
Percent Training Size  0.4
Training the Model

Epoch 00001: loss improved from inf to 1.09134, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.09134 to 1.08356, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.08356 to 1.07912, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.07912 to 1.07655, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.07655 to 1.07479, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.07479 to 1.07109, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.07109 to 1.06957, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.06957 to 1.06702, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.06702 to 1.06499, saving model to model_part2.hdf5

Epoch 00010: loss improved from 1.06499 to 1.06277, saving model to model_part2.hdf5

Epoch 00011: loss improved from 1.06277 to 1.06059, saving model to model_part2.hdf5

Epoch 00012: loss improved from 1.06059 to 1.05977, saving model to model_part2.hdf5

Epoch 00013: loss improved from 1.05977 to 1.05680, saving model to model_part2.hdf5

Epoch 00014: loss improved from 1.05680 to 1.05375, saving model to model_part2.hdf5

Epoch 00015: loss improved from 1.05375 to 1.05229, saving model to model_part2.hdf5

Epoch 00016: loss improved from 1.05229 to 1.04985, saving model to model_part2.hdf5

Epoch 00017: loss improved from 1.04985 to 1.04729, saving model to model_part2.hdf5

Epoch 00018: loss improved from 1.04729 to 1.04485, saving model to model_part2.hdf5

Epoch 00019: loss improved from 1.04485 to 1.04364, saving model to model_part2.hdf5

Epoch 00020: loss improved from 1.04364 to 1.04035, saving model to model_part2.hdf5

Epoch 00021: loss improved from 1.04035 to 1.03895, saving model to model_part2.hdf5

Epoch 00022: loss improved from 1.03895 to 1.03455, saving model to model_part2.hdf5

Epoch 00023: loss improved from 1.03455 to 1.03169, saving model to model_part2.hdf5

Epoch 00024: loss improved from 1.03169 to 1.02790, saving model to model_part2.hdf5

Epoch 00025: loss improved from 1.02790 to 1.02443, saving model to model_part2.hdf5

Epoch 00026: loss improved from 1.02443 to 1.02157, saving model to model_part2.hdf5

Epoch 00027: loss improved from 1.02157 to 1.01770, saving model to model_part2.hdf5

Epoch 00028: loss improved from 1.01770 to 1.01291, saving model to model_part2.hdf5

Epoch 00029: loss improved from 1.01291 to 1.01037, saving model to model_part2.hdf5

Epoch 00030: loss improved from 1.01037 to 1.00625, saving model to model_part2.hdf5

Epoch 00031: loss improved from 1.00625 to 1.00120, saving model to model_part2.hdf5

Epoch 00032: loss improved from 1.00120 to 1.00018, saving model to model_part2.hdf5

Epoch 00033: loss improved from 1.00018 to 0.99342, saving model to model_part2.hdf5

Epoch 00034: loss improved from 0.99342 to 0.98945, saving model to model_part2.hdf5

Epoch 00035: loss improved from 0.98945 to 0.98419, saving model to model_part2.hdf5

Epoch 00036: loss improved from 0.98419 to 0.98063, saving model to model_part2.hdf5

Epoch 00037: loss improved from 0.98063 to 0.97690, saving model to model_part2.hdf5

Epoch 00038: loss improved from 0.97690 to 0.97214, saving model to model_part2.hdf5

Epoch 00039: loss improved from 0.97214 to 0.96680, saving model to model_part2.hdf5

Epoch 00040: loss improved from 0.96680 to 0.96202, saving model to model_part2.hdf5

Epoch 00041: loss improved from 0.96202 to 0.95790, saving model to model_part2.hdf5

Epoch 00042: loss improved from 0.95790 to 0.95388, saving model to model_part2.hdf5

Epoch 00043: loss improved from 0.95388 to 0.94794, saving model to model_part2.hdf5

Epoch 00044: loss improved from 0.94794 to 0.94424, saving model to model_part2.hdf5

Epoch 00045: loss improved from 0.94424 to 0.93969, saving model to model_part2.hdf5

Epoch 00046: loss improved from 0.93969 to 0.93350, saving model to model_part2.hdf5

Epoch 00047: loss improved from 0.93350 to 0.92489, saving model to model_part2.hdf5

Epoch 00048: loss improved from 0.92489 to 0.92056, saving model to model_part2.hdf5

Epoch 00049: loss improved from 0.92056 to 0.91336, saving model to model_part2.hdf5

Epoch 00050: loss improved from 0.91336 to 0.90841, saving model to model_part2.hdf5

Epoch 00051: loss improved from 0.90841 to 0.90210, saving model to model_part2.hdf5

Epoch 00052: loss improved from 0.90210 to 0.89744, saving model to model_part2.hdf5

Epoch 00053: loss improved from 0.89744 to 0.89645, saving model to model_part2.hdf5

Epoch 00054: loss improved from 0.89645 to 0.88836, saving model to model_part2.hdf5

Epoch 00055: loss improved from 0.88836 to 0.87968, saving model to model_part2.hdf5

Epoch 00056: loss improved from 0.87968 to 0.87143, saving model to model_part2.hdf5

Epoch 00057: loss improved from 0.87143 to 0.86718, saving model to model_part2.hdf5

Epoch 00058: loss improved from 0.86718 to 0.85925, saving model to model_part2.hdf5

Epoch 00059: loss improved from 0.85925 to 0.85353, saving model to model_part2.hdf5

Epoch 00060: loss improved from 0.85353 to 0.84770, saving model to model_part2.hdf5

Epoch 00061: loss improved from 0.84770 to 0.84655, saving model to model_part2.hdf5

Epoch 00062: loss improved from 0.84655 to 0.83344, saving model to model_part2.hdf5

Epoch 00063: loss improved from 0.83344 to 0.83260, saving model to model_part2.hdf5

Epoch 00064: loss improved from 0.83260 to 0.82425, saving model to model_part2.hdf5

Epoch 00065: loss improved from 0.82425 to 0.81927, saving model to model_part2.hdf5

Epoch 00066: loss improved from 0.81927 to 0.81416, saving model to model_part2.hdf5

Epoch 00067: loss did not improve from 0.81416

Epoch 00068: loss improved from 0.81416 to 0.80668, saving model to model_part2.hdf5

Epoch 00069: loss improved from 0.80668 to 0.80159, saving model to model_part2.hdf5

Epoch 00070: loss improved from 0.80159 to 0.79684, saving model to model_part2.hdf5

Epoch 00071: loss improved from 0.79684 to 0.79304, saving model to model_part2.hdf5

Epoch 00072: loss improved from 0.79304 to 0.78824, saving model to model_part2.hdf5

Epoch 00073: loss improved from 0.78824 to 0.78063, saving model to model_part2.hdf5

Epoch 00074: loss improved from 0.78063 to 0.77841, saving model to model_part2.hdf5

Epoch 00075: loss improved from 0.77841 to 0.76897, saving model to model_part2.hdf5

Epoch 00076: loss improved from 0.76897 to 0.76679, saving model to model_part2.hdf5

Epoch 00077: loss improved from 0.76679 to 0.75884, saving model to model_part2.hdf5

Epoch 00078: loss did not improve from 0.75884

Epoch 00079: loss improved from 0.75884 to 0.74991, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.74991 to 0.74595, saving model to model_part2.hdf5

Epoch 00081: loss did not improve from 0.74595

Epoch 00082: loss improved from 0.74595 to 0.73940, saving model to model_part2.hdf5

Epoch 00083: loss did not improve from 0.73940

Epoch 00084: loss improved from 0.73940 to 0.73084, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.73084 to 0.72603, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.72603 to 0.72162, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.72162 to 0.71557, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.71557 to 0.71308, saving model to model_part2.hdf5

Epoch 00089: loss did not improve from 0.71308

Epoch 00090: loss improved from 0.71308 to 0.70863, saving model to model_part2.hdf5

Epoch 00091: loss did not improve from 0.70863

Epoch 00092: loss improved from 0.70863 to 0.69337, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.69337 to 0.69096, saving model to model_part2.hdf5

Epoch 00094: loss did not improve from 0.69096

Epoch 00095: loss improved from 0.69096 to 0.67363, saving model to model_part2.hdf5

Epoch 00096: loss did not improve from 0.67363

Epoch 00097: loss did not improve from 0.67363

Epoch 00098: loss improved from 0.67363 to 0.66549, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.66549 to 0.65719, saving model to model_part2.hdf5

Epoch 00100: loss improved from 0.65719 to 0.65164, saving model to model_part2.hdf5

Epoch 00101: loss improved from 0.65164 to 0.64649, saving model to model_part2.hdf5

Epoch 00102: loss improved from 0.64649 to 0.64623, saving model to model_part2.hdf5

Epoch 00103: loss improved from 0.64623 to 0.63659, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.63659 to 0.63252, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.63252 to 0.62939, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.62939 to 0.62404, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.62404 to 0.62075, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.62075 to 0.61632, saving model to model_part2.hdf5

Epoch 00109: loss did not improve from 0.61632

Epoch 00110: loss did not improve from 0.61632

Epoch 00111: loss improved from 0.61632 to 0.60888, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.60888 to 0.59501, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.59501 to 0.58969, saving model to model_part2.hdf5

Epoch 00114: loss did not improve from 0.58969

Epoch 00115: loss improved from 0.58969 to 0.58957, saving model to model_part2.hdf5

Epoch 00116: loss did not improve from 0.58957

Epoch 00117: loss improved from 0.58957 to 0.58203, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.58203 to 0.56815, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.56815 to 0.56372, saving model to model_part2.hdf5

Epoch 00120: loss improved from 0.56372 to 0.56024, saving model to model_part2.hdf5

Epoch 00121: loss did not improve from 0.56024

Epoch 00122: loss improved from 0.56024 to 0.55232, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.55232 to 0.54867, saving model to model_part2.hdf5

Epoch 00124: loss improved from 0.54867 to 0.54718, saving model to model_part2.hdf5

Epoch 00125: loss improved from 0.54718 to 0.53999, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.53999 to 0.53832, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.53832 to 0.53501, saving model to model_part2.hdf5

Epoch 00128: loss improved from 0.53501 to 0.52851, saving model to model_part2.hdf5

Epoch 00129: loss improved from 0.52851 to 0.52451, saving model to model_part2.hdf5

Epoch 00130: loss improved from 0.52451 to 0.52003, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.52003 to 0.51519, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.51519 to 0.51130, saving model to model_part2.hdf5

Epoch 00133: loss did not improve from 0.51130

Epoch 00134: loss improved from 0.51130 to 0.50595, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.50595 to 0.50112, saving model to model_part2.hdf5

Epoch 00136: loss did not improve from 0.50112

Epoch 00137: loss did not improve from 0.50112

Epoch 00138: loss did not improve from 0.50112

Epoch 00139: loss improved from 0.50112 to 0.48546, saving model to model_part2.hdf5

Epoch 00140: loss improved from 0.48546 to 0.48139, saving model to model_part2.hdf5

Epoch 00141: loss improved from 0.48139 to 0.47979, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.47979 to 0.47805, saving model to model_part2.hdf5

Epoch 00143: loss did not improve from 0.47805

Epoch 00144: loss improved from 0.47805 to 0.47144, saving model to model_part2.hdf5

Epoch 00145: loss improved from 0.47144 to 0.46974, saving model to model_part2.hdf5

Epoch 00146: loss improved from 0.46974 to 0.46169, saving model to model_part2.hdf5

Epoch 00147: loss did not improve from 0.46169

Epoch 00148: loss improved from 0.46169 to 0.45483, saving model to model_part2.hdf5

Epoch 00149: loss did not improve from 0.45483

Epoch 00150: loss improved from 0.45483 to 0.45045, saving model to model_part2.hdf5

Epoch 00151: loss improved from 0.45045 to 0.44925, saving model to model_part2.hdf5

Epoch 00152: loss did not improve from 0.44925

Epoch 00153: loss improved from 0.44925 to 0.44592, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.44592 to 0.44449, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.44449 to 0.43603, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.43603 to 0.43315, saving model to model_part2.hdf5

Epoch 00157: loss did not improve from 0.43315

Epoch 00158: loss improved from 0.43315 to 0.43131, saving model to model_part2.hdf5

Epoch 00159: loss improved from 0.43131 to 0.42118, saving model to model_part2.hdf5

Epoch 00160: loss improved from 0.42118 to 0.41778, saving model to model_part2.hdf5

Epoch 00161: loss did not improve from 0.41778

Epoch 00162: loss improved from 0.41778 to 0.41173, saving model to model_part2.hdf5

Epoch 00163: loss did not improve from 0.41173

Epoch 00164: loss did not improve from 0.41173

Epoch 00165: loss improved from 0.41173 to 0.40659, saving model to model_part2.hdf5

Epoch 00166: loss improved from 0.40659 to 0.40266, saving model to model_part2.hdf5

Epoch 00167: loss improved from 0.40266 to 0.40105, saving model to model_part2.hdf5

Epoch 00168: loss improved from 0.40105 to 0.39702, saving model to model_part2.hdf5

Epoch 00169: loss did not improve from 0.39702

Epoch 00170: loss did not improve from 0.39702

Epoch 00171: loss improved from 0.39702 to 0.39470, saving model to model_part2.hdf5

Epoch 00172: loss did not improve from 0.39470

Epoch 00173: loss improved from 0.39470 to 0.39128, saving model to model_part2.hdf5

Epoch 00174: loss did not improve from 0.39128

Epoch 00175: loss improved from 0.39128 to 0.38074, saving model to model_part2.hdf5

Epoch 00176: loss improved from 0.38074 to 0.37586, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.37586 to 0.37386, saving model to model_part2.hdf5

Epoch 00178: loss did not improve from 0.37386

Epoch 00179: loss did not improve from 0.37386

Epoch 00180: loss did not improve from 0.37386
Testing the model
45/45 [==============================] - 0s 1ms/step
====================================================

====================================================
Percent Training Size  0.5
Training the Model

Epoch 00001: loss improved from inf to 1.09580, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.09580 to 1.09373, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.09373 to 1.09161, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.09161 to 1.08900, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.08900 to 1.08688, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.08688 to 1.08499, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.08499 to 1.08185, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.08185 to 1.07810, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.07810 to 1.07574, saving model to model_part2.hdf5

Epoch 00010: loss improved from 1.07574 to 1.07248, saving model to model_part2.hdf5

Epoch 00011: loss improved from 1.07248 to 1.07111, saving model to model_part2.hdf5

Epoch 00012: loss improved from 1.07111 to 1.06768, saving model to model_part2.hdf5

Epoch 00013: loss improved from 1.06768 to 1.06485, saving model to model_part2.hdf5

Epoch 00014: loss improved from 1.06485 to 1.06253, saving model to model_part2.hdf5

Epoch 00015: loss improved from 1.06253 to 1.06054, saving model to model_part2.hdf5

Epoch 00016: loss improved from 1.06054 to 1.05771, saving model to model_part2.hdf5

Epoch 00017: loss improved from 1.05771 to 1.05676, saving model to model_part2.hdf5

Epoch 00018: loss improved from 1.05676 to 1.05395, saving model to model_part2.hdf5

Epoch 00019: loss improved from 1.05395 to 1.05029, saving model to model_part2.hdf5

Epoch 00020: loss improved from 1.05029 to 1.04769, saving model to model_part2.hdf5

Epoch 00021: loss improved from 1.04769 to 1.04491, saving model to model_part2.hdf5

Epoch 00022: loss improved from 1.04491 to 1.04197, saving model to model_part2.hdf5

Epoch 00023: loss improved from 1.04197 to 1.03910, saving model to model_part2.hdf5

Epoch 00024: loss improved from 1.03910 to 1.03703, saving model to model_part2.hdf5

Epoch 00025: loss improved from 1.03703 to 1.03354, saving model to model_part2.hdf5

Epoch 00026: loss improved from 1.03354 to 1.03029, saving model to model_part2.hdf5

Epoch 00027: loss improved from 1.03029 to 1.02719, saving model to model_part2.hdf5

Epoch 00028: loss improved from 1.02719 to 1.02266, saving model to model_part2.hdf5

Epoch 00029: loss improved from 1.02266 to 1.01915, saving model to model_part2.hdf5

Epoch 00030: loss improved from 1.01915 to 1.01637, saving model to model_part2.hdf5

Epoch 00031: loss improved from 1.01637 to 1.01363, saving model to model_part2.hdf5

Epoch 00032: loss improved from 1.01363 to 1.00943, saving model to model_part2.hdf5

Epoch 00033: loss improved from 1.00943 to 1.00580, saving model to model_part2.hdf5

Epoch 00034: loss improved from 1.00580 to 1.00226, saving model to model_part2.hdf5

Epoch 00035: loss improved from 1.00226 to 0.99811, saving model to model_part2.hdf5

Epoch 00036: loss improved from 0.99811 to 0.99565, saving model to model_part2.hdf5

Epoch 00037: loss improved from 0.99565 to 0.99109, saving model to model_part2.hdf5

Epoch 00038: loss improved from 0.99109 to 0.98800, saving model to model_part2.hdf5

Epoch 00039: loss improved from 0.98800 to 0.98344, saving model to model_part2.hdf5

Epoch 00040: loss improved from 0.98344 to 0.97951, saving model to model_part2.hdf5

Epoch 00041: loss improved from 0.97951 to 0.97554, saving model to model_part2.hdf5

Epoch 00042: loss improved from 0.97554 to 0.97060, saving model to model_part2.hdf5

Epoch 00043: loss improved from 0.97060 to 0.96644, saving model to model_part2.hdf5

Epoch 00044: loss improved from 0.96644 to 0.96143, saving model to model_part2.hdf5

Epoch 00045: loss improved from 0.96143 to 0.95781, saving model to model_part2.hdf5

Epoch 00046: loss improved from 0.95781 to 0.95203, saving model to model_part2.hdf5

Epoch 00047: loss improved from 0.95203 to 0.94878, saving model to model_part2.hdf5

Epoch 00048: loss improved from 0.94878 to 0.94406, saving model to model_part2.hdf5

Epoch 00049: loss improved from 0.94406 to 0.93883, saving model to model_part2.hdf5

Epoch 00050: loss improved from 0.93883 to 0.93521, saving model to model_part2.hdf5

Epoch 00051: loss improved from 0.93521 to 0.92915, saving model to model_part2.hdf5

Epoch 00052: loss improved from 0.92915 to 0.92330, saving model to model_part2.hdf5

Epoch 00053: loss improved from 0.92330 to 0.91877, saving model to model_part2.hdf5

Epoch 00054: loss improved from 0.91877 to 0.91225, saving model to model_part2.hdf5

Epoch 00055: loss improved from 0.91225 to 0.90573, saving model to model_part2.hdf5

Epoch 00056: loss improved from 0.90573 to 0.90002, saving model to model_part2.hdf5

Epoch 00057: loss improved from 0.90002 to 0.89499, saving model to model_part2.hdf5

Epoch 00058: loss improved from 0.89499 to 0.88742, saving model to model_part2.hdf5

Epoch 00059: loss improved from 0.88742 to 0.88151, saving model to model_part2.hdf5

Epoch 00060: loss improved from 0.88151 to 0.87458, saving model to model_part2.hdf5

Epoch 00061: loss improved from 0.87458 to 0.86940, saving model to model_part2.hdf5

Epoch 00062: loss improved from 0.86940 to 0.86354, saving model to model_part2.hdf5

Epoch 00063: loss improved from 0.86354 to 0.85657, saving model to model_part2.hdf5

Epoch 00064: loss improved from 0.85657 to 0.85054, saving model to model_part2.hdf5

Epoch 00065: loss improved from 0.85054 to 0.84432, saving model to model_part2.hdf5

Epoch 00066: loss improved from 0.84432 to 0.83718, saving model to model_part2.hdf5

Epoch 00067: loss improved from 0.83718 to 0.82956, saving model to model_part2.hdf5

Epoch 00068: loss improved from 0.82956 to 0.82250, saving model to model_part2.hdf5

Epoch 00069: loss improved from 0.82250 to 0.81751, saving model to model_part2.hdf5

Epoch 00070: loss improved from 0.81751 to 0.81391, saving model to model_part2.hdf5

Epoch 00071: loss improved from 0.81391 to 0.80440, saving model to model_part2.hdf5

Epoch 00072: loss improved from 0.80440 to 0.79760, saving model to model_part2.hdf5

Epoch 00073: loss improved from 0.79760 to 0.79162, saving model to model_part2.hdf5

Epoch 00074: loss improved from 0.79162 to 0.78438, saving model to model_part2.hdf5

Epoch 00075: loss improved from 0.78438 to 0.77794, saving model to model_part2.hdf5

Epoch 00076: loss improved from 0.77794 to 0.77070, saving model to model_part2.hdf5

Epoch 00077: loss improved from 0.77070 to 0.76458, saving model to model_part2.hdf5

Epoch 00078: loss improved from 0.76458 to 0.75719, saving model to model_part2.hdf5

Epoch 00079: loss improved from 0.75719 to 0.74988, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.74988 to 0.74224, saving model to model_part2.hdf5

Epoch 00081: loss improved from 0.74224 to 0.73450, saving model to model_part2.hdf5

Epoch 00082: loss improved from 0.73450 to 0.72696, saving model to model_part2.hdf5

Epoch 00083: loss improved from 0.72696 to 0.71949, saving model to model_part2.hdf5

Epoch 00084: loss improved from 0.71949 to 0.71243, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.71243 to 0.70420, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.70420 to 0.69564, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.69564 to 0.68852, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.68852 to 0.68170, saving model to model_part2.hdf5

Epoch 00089: loss improved from 0.68170 to 0.67511, saving model to model_part2.hdf5

Epoch 00090: loss improved from 0.67511 to 0.67095, saving model to model_part2.hdf5

Epoch 00091: loss improved from 0.67095 to 0.65860, saving model to model_part2.hdf5

Epoch 00092: loss improved from 0.65860 to 0.65542, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.65542 to 0.65123, saving model to model_part2.hdf5

Epoch 00094: loss improved from 0.65123 to 0.64001, saving model to model_part2.hdf5

Epoch 00095: loss improved from 0.64001 to 0.63328, saving model to model_part2.hdf5

Epoch 00096: loss improved from 0.63328 to 0.62646, saving model to model_part2.hdf5

Epoch 00097: loss improved from 0.62646 to 0.61955, saving model to model_part2.hdf5

Epoch 00098: loss improved from 0.61955 to 0.61298, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.61298 to 0.60772, saving model to model_part2.hdf5

Epoch 00100: loss did not improve from 0.60772

Epoch 00101: loss improved from 0.60772 to 0.60060, saving model to model_part2.hdf5

Epoch 00102: loss improved from 0.60060 to 0.58771, saving model to model_part2.hdf5

Epoch 00103: loss improved from 0.58771 to 0.58273, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.58273 to 0.57779, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.57779 to 0.57380, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.57380 to 0.56673, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.56673 to 0.55945, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.55945 to 0.55583, saving model to model_part2.hdf5

Epoch 00109: loss improved from 0.55583 to 0.54840, saving model to model_part2.hdf5

Epoch 00110: loss improved from 0.54840 to 0.53921, saving model to model_part2.hdf5

Epoch 00111: loss improved from 0.53921 to 0.53286, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.53286 to 0.52609, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.52609 to 0.51869, saving model to model_part2.hdf5

Epoch 00114: loss improved from 0.51869 to 0.51357, saving model to model_part2.hdf5

Epoch 00115: loss improved from 0.51357 to 0.51047, saving model to model_part2.hdf5

Epoch 00116: loss improved from 0.51047 to 0.49985, saving model to model_part2.hdf5

Epoch 00117: loss improved from 0.49985 to 0.49508, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.49508 to 0.48724, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.48724 to 0.48480, saving model to model_part2.hdf5

Epoch 00120: loss improved from 0.48480 to 0.48428, saving model to model_part2.hdf5

Epoch 00121: loss improved from 0.48428 to 0.47644, saving model to model_part2.hdf5

Epoch 00122: loss improved from 0.47644 to 0.46577, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.46577 to 0.46093, saving model to model_part2.hdf5

Epoch 00124: loss did not improve from 0.46093

Epoch 00125: loss improved from 0.46093 to 0.44949, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.44949 to 0.44738, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.44738 to 0.43837, saving model to model_part2.hdf5

Epoch 00128: loss did not improve from 0.43837

Epoch 00129: loss did not improve from 0.43837

Epoch 00130: loss improved from 0.43837 to 0.43389, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.43389 to 0.42368, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.42368 to 0.41801, saving model to model_part2.hdf5

Epoch 00133: loss improved from 0.41801 to 0.41271, saving model to model_part2.hdf5

Epoch 00134: loss improved from 0.41271 to 0.40935, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.40935 to 0.40413, saving model to model_part2.hdf5

Epoch 00136: loss improved from 0.40413 to 0.39942, saving model to model_part2.hdf5

Epoch 00137: loss improved from 0.39942 to 0.39499, saving model to model_part2.hdf5

Epoch 00138: loss improved from 0.39499 to 0.38971, saving model to model_part2.hdf5

Epoch 00139: loss improved from 0.38971 to 0.38868, saving model to model_part2.hdf5

Epoch 00140: loss improved from 0.38868 to 0.38016, saving model to model_part2.hdf5

Epoch 00141: loss improved from 0.38016 to 0.37479, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.37479 to 0.37021, saving model to model_part2.hdf5

Epoch 00143: loss improved from 0.37021 to 0.36742, saving model to model_part2.hdf5

Epoch 00144: loss improved from 0.36742 to 0.36164, saving model to model_part2.hdf5

Epoch 00145: loss did not improve from 0.36164

Epoch 00146: loss did not improve from 0.36164

Epoch 00147: loss improved from 0.36164 to 0.34922, saving model to model_part2.hdf5

Epoch 00148: loss did not improve from 0.34922

Epoch 00149: loss did not improve from 0.34922

Epoch 00150: loss improved from 0.34922 to 0.33718, saving model to model_part2.hdf5

Epoch 00151: loss improved from 0.33718 to 0.33132, saving model to model_part2.hdf5

Epoch 00152: loss improved from 0.33132 to 0.33105, saving model to model_part2.hdf5

Epoch 00153: loss improved from 0.33105 to 0.32732, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.32732 to 0.31961, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.31961 to 0.31573, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.31573 to 0.31156, saving model to model_part2.hdf5

Epoch 00157: loss improved from 0.31156 to 0.30919, saving model to model_part2.hdf5

Epoch 00158: loss did not improve from 0.30919

Epoch 00159: loss improved from 0.30919 to 0.30265, saving model to model_part2.hdf5

Epoch 00160: loss improved from 0.30265 to 0.29664, saving model to model_part2.hdf5

Epoch 00161: loss improved from 0.29664 to 0.29513, saving model to model_part2.hdf5

Epoch 00162: loss improved from 0.29513 to 0.29415, saving model to model_part2.hdf5

Epoch 00163: loss improved from 0.29415 to 0.28491, saving model to model_part2.hdf5

Epoch 00164: loss did not improve from 0.28491

Epoch 00165: loss improved from 0.28491 to 0.28045, saving model to model_part2.hdf5

Epoch 00166: loss did not improve from 0.28045

Epoch 00167: loss improved from 0.28045 to 0.27289, saving model to model_part2.hdf5

Epoch 00168: loss improved from 0.27289 to 0.27152, saving model to model_part2.hdf5

Epoch 00169: loss did not improve from 0.27152

Epoch 00170: loss improved from 0.27152 to 0.27091, saving model to model_part2.hdf5

Epoch 00171: loss improved from 0.27091 to 0.26118, saving model to model_part2.hdf5

Epoch 00172: loss improved from 0.26118 to 0.25934, saving model to model_part2.hdf5

Epoch 00173: loss improved from 0.25934 to 0.25316, saving model to model_part2.hdf5

Epoch 00174: loss improved from 0.25316 to 0.25036, saving model to model_part2.hdf5

Epoch 00175: loss did not improve from 0.25036

Epoch 00176: loss improved from 0.25036 to 0.24514, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.24514 to 0.24094, saving model to model_part2.hdf5

Epoch 00178: loss improved from 0.24094 to 0.24055, saving model to model_part2.hdf5

Epoch 00179: loss improved from 0.24055 to 0.23437, saving model to model_part2.hdf5

Epoch 00180: loss improved from 0.23437 to 0.23403, saving model to model_part2.hdf5

Epoch 00181: loss improved from 0.23403 to 0.23115, saving model to model_part2.hdf5

Epoch 00182: loss did not improve from 0.23115

Epoch 00183: loss improved from 0.23115 to 0.22361, saving model to model_part2.hdf5

Epoch 00184: loss improved from 0.22361 to 0.22276, saving model to model_part2.hdf5

Epoch 00185: loss improved from 0.22276 to 0.21697, saving model to model_part2.hdf5

Epoch 00186: loss improved from 0.21697 to 0.21402, saving model to model_part2.hdf5

Epoch 00187: loss improved from 0.21402 to 0.21276, saving model to model_part2.hdf5

Epoch 00188: loss did not improve from 0.21276

Epoch 00189: loss improved from 0.21276 to 0.20648, saving model to model_part2.hdf5

Epoch 00190: loss did not improve from 0.20648

Epoch 00191: loss improved from 0.20648 to 0.20123, saving model to model_part2.hdf5

Epoch 00192: loss improved from 0.20123 to 0.19647, saving model to model_part2.hdf5

Epoch 00193: loss improved from 0.19647 to 0.19361, saving model to model_part2.hdf5

Epoch 00194: loss improved from 0.19361 to 0.19172, saving model to model_part2.hdf5

Epoch 00195: loss improved from 0.19172 to 0.18791, saving model to model_part2.hdf5

Epoch 00196: loss did not improve from 0.18791

Epoch 00197: loss did not improve from 0.18791

Epoch 00198: loss improved from 0.18791 to 0.17935, saving model to model_part2.hdf5

Epoch 00199: loss improved from 0.17935 to 0.17881, saving model to model_part2.hdf5

Epoch 00200: loss did not improve from 0.17881

Epoch 00201: loss improved from 0.17881 to 0.17303, saving model to model_part2.hdf5

Epoch 00202: loss did not improve from 0.17303

Epoch 00203: loss improved from 0.17303 to 0.16721, saving model to model_part2.hdf5

Epoch 00204: loss improved from 0.16721 to 0.16611, saving model to model_part2.hdf5

Epoch 00205: loss improved from 0.16611 to 0.16584, saving model to model_part2.hdf5

Epoch 00206: loss improved from 0.16584 to 0.16228, saving model to model_part2.hdf5

Epoch 00207: loss improved from 0.16228 to 0.15722, saving model to model_part2.hdf5

Epoch 00208: loss did not improve from 0.15722

Epoch 00209: loss did not improve from 0.15722

Epoch 00210: loss improved from 0.15722 to 0.15102, saving model to model_part2.hdf5

Epoch 00211: loss improved from 0.15102 to 0.14826, saving model to model_part2.hdf5

Epoch 00212: loss improved from 0.14826 to 0.14810, saving model to model_part2.hdf5
Testing the model
45/45 [==============================] - 0s 1ms/step
====================================================

====================================================
Percent Training Size  0.6
Training the Model

Epoch 00001: loss improved from inf to 1.09698, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.09698 to 1.09208, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.09208 to 1.08815, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.08815 to 1.08486, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.08486 to 1.08160, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.08160 to 1.07832, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.07832 to 1.07475, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.07475 to 1.07049, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.07049 to 1.06604, saving model to model_part2.hdf5

Epoch 00010: loss improved from 1.06604 to 1.06167, saving model to model_part2.hdf5

Epoch 00011: loss improved from 1.06167 to 1.05743, saving model to model_part2.hdf5

Epoch 00012: loss improved from 1.05743 to 1.05323, saving model to model_part2.hdf5

Epoch 00013: loss improved from 1.05323 to 1.04934, saving model to model_part2.hdf5

Epoch 00014: loss improved from 1.04934 to 1.04502, saving model to model_part2.hdf5

Epoch 00015: loss improved from 1.04502 to 1.04112, saving model to model_part2.hdf5

Epoch 00016: loss improved from 1.04112 to 1.03748, saving model to model_part2.hdf5

Epoch 00017: loss improved from 1.03748 to 1.03354, saving model to model_part2.hdf5

Epoch 00018: loss improved from 1.03354 to 1.02962, saving model to model_part2.hdf5

Epoch 00019: loss improved from 1.02962 to 1.02595, saving model to model_part2.hdf5

Epoch 00020: loss improved from 1.02595 to 1.02171, saving model to model_part2.hdf5

Epoch 00021: loss improved from 1.02171 to 1.01799, saving model to model_part2.hdf5

Epoch 00022: loss improved from 1.01799 to 1.01387, saving model to model_part2.hdf5

Epoch 00023: loss improved from 1.01387 to 1.00981, saving model to model_part2.hdf5

Epoch 00024: loss improved from 1.00981 to 1.00562, saving model to model_part2.hdf5

Epoch 00025: loss improved from 1.00562 to 1.00220, saving model to model_part2.hdf5

Epoch 00026: loss improved from 1.00220 to 0.99856, saving model to model_part2.hdf5

Epoch 00027: loss improved from 0.99856 to 0.99479, saving model to model_part2.hdf5

Epoch 00028: loss improved from 0.99479 to 0.99103, saving model to model_part2.hdf5

Epoch 00029: loss improved from 0.99103 to 0.98806, saving model to model_part2.hdf5

Epoch 00030: loss improved from 0.98806 to 0.98416, saving model to model_part2.hdf5

Epoch 00031: loss improved from 0.98416 to 0.98331, saving model to model_part2.hdf5

Epoch 00032: loss improved from 0.98331 to 0.97784, saving model to model_part2.hdf5

Epoch 00033: loss improved from 0.97784 to 0.97426, saving model to model_part2.hdf5

Epoch 00034: loss improved from 0.97426 to 0.97086, saving model to model_part2.hdf5

Epoch 00035: loss improved from 0.97086 to 0.96745, saving model to model_part2.hdf5

Epoch 00036: loss improved from 0.96745 to 0.96408, saving model to model_part2.hdf5

Epoch 00037: loss improved from 0.96408 to 0.96058, saving model to model_part2.hdf5

Epoch 00038: loss improved from 0.96058 to 0.95698, saving model to model_part2.hdf5

Epoch 00039: loss improved from 0.95698 to 0.95296, saving model to model_part2.hdf5

Epoch 00040: loss improved from 0.95296 to 0.95046, saving model to model_part2.hdf5

Epoch 00041: loss improved from 0.95046 to 0.94607, saving model to model_part2.hdf5

Epoch 00042: loss improved from 0.94607 to 0.94282, saving model to model_part2.hdf5

Epoch 00043: loss improved from 0.94282 to 0.93969, saving model to model_part2.hdf5

Epoch 00044: loss improved from 0.93969 to 0.93582, saving model to model_part2.hdf5

Epoch 00045: loss improved from 0.93582 to 0.93285, saving model to model_part2.hdf5

Epoch 00046: loss improved from 0.93285 to 0.92971, saving model to model_part2.hdf5

Epoch 00047: loss improved from 0.92971 to 0.92631, saving model to model_part2.hdf5

Epoch 00048: loss improved from 0.92631 to 0.92541, saving model to model_part2.hdf5

Epoch 00049: loss improved from 0.92541 to 0.91997, saving model to model_part2.hdf5

Epoch 00050: loss improved from 0.91997 to 0.91684, saving model to model_part2.hdf5

Epoch 00051: loss improved from 0.91684 to 0.91514, saving model to model_part2.hdf5

Epoch 00052: loss improved from 0.91514 to 0.91110, saving model to model_part2.hdf5

Epoch 00053: loss improved from 0.91110 to 0.90778, saving model to model_part2.hdf5

Epoch 00054: loss improved from 0.90778 to 0.90414, saving model to model_part2.hdf5

Epoch 00055: loss improved from 0.90414 to 0.90092, saving model to model_part2.hdf5

Epoch 00056: loss improved from 0.90092 to 0.89765, saving model to model_part2.hdf5

Epoch 00057: loss improved from 0.89765 to 0.89491, saving model to model_part2.hdf5

Epoch 00058: loss improved from 0.89491 to 0.89125, saving model to model_part2.hdf5

Epoch 00059: loss improved from 0.89125 to 0.88795, saving model to model_part2.hdf5

Epoch 00060: loss improved from 0.88795 to 0.88581, saving model to model_part2.hdf5

Epoch 00061: loss improved from 0.88581 to 0.88202, saving model to model_part2.hdf5

Epoch 00062: loss improved from 0.88202 to 0.87834, saving model to model_part2.hdf5

Epoch 00063: loss improved from 0.87834 to 0.87597, saving model to model_part2.hdf5

Epoch 00064: loss improved from 0.87597 to 0.87331, saving model to model_part2.hdf5

Epoch 00065: loss improved from 0.87331 to 0.86981, saving model to model_part2.hdf5

Epoch 00066: loss improved from 0.86981 to 0.86691, saving model to model_part2.hdf5

Epoch 00067: loss improved from 0.86691 to 0.86385, saving model to model_part2.hdf5

Epoch 00068: loss improved from 0.86385 to 0.86244, saving model to model_part2.hdf5

Epoch 00069: loss improved from 0.86244 to 0.85956, saving model to model_part2.hdf5

Epoch 00070: loss improved from 0.85956 to 0.85657, saving model to model_part2.hdf5

Epoch 00071: loss improved from 0.85657 to 0.85408, saving model to model_part2.hdf5

Epoch 00072: loss improved from 0.85408 to 0.85129, saving model to model_part2.hdf5

Epoch 00073: loss improved from 0.85129 to 0.85000, saving model to model_part2.hdf5

Epoch 00074: loss improved from 0.85000 to 0.84605, saving model to model_part2.hdf5

Epoch 00075: loss did not improve from 0.84605

Epoch 00076: loss improved from 0.84605 to 0.84297, saving model to model_part2.hdf5

Epoch 00077: loss improved from 0.84297 to 0.84018, saving model to model_part2.hdf5

Epoch 00078: loss improved from 0.84018 to 0.83831, saving model to model_part2.hdf5

Epoch 00079: loss improved from 0.83831 to 0.83628, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.83628 to 0.83420, saving model to model_part2.hdf5

Epoch 00081: loss improved from 0.83420 to 0.83166, saving model to model_part2.hdf5

Epoch 00082: loss improved from 0.83166 to 0.82983, saving model to model_part2.hdf5

Epoch 00083: loss improved from 0.82983 to 0.82690, saving model to model_part2.hdf5

Epoch 00084: loss improved from 0.82690 to 0.82470, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.82470 to 0.82307, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.82307 to 0.82073, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.82073 to 0.81828, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.81828 to 0.81620, saving model to model_part2.hdf5

Epoch 00089: loss improved from 0.81620 to 0.81356, saving model to model_part2.hdf5

Epoch 00090: loss improved from 0.81356 to 0.81176, saving model to model_part2.hdf5

Epoch 00091: loss improved from 0.81176 to 0.80993, saving model to model_part2.hdf5

Epoch 00092: loss improved from 0.80993 to 0.80733, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.80733 to 0.80575, saving model to model_part2.hdf5

Epoch 00094: loss improved from 0.80575 to 0.80390, saving model to model_part2.hdf5

Epoch 00095: loss improved from 0.80390 to 0.80209, saving model to model_part2.hdf5

Epoch 00096: loss improved from 0.80209 to 0.80010, saving model to model_part2.hdf5

Epoch 00097: loss improved from 0.80010 to 0.79821, saving model to model_part2.hdf5

Epoch 00098: loss improved from 0.79821 to 0.79715, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.79715 to 0.79504, saving model to model_part2.hdf5

Epoch 00100: loss improved from 0.79504 to 0.79337, saving model to model_part2.hdf5

Epoch 00101: loss improved from 0.79337 to 0.79209, saving model to model_part2.hdf5

Epoch 00102: loss improved from 0.79209 to 0.79033, saving model to model_part2.hdf5

Epoch 00103: loss improved from 0.79033 to 0.79003, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.79003 to 0.78705, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.78705 to 0.78588, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.78588 to 0.78366, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.78366 to 0.78314, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.78314 to 0.78214, saving model to model_part2.hdf5

Epoch 00109: loss improved from 0.78214 to 0.78042, saving model to model_part2.hdf5

Epoch 00110: loss improved from 0.78042 to 0.77960, saving model to model_part2.hdf5

Epoch 00111: loss improved from 0.77960 to 0.77765, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.77765 to 0.77654, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.77654 to 0.77492, saving model to model_part2.hdf5

Epoch 00114: loss improved from 0.77492 to 0.77362, saving model to model_part2.hdf5

Epoch 00115: loss improved from 0.77362 to 0.77214, saving model to model_part2.hdf5

Epoch 00116: loss improved from 0.77214 to 0.77095, saving model to model_part2.hdf5

Epoch 00117: loss improved from 0.77095 to 0.76973, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.76973 to 0.76884, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.76884 to 0.76677, saving model to model_part2.hdf5

Epoch 00120: loss did not improve from 0.76677

Epoch 00121: loss improved from 0.76677 to 0.76488, saving model to model_part2.hdf5

Epoch 00122: loss improved from 0.76488 to 0.76397, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.76397 to 0.76288, saving model to model_part2.hdf5

Epoch 00124: loss improved from 0.76288 to 0.76232, saving model to model_part2.hdf5

Epoch 00125: loss improved from 0.76232 to 0.76102, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.76102 to 0.75965, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.75965 to 0.75900, saving model to model_part2.hdf5

Epoch 00128: loss improved from 0.75900 to 0.75741, saving model to model_part2.hdf5

Epoch 00129: loss improved from 0.75741 to 0.75615, saving model to model_part2.hdf5

Epoch 00130: loss improved from 0.75615 to 0.75475, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.75475 to 0.75387, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.75387 to 0.75325, saving model to model_part2.hdf5

Epoch 00133: loss improved from 0.75325 to 0.75267, saving model to model_part2.hdf5

Epoch 00134: loss improved from 0.75267 to 0.75150, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.75150 to 0.75031, saving model to model_part2.hdf5

Epoch 00136: loss improved from 0.75031 to 0.74951, saving model to model_part2.hdf5

Epoch 00137: loss improved from 0.74951 to 0.74817, saving model to model_part2.hdf5

Epoch 00138: loss improved from 0.74817 to 0.74780, saving model to model_part2.hdf5

Epoch 00139: loss improved from 0.74780 to 0.74635, saving model to model_part2.hdf5

Epoch 00140: loss did not improve from 0.74635

Epoch 00141: loss improved from 0.74635 to 0.74537, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.74537 to 0.74404, saving model to model_part2.hdf5

Epoch 00143: loss improved from 0.74404 to 0.74284, saving model to model_part2.hdf5

Epoch 00144: loss improved from 0.74284 to 0.74248, saving model to model_part2.hdf5

Epoch 00145: loss improved from 0.74248 to 0.74144, saving model to model_part2.hdf5

Epoch 00146: loss improved from 0.74144 to 0.74022, saving model to model_part2.hdf5

Epoch 00147: loss improved from 0.74022 to 0.73993, saving model to model_part2.hdf5

Epoch 00148: loss improved from 0.73993 to 0.73866, saving model to model_part2.hdf5

Epoch 00149: loss improved from 0.73866 to 0.73770, saving model to model_part2.hdf5

Epoch 00150: loss did not improve from 0.73770

Epoch 00151: loss improved from 0.73770 to 0.73687, saving model to model_part2.hdf5

Epoch 00152: loss improved from 0.73687 to 0.73560, saving model to model_part2.hdf5

Epoch 00153: loss improved from 0.73560 to 0.73491, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.73491 to 0.73470, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.73470 to 0.73297, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.73297 to 0.73211, saving model to model_part2.hdf5

Epoch 00157: loss improved from 0.73211 to 0.73172, saving model to model_part2.hdf5

Epoch 00158: loss improved from 0.73172 to 0.73057, saving model to model_part2.hdf5

Epoch 00159: loss improved from 0.73057 to 0.72944, saving model to model_part2.hdf5

Epoch 00160: loss improved from 0.72944 to 0.72925, saving model to model_part2.hdf5

Epoch 00161: loss improved from 0.72925 to 0.72810, saving model to model_part2.hdf5

Epoch 00162: loss improved from 0.72810 to 0.72688, saving model to model_part2.hdf5

Epoch 00163: loss improved from 0.72688 to 0.72577, saving model to model_part2.hdf5

Epoch 00164: loss improved from 0.72577 to 0.72561, saving model to model_part2.hdf5

Epoch 00165: loss improved from 0.72561 to 0.72537, saving model to model_part2.hdf5

Epoch 00166: loss improved from 0.72537 to 0.72354, saving model to model_part2.hdf5

Epoch 00167: loss improved from 0.72354 to 0.72257, saving model to model_part2.hdf5

Epoch 00168: loss improved from 0.72257 to 0.72124, saving model to model_part2.hdf5

Epoch 00169: loss improved from 0.72124 to 0.72028, saving model to model_part2.hdf5

Epoch 00170: loss improved from 0.72028 to 0.71950, saving model to model_part2.hdf5

Epoch 00171: loss improved from 0.71950 to 0.71945, saving model to model_part2.hdf5

Epoch 00172: loss improved from 0.71945 to 0.71840, saving model to model_part2.hdf5

Epoch 00173: loss improved from 0.71840 to 0.71670, saving model to model_part2.hdf5

Epoch 00174: loss improved from 0.71670 to 0.71561, saving model to model_part2.hdf5

Epoch 00175: loss improved from 0.71561 to 0.71466, saving model to model_part2.hdf5

Epoch 00176: loss improved from 0.71466 to 0.71356, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.71356 to 0.71255, saving model to model_part2.hdf5

Epoch 00178: loss improved from 0.71255 to 0.71252, saving model to model_part2.hdf5

Epoch 00179: loss improved from 0.71252 to 0.71120, saving model to model_part2.hdf5

Epoch 00180: loss improved from 0.71120 to 0.70961, saving model to model_part2.hdf5

Epoch 00181: loss improved from 0.70961 to 0.70835, saving model to model_part2.hdf5

Epoch 00182: loss improved from 0.70835 to 0.70705, saving model to model_part2.hdf5

Epoch 00183: loss improved from 0.70705 to 0.70670, saving model to model_part2.hdf5

Epoch 00184: loss improved from 0.70670 to 0.70526, saving model to model_part2.hdf5

Epoch 00185: loss improved from 0.70526 to 0.70350, saving model to model_part2.hdf5

Epoch 00186: loss improved from 0.70350 to 0.70298, saving model to model_part2.hdf5

Epoch 00187: loss improved from 0.70298 to 0.70202, saving model to model_part2.hdf5

Epoch 00188: loss improved from 0.70202 to 0.70049, saving model to model_part2.hdf5

Epoch 00189: loss did not improve from 0.70049

Epoch 00190: loss improved from 0.70049 to 0.69808, saving model to model_part2.hdf5

Epoch 00191: loss improved from 0.69808 to 0.69726, saving model to model_part2.hdf5

Epoch 00192: loss improved from 0.69726 to 0.69605, saving model to model_part2.hdf5

Epoch 00193: loss improved from 0.69605 to 0.69510, saving model to model_part2.hdf5

Epoch 00194: loss improved from 0.69510 to 0.69349, saving model to model_part2.hdf5

Epoch 00195: loss improved from 0.69349 to 0.69229, saving model to model_part2.hdf5

Epoch 00196: loss improved from 0.69229 to 0.69114, saving model to model_part2.hdf5

Epoch 00197: loss improved from 0.69114 to 0.69018, saving model to model_part2.hdf5

Epoch 00198: loss improved from 0.69018 to 0.68853, saving model to model_part2.hdf5

Epoch 00199: loss improved from 0.68853 to 0.68726, saving model to model_part2.hdf5

Epoch 00200: loss improved from 0.68726 to 0.68594, saving model to model_part2.hdf5

Epoch 00201: loss improved from 0.68594 to 0.68425, saving model to model_part2.hdf5

Epoch 00202: loss improved from 0.68425 to 0.68312, saving model to model_part2.hdf5

Epoch 00203: loss improved from 0.68312 to 0.68135, saving model to model_part2.hdf5

Epoch 00204: loss improved from 0.68135 to 0.67995, saving model to model_part2.hdf5

Epoch 00205: loss improved from 0.67995 to 0.67859, saving model to model_part2.hdf5

Epoch 00206: loss improved from 0.67859 to 0.67763, saving model to model_part2.hdf5

Epoch 00207: loss improved from 0.67763 to 0.67553, saving model to model_part2.hdf5

Epoch 00208: loss improved from 0.67553 to 0.67549, saving model to model_part2.hdf5

Epoch 00209: loss improved from 0.67549 to 0.67288, saving model to model_part2.hdf5

Epoch 00210: loss improved from 0.67288 to 0.67124, saving model to model_part2.hdf5

Epoch 00211: loss did not improve from 0.67124

Epoch 00212: loss did not improve from 0.67124

Epoch 00213: loss improved from 0.67124 to 0.66754, saving model to model_part2.hdf5

Epoch 00214: loss improved from 0.66754 to 0.66662, saving model to model_part2.hdf5

Epoch 00215: loss improved from 0.66662 to 0.66505, saving model to model_part2.hdf5

Epoch 00216: loss improved from 0.66505 to 0.66408, saving model to model_part2.hdf5

Epoch 00217: loss improved from 0.66408 to 0.66259, saving model to model_part2.hdf5

Epoch 00218: loss improved from 0.66259 to 0.66160, saving model to model_part2.hdf5

Epoch 00219: loss improved from 0.66160 to 0.66130, saving model to model_part2.hdf5

Epoch 00220: loss improved from 0.66130 to 0.66016, saving model to model_part2.hdf5

Epoch 00221: loss improved from 0.66016 to 0.65902, saving model to model_part2.hdf5

Epoch 00222: loss improved from 0.65902 to 0.65680, saving model to model_part2.hdf5

Epoch 00223: loss improved from 0.65680 to 0.65544, saving model to model_part2.hdf5

Epoch 00224: loss improved from 0.65544 to 0.65453, saving model to model_part2.hdf5

Epoch 00225: loss improved from 0.65453 to 0.65262, saving model to model_part2.hdf5

Epoch 00226: loss improved from 0.65262 to 0.65139, saving model to model_part2.hdf5

Epoch 00227: loss improved from 0.65139 to 0.64998, saving model to model_part2.hdf5

Epoch 00228: loss improved from 0.64998 to 0.64837, saving model to model_part2.hdf5

Epoch 00229: loss improved from 0.64837 to 0.64677, saving model to model_part2.hdf5

Epoch 00230: loss improved from 0.64677 to 0.64663, saving model to model_part2.hdf5

Epoch 00231: loss improved from 0.64663 to 0.64543, saving model to model_part2.hdf5

Epoch 00232: loss improved from 0.64543 to 0.64285, saving model to model_part2.hdf5

Epoch 00233: loss improved from 0.64285 to 0.64219, saving model to model_part2.hdf5

Epoch 00234: loss did not improve from 0.64219

Epoch 00235: loss improved from 0.64219 to 0.63864, saving model to model_part2.hdf5

Epoch 00236: loss improved from 0.63864 to 0.63723, saving model to model_part2.hdf5

Epoch 00237: loss did not improve from 0.63723

Epoch 00238: loss improved from 0.63723 to 0.63481, saving model to model_part2.hdf5

Epoch 00239: loss improved from 0.63481 to 0.63358, saving model to model_part2.hdf5

Epoch 00240: loss improved from 0.63358 to 0.63207, saving model to model_part2.hdf5

Epoch 00241: loss improved from 0.63207 to 0.63122, saving model to model_part2.hdf5

Epoch 00242: loss improved from 0.63122 to 0.62951, saving model to model_part2.hdf5

Epoch 00243: loss improved from 0.62951 to 0.62770, saving model to model_part2.hdf5

Epoch 00244: loss improved from 0.62770 to 0.62634, saving model to model_part2.hdf5

Epoch 00245: loss improved from 0.62634 to 0.62444, saving model to model_part2.hdf5

Epoch 00246: loss improved from 0.62444 to 0.62410, saving model to model_part2.hdf5

Epoch 00247: loss improved from 0.62410 to 0.62181, saving model to model_part2.hdf5

Epoch 00248: loss improved from 0.62181 to 0.62132, saving model to model_part2.hdf5

Epoch 00249: loss improved from 0.62132 to 0.61904, saving model to model_part2.hdf5

Epoch 00250: loss improved from 0.61904 to 0.61712, saving model to model_part2.hdf5

Epoch 00251: loss improved from 0.61712 to 0.61609, saving model to model_part2.hdf5

Epoch 00252: loss improved from 0.61609 to 0.61586, saving model to model_part2.hdf5

Epoch 00253: loss improved from 0.61586 to 0.61333, saving model to model_part2.hdf5

Epoch 00254: loss did not improve from 0.61333

Epoch 00255: loss improved from 0.61333 to 0.61107, saving model to model_part2.hdf5

Epoch 00256: loss improved from 0.61107 to 0.60910, saving model to model_part2.hdf5

Epoch 00257: loss improved from 0.60910 to 0.60816, saving model to model_part2.hdf5

Epoch 00258: loss improved from 0.60816 to 0.60775, saving model to model_part2.hdf5

Epoch 00259: loss improved from 0.60775 to 0.60620, saving model to model_part2.hdf5

Epoch 00260: loss improved from 0.60620 to 0.60554, saving model to model_part2.hdf5

Epoch 00261: loss improved from 0.60554 to 0.60354, saving model to model_part2.hdf5

Epoch 00262: loss improved from 0.60354 to 0.60202, saving model to model_part2.hdf5

Epoch 00263: loss improved from 0.60202 to 0.60107, saving model to model_part2.hdf5

Epoch 00264: loss improved from 0.60107 to 0.59942, saving model to model_part2.hdf5

Epoch 00265: loss improved from 0.59942 to 0.59786, saving model to model_part2.hdf5

Epoch 00266: loss improved from 0.59786 to 0.59721, saving model to model_part2.hdf5

Epoch 00267: loss improved from 0.59721 to 0.59716, saving model to model_part2.hdf5

Epoch 00268: loss improved from 0.59716 to 0.59518, saving model to model_part2.hdf5

Epoch 00269: loss did not improve from 0.59518

Epoch 00270: loss improved from 0.59518 to 0.59262, saving model to model_part2.hdf5

Epoch 00271: loss improved from 0.59262 to 0.59092, saving model to model_part2.hdf5

Epoch 00272: loss did not improve from 0.59092

Epoch 00273: loss improved from 0.59092 to 0.59013, saving model to model_part2.hdf5

Epoch 00274: loss improved from 0.59013 to 0.58809, saving model to model_part2.hdf5

Epoch 00275: loss improved from 0.58809 to 0.58665, saving model to model_part2.hdf5

Epoch 00276: loss improved from 0.58665 to 0.58539, saving model to model_part2.hdf5

Epoch 00277: loss improved from 0.58539 to 0.58415, saving model to model_part2.hdf5
Testing the model
45/45 [==============================] - 0s 1ms/step
====================================================

====================================================
Percent Training Size  0.7
Training the Model

Epoch 00001: loss improved from inf to 1.09654, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.09654 to 1.09118, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.09118 to 1.08729, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.08729 to 1.08467, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.08467 to 1.08242, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.08242 to 1.08029, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.08029 to 1.07876, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.07876 to 1.07713, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.07713 to 1.07544, saving model to model_part2.hdf5

Epoch 00010: loss improved from 1.07544 to 1.07434, saving model to model_part2.hdf5

Epoch 00011: loss improved from 1.07434 to 1.07296, saving model to model_part2.hdf5

Epoch 00012: loss improved from 1.07296 to 1.07142, saving model to model_part2.hdf5

Epoch 00013: loss improved from 1.07142 to 1.07008, saving model to model_part2.hdf5

Epoch 00014: loss improved from 1.07008 to 1.06881, saving model to model_part2.hdf5

Epoch 00015: loss improved from 1.06881 to 1.06714, saving model to model_part2.hdf5

Epoch 00016: loss improved from 1.06714 to 1.06554, saving model to model_part2.hdf5

Epoch 00017: loss improved from 1.06554 to 1.06422, saving model to model_part2.hdf5

Epoch 00018: loss improved from 1.06422 to 1.06192, saving model to model_part2.hdf5

Epoch 00019: loss improved from 1.06192 to 1.05975, saving model to model_part2.hdf5

Epoch 00020: loss improved from 1.05975 to 1.05728, saving model to model_part2.hdf5

Epoch 00021: loss improved from 1.05728 to 1.05449, saving model to model_part2.hdf5

Epoch 00022: loss improved from 1.05449 to 1.05174, saving model to model_part2.hdf5

Epoch 00023: loss improved from 1.05174 to 1.04795, saving model to model_part2.hdf5

Epoch 00024: loss improved from 1.04795 to 1.04460, saving model to model_part2.hdf5

Epoch 00025: loss improved from 1.04460 to 1.04143, saving model to model_part2.hdf5

Epoch 00026: loss improved from 1.04143 to 1.03784, saving model to model_part2.hdf5

Epoch 00027: loss improved from 1.03784 to 1.03413, saving model to model_part2.hdf5

Epoch 00028: loss improved from 1.03413 to 1.03044, saving model to model_part2.hdf5

Epoch 00029: loss improved from 1.03044 to 1.02674, saving model to model_part2.hdf5

Epoch 00030: loss improved from 1.02674 to 1.02301, saving model to model_part2.hdf5

Epoch 00031: loss improved from 1.02301 to 1.01902, saving model to model_part2.hdf5

Epoch 00032: loss improved from 1.01902 to 1.01511, saving model to model_part2.hdf5

Epoch 00033: loss improved from 1.01511 to 1.01113, saving model to model_part2.hdf5

Epoch 00034: loss improved from 1.01113 to 1.00702, saving model to model_part2.hdf5

Epoch 00035: loss improved from 1.00702 to 1.00292, saving model to model_part2.hdf5

Epoch 00036: loss improved from 1.00292 to 0.99882, saving model to model_part2.hdf5

Epoch 00037: loss improved from 0.99882 to 0.99429, saving model to model_part2.hdf5

Epoch 00038: loss improved from 0.99429 to 0.99077, saving model to model_part2.hdf5

Epoch 00039: loss improved from 0.99077 to 0.98571, saving model to model_part2.hdf5

Epoch 00040: loss improved from 0.98571 to 0.98124, saving model to model_part2.hdf5

Epoch 00041: loss improved from 0.98124 to 0.97703, saving model to model_part2.hdf5

Epoch 00042: loss improved from 0.97703 to 0.97228, saving model to model_part2.hdf5

Epoch 00043: loss improved from 0.97228 to 0.96763, saving model to model_part2.hdf5

Epoch 00044: loss improved from 0.96763 to 0.96277, saving model to model_part2.hdf5

Epoch 00045: loss improved from 0.96277 to 0.95854, saving model to model_part2.hdf5

Epoch 00046: loss improved from 0.95854 to 0.95379, saving model to model_part2.hdf5

Epoch 00047: loss improved from 0.95379 to 0.94906, saving model to model_part2.hdf5

Epoch 00048: loss improved from 0.94906 to 0.94417, saving model to model_part2.hdf5

Epoch 00049: loss improved from 0.94417 to 0.93964, saving model to model_part2.hdf5

Epoch 00050: loss improved from 0.93964 to 0.93490, saving model to model_part2.hdf5

Epoch 00051: loss improved from 0.93490 to 0.93004, saving model to model_part2.hdf5

Epoch 00052: loss improved from 0.93004 to 0.92570, saving model to model_part2.hdf5

Epoch 00053: loss improved from 0.92570 to 0.92046, saving model to model_part2.hdf5

Epoch 00054: loss improved from 0.92046 to 0.91582, saving model to model_part2.hdf5

Epoch 00055: loss improved from 0.91582 to 0.91157, saving model to model_part2.hdf5

Epoch 00056: loss improved from 0.91157 to 0.90674, saving model to model_part2.hdf5

Epoch 00057: loss improved from 0.90674 to 0.90245, saving model to model_part2.hdf5

Epoch 00058: loss improved from 0.90245 to 0.89821, saving model to model_part2.hdf5

Epoch 00059: loss improved from 0.89821 to 0.89335, saving model to model_part2.hdf5

Epoch 00060: loss improved from 0.89335 to 0.89011, saving model to model_part2.hdf5

Epoch 00061: loss improved from 0.89011 to 0.88514, saving model to model_part2.hdf5

Epoch 00062: loss improved from 0.88514 to 0.88117, saving model to model_part2.hdf5

Epoch 00063: loss improved from 0.88117 to 0.87712, saving model to model_part2.hdf5

Epoch 00064: loss improved from 0.87712 to 0.87293, saving model to model_part2.hdf5

Epoch 00065: loss improved from 0.87293 to 0.86965, saving model to model_part2.hdf5

Epoch 00066: loss improved from 0.86965 to 0.86524, saving model to model_part2.hdf5

Epoch 00067: loss improved from 0.86524 to 0.86162, saving model to model_part2.hdf5

Epoch 00068: loss improved from 0.86162 to 0.85817, saving model to model_part2.hdf5

Epoch 00069: loss improved from 0.85817 to 0.85430, saving model to model_part2.hdf5

Epoch 00070: loss improved from 0.85430 to 0.85061, saving model to model_part2.hdf5

Epoch 00071: loss improved from 0.85061 to 0.84719, saving model to model_part2.hdf5

Epoch 00072: loss improved from 0.84719 to 0.84424, saving model to model_part2.hdf5

Epoch 00073: loss improved from 0.84424 to 0.84044, saving model to model_part2.hdf5

Epoch 00074: loss improved from 0.84044 to 0.83764, saving model to model_part2.hdf5

Epoch 00075: loss improved from 0.83764 to 0.83414, saving model to model_part2.hdf5

Epoch 00076: loss improved from 0.83414 to 0.83096, saving model to model_part2.hdf5

Epoch 00077: loss improved from 0.83096 to 0.82783, saving model to model_part2.hdf5

Epoch 00078: loss improved from 0.82783 to 0.82475, saving model to model_part2.hdf5

Epoch 00079: loss improved from 0.82475 to 0.82288, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.82288 to 0.81884, saving model to model_part2.hdf5

Epoch 00081: loss improved from 0.81884 to 0.81598, saving model to model_part2.hdf5

Epoch 00082: loss improved from 0.81598 to 0.81334, saving model to model_part2.hdf5

Epoch 00083: loss improved from 0.81334 to 0.81073, saving model to model_part2.hdf5

Epoch 00084: loss improved from 0.81073 to 0.80780, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.80780 to 0.80513, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.80513 to 0.80401, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.80401 to 0.79989, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.79989 to 0.79732, saving model to model_part2.hdf5

Epoch 00089: loss improved from 0.79732 to 0.79476, saving model to model_part2.hdf5

Epoch 00090: loss improved from 0.79476 to 0.79257, saving model to model_part2.hdf5

Epoch 00091: loss improved from 0.79257 to 0.78971, saving model to model_part2.hdf5

Epoch 00092: loss improved from 0.78971 to 0.78855, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.78855 to 0.78528, saving model to model_part2.hdf5

Epoch 00094: loss improved from 0.78528 to 0.78250, saving model to model_part2.hdf5

Epoch 00095: loss improved from 0.78250 to 0.78077, saving model to model_part2.hdf5

Epoch 00096: loss improved from 0.78077 to 0.77801, saving model to model_part2.hdf5

Epoch 00097: loss improved from 0.77801 to 0.77614, saving model to model_part2.hdf5

Epoch 00098: loss improved from 0.77614 to 0.77347, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.77347 to 0.77106, saving model to model_part2.hdf5

Epoch 00100: loss improved from 0.77106 to 0.76927, saving model to model_part2.hdf5

Epoch 00101: loss improved from 0.76927 to 0.76654, saving model to model_part2.hdf5

Epoch 00102: loss did not improve from 0.76654

Epoch 00103: loss improved from 0.76654 to 0.76261, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.76261 to 0.76015, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.76015 to 0.75813, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.75813 to 0.75591, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.75591 to 0.75363, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.75363 to 0.75161, saving model to model_part2.hdf5

Epoch 00109: loss improved from 0.75161 to 0.74927, saving model to model_part2.hdf5

Epoch 00110: loss improved from 0.74927 to 0.74706, saving model to model_part2.hdf5

Epoch 00111: loss improved from 0.74706 to 0.74478, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.74478 to 0.74364, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.74364 to 0.74043, saving model to model_part2.hdf5

Epoch 00114: loss improved from 0.74043 to 0.73787, saving model to model_part2.hdf5

Epoch 00115: loss improved from 0.73787 to 0.73608, saving model to model_part2.hdf5

Epoch 00116: loss did not improve from 0.73608

Epoch 00117: loss improved from 0.73608 to 0.73203, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.73203 to 0.72994, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.72994 to 0.72785, saving model to model_part2.hdf5

Epoch 00120: loss improved from 0.72785 to 0.72569, saving model to model_part2.hdf5

Epoch 00121: loss improved from 0.72569 to 0.72389, saving model to model_part2.hdf5

Epoch 00122: loss improved from 0.72389 to 0.72143, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.72143 to 0.71977, saving model to model_part2.hdf5

Epoch 00124: loss improved from 0.71977 to 0.71721, saving model to model_part2.hdf5

Epoch 00125: loss improved from 0.71721 to 0.71536, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.71536 to 0.71296, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.71296 to 0.71070, saving model to model_part2.hdf5

Epoch 00128: loss improved from 0.71070 to 0.70850, saving model to model_part2.hdf5

Epoch 00129: loss improved from 0.70850 to 0.70725, saving model to model_part2.hdf5

Epoch 00130: loss improved from 0.70725 to 0.70597, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.70597 to 0.70255, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.70255 to 0.70028, saving model to model_part2.hdf5

Epoch 00133: loss improved from 0.70028 to 0.69800, saving model to model_part2.hdf5

Epoch 00134: loss improved from 0.69800 to 0.69606, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.69606 to 0.69389, saving model to model_part2.hdf5

Epoch 00136: loss improved from 0.69389 to 0.69149, saving model to model_part2.hdf5

Epoch 00137: loss improved from 0.69149 to 0.68919, saving model to model_part2.hdf5

Epoch 00138: loss improved from 0.68919 to 0.68801, saving model to model_part2.hdf5

Epoch 00139: loss improved from 0.68801 to 0.68502, saving model to model_part2.hdf5

Epoch 00140: loss improved from 0.68502 to 0.68362, saving model to model_part2.hdf5

Epoch 00141: loss improved from 0.68362 to 0.68093, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.68093 to 0.67851, saving model to model_part2.hdf5

Epoch 00143: loss improved from 0.67851 to 0.67716, saving model to model_part2.hdf5

Epoch 00144: loss improved from 0.67716 to 0.67436, saving model to model_part2.hdf5

Epoch 00145: loss improved from 0.67436 to 0.67285, saving model to model_part2.hdf5

Epoch 00146: loss improved from 0.67285 to 0.67086, saving model to model_part2.hdf5

Epoch 00147: loss improved from 0.67086 to 0.66871, saving model to model_part2.hdf5

Epoch 00148: loss improved from 0.66871 to 0.66583, saving model to model_part2.hdf5

Epoch 00149: loss improved from 0.66583 to 0.66457, saving model to model_part2.hdf5

Epoch 00150: loss improved from 0.66457 to 0.66386, saving model to model_part2.hdf5

Epoch 00151: loss improved from 0.66386 to 0.65996, saving model to model_part2.hdf5

Epoch 00152: loss improved from 0.65996 to 0.65772, saving model to model_part2.hdf5

Epoch 00153: loss improved from 0.65772 to 0.65636, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.65636 to 0.65383, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.65383 to 0.65190, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.65190 to 0.64983, saving model to model_part2.hdf5

Epoch 00157: loss improved from 0.64983 to 0.64761, saving model to model_part2.hdf5

Epoch 00158: loss improved from 0.64761 to 0.64620, saving model to model_part2.hdf5

Epoch 00159: loss improved from 0.64620 to 0.64358, saving model to model_part2.hdf5

Epoch 00160: loss improved from 0.64358 to 0.64180, saving model to model_part2.hdf5

Epoch 00161: loss improved from 0.64180 to 0.63899, saving model to model_part2.hdf5

Epoch 00162: loss improved from 0.63899 to 0.63668, saving model to model_part2.hdf5

Epoch 00163: loss did not improve from 0.63668

Epoch 00164: loss improved from 0.63668 to 0.63349, saving model to model_part2.hdf5

Epoch 00165: loss improved from 0.63349 to 0.63229, saving model to model_part2.hdf5

Epoch 00166: loss improved from 0.63229 to 0.62982, saving model to model_part2.hdf5

Epoch 00167: loss improved from 0.62982 to 0.62893, saving model to model_part2.hdf5

Epoch 00168: loss improved from 0.62893 to 0.62599, saving model to model_part2.hdf5

Epoch 00169: loss improved from 0.62599 to 0.62343, saving model to model_part2.hdf5

Epoch 00170: loss did not improve from 0.62343

Epoch 00171: loss improved from 0.62343 to 0.62008, saving model to model_part2.hdf5

Epoch 00172: loss improved from 0.62008 to 0.61998, saving model to model_part2.hdf5

Epoch 00173: loss improved from 0.61998 to 0.61635, saving model to model_part2.hdf5

Epoch 00174: loss improved from 0.61635 to 0.61468, saving model to model_part2.hdf5

Epoch 00175: loss improved from 0.61468 to 0.61262, saving model to model_part2.hdf5

Epoch 00176: loss improved from 0.61262 to 0.61014, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.61014 to 0.60857, saving model to model_part2.hdf5

Epoch 00178: loss improved from 0.60857 to 0.60799, saving model to model_part2.hdf5

Epoch 00179: loss improved from 0.60799 to 0.60503, saving model to model_part2.hdf5

Epoch 00180: loss improved from 0.60503 to 0.60267, saving model to model_part2.hdf5

Epoch 00181: loss improved from 0.60267 to 0.60118, saving model to model_part2.hdf5

Epoch 00182: loss improved from 0.60118 to 0.60026, saving model to model_part2.hdf5

Epoch 00183: loss improved from 0.60026 to 0.59787, saving model to model_part2.hdf5

Epoch 00184: loss improved from 0.59787 to 0.59511, saving model to model_part2.hdf5

Epoch 00185: loss improved from 0.59511 to 0.59277, saving model to model_part2.hdf5

Epoch 00186: loss improved from 0.59277 to 0.59062, saving model to model_part2.hdf5

Epoch 00187: loss improved from 0.59062 to 0.58852, saving model to model_part2.hdf5

Epoch 00188: loss improved from 0.58852 to 0.58807, saving model to model_part2.hdf5

Epoch 00189: loss improved from 0.58807 to 0.58473, saving model to model_part2.hdf5

Epoch 00190: loss improved from 0.58473 to 0.58206, saving model to model_part2.hdf5

Epoch 00191: loss did not improve from 0.58206

Epoch 00192: loss improved from 0.58206 to 0.57925, saving model to model_part2.hdf5

Epoch 00193: loss improved from 0.57925 to 0.57664, saving model to model_part2.hdf5

Epoch 00194: loss improved from 0.57664 to 0.57497, saving model to model_part2.hdf5

Epoch 00195: loss improved from 0.57497 to 0.57276, saving model to model_part2.hdf5

Epoch 00196: loss did not improve from 0.57276

Epoch 00197: loss improved from 0.57276 to 0.56894, saving model to model_part2.hdf5

Epoch 00198: loss did not improve from 0.56894

Epoch 00199: loss improved from 0.56894 to 0.56633, saving model to model_part2.hdf5

Epoch 00200: loss improved from 0.56633 to 0.56468, saving model to model_part2.hdf5

Epoch 00201: loss improved from 0.56468 to 0.56137, saving model to model_part2.hdf5

Epoch 00202: loss improved from 0.56137 to 0.55923, saving model to model_part2.hdf5

Epoch 00203: loss improved from 0.55923 to 0.55755, saving model to model_part2.hdf5

Epoch 00204: loss improved from 0.55755 to 0.55643, saving model to model_part2.hdf5

Epoch 00205: loss improved from 0.55643 to 0.55362, saving model to model_part2.hdf5

Epoch 00206: loss improved from 0.55362 to 0.55092, saving model to model_part2.hdf5

Epoch 00207: loss improved from 0.55092 to 0.54884, saving model to model_part2.hdf5

Epoch 00208: loss improved from 0.54884 to 0.54647, saving model to model_part2.hdf5

Epoch 00209: loss improved from 0.54647 to 0.54441, saving model to model_part2.hdf5

Epoch 00210: loss improved from 0.54441 to 0.54263, saving model to model_part2.hdf5

Epoch 00211: loss improved from 0.54263 to 0.53981, saving model to model_part2.hdf5

Epoch 00212: loss improved from 0.53981 to 0.53843, saving model to model_part2.hdf5

Epoch 00213: loss improved from 0.53843 to 0.53580, saving model to model_part2.hdf5

Epoch 00214: loss improved from 0.53580 to 0.53376, saving model to model_part2.hdf5

Epoch 00215: loss improved from 0.53376 to 0.53172, saving model to model_part2.hdf5

Epoch 00216: loss improved from 0.53172 to 0.52938, saving model to model_part2.hdf5

Epoch 00217: loss improved from 0.52938 to 0.52662, saving model to model_part2.hdf5

Epoch 00218: loss improved from 0.52662 to 0.52447, saving model to model_part2.hdf5

Epoch 00219: loss did not improve from 0.52447

Epoch 00220: loss improved from 0.52447 to 0.52256, saving model to model_part2.hdf5

Epoch 00221: loss improved from 0.52256 to 0.51814, saving model to model_part2.hdf5

Epoch 00222: loss improved from 0.51814 to 0.51607, saving model to model_part2.hdf5

Epoch 00223: loss did not improve from 0.51607

Epoch 00224: loss improved from 0.51607 to 0.51286, saving model to model_part2.hdf5

Epoch 00225: loss improved from 0.51286 to 0.51080, saving model to model_part2.hdf5

Epoch 00226: loss improved from 0.51080 to 0.50921, saving model to model_part2.hdf5

Epoch 00227: loss improved from 0.50921 to 0.50876, saving model to model_part2.hdf5

Epoch 00228: loss improved from 0.50876 to 0.50484, saving model to model_part2.hdf5

Epoch 00229: loss improved from 0.50484 to 0.50203, saving model to model_part2.hdf5

Epoch 00230: loss improved from 0.50203 to 0.50180, saving model to model_part2.hdf5

Epoch 00231: loss improved from 0.50180 to 0.49876, saving model to model_part2.hdf5

Epoch 00232: loss improved from 0.49876 to 0.49754, saving model to model_part2.hdf5

Epoch 00233: loss improved from 0.49754 to 0.49399, saving model to model_part2.hdf5

Epoch 00234: loss improved from 0.49399 to 0.49239, saving model to model_part2.hdf5

Epoch 00235: loss improved from 0.49239 to 0.48971, saving model to model_part2.hdf5

Epoch 00236: loss improved from 0.48971 to 0.48780, saving model to model_part2.hdf5

Epoch 00237: loss improved from 0.48780 to 0.48628, saving model to model_part2.hdf5

Epoch 00238: loss improved from 0.48628 to 0.48409, saving model to model_part2.hdf5

Epoch 00239: loss improved from 0.48409 to 0.48231, saving model to model_part2.hdf5

Epoch 00240: loss improved from 0.48231 to 0.47966, saving model to model_part2.hdf5

Epoch 00241: loss improved from 0.47966 to 0.47795, saving model to model_part2.hdf5

Epoch 00242: loss improved from 0.47795 to 0.47477, saving model to model_part2.hdf5

Epoch 00243: loss improved from 0.47477 to 0.47311, saving model to model_part2.hdf5

Epoch 00244: loss improved from 0.47311 to 0.47063, saving model to model_part2.hdf5

Epoch 00245: loss improved from 0.47063 to 0.46821, saving model to model_part2.hdf5

Epoch 00246: loss improved from 0.46821 to 0.46568, saving model to model_part2.hdf5

Epoch 00247: loss improved from 0.46568 to 0.46326, saving model to model_part2.hdf5

Epoch 00248: loss improved from 0.46326 to 0.46201, saving model to model_part2.hdf5

Epoch 00249: loss improved from 0.46201 to 0.45897, saving model to model_part2.hdf5

Epoch 00250: loss did not improve from 0.45897

Epoch 00251: loss improved from 0.45897 to 0.45529, saving model to model_part2.hdf5

Epoch 00252: loss improved from 0.45529 to 0.45317, saving model to model_part2.hdf5

Epoch 00253: loss improved from 0.45317 to 0.45004, saving model to model_part2.hdf5

Epoch 00254: loss improved from 0.45004 to 0.44960, saving model to model_part2.hdf5

Epoch 00255: loss improved from 0.44960 to 0.44592, saving model to model_part2.hdf5

Epoch 00256: loss improved from 0.44592 to 0.44353, saving model to model_part2.hdf5

Epoch 00257: loss improved from 0.44353 to 0.44196, saving model to model_part2.hdf5

Epoch 00258: loss did not improve from 0.44196

Epoch 00259: loss improved from 0.44196 to 0.44027, saving model to model_part2.hdf5

Epoch 00260: loss improved from 0.44027 to 0.43607, saving model to model_part2.hdf5

Epoch 00261: loss improved from 0.43607 to 0.43533, saving model to model_part2.hdf5

Epoch 00262: loss improved from 0.43533 to 0.43358, saving model to model_part2.hdf5

Epoch 00263: loss improved from 0.43358 to 0.42989, saving model to model_part2.hdf5

Epoch 00264: loss improved from 0.42989 to 0.42766, saving model to model_part2.hdf5

Epoch 00265: loss improved from 0.42766 to 0.42693, saving model to model_part2.hdf5

Epoch 00266: loss improved from 0.42693 to 0.42400, saving model to model_part2.hdf5

Epoch 00267: loss did not improve from 0.42400

Epoch 00268: loss improved from 0.42400 to 0.42128, saving model to model_part2.hdf5

Epoch 00269: loss improved from 0.42128 to 0.41798, saving model to model_part2.hdf5

Epoch 00270: loss did not improve from 0.41798

Epoch 00271: loss improved from 0.41798 to 0.41518, saving model to model_part2.hdf5

Epoch 00272: loss improved from 0.41518 to 0.41263, saving model to model_part2.hdf5

Epoch 00273: loss improved from 0.41263 to 0.41019, saving model to model_part2.hdf5

Epoch 00274: loss did not improve from 0.41019

Epoch 00275: loss improved from 0.41019 to 0.40600, saving model to model_part2.hdf5

Epoch 00276: loss improved from 0.40600 to 0.40465, saving model to model_part2.hdf5

Epoch 00277: loss did not improve from 0.40465

Epoch 00278: loss improved from 0.40465 to 0.40149, saving model to model_part2.hdf5

Epoch 00279: loss improved from 0.40149 to 0.39803, saving model to model_part2.hdf5

Epoch 00280: loss improved from 0.39803 to 0.39750, saving model to model_part2.hdf5

Epoch 00281: loss improved from 0.39750 to 0.39617, saving model to model_part2.hdf5

Epoch 00282: loss improved from 0.39617 to 0.39403, saving model to model_part2.hdf5

Epoch 00283: loss improved from 0.39403 to 0.39072, saving model to model_part2.hdf5

Epoch 00284: loss improved from 0.39072 to 0.38839, saving model to model_part2.hdf5

Epoch 00285: loss improved from 0.38839 to 0.38608, saving model to model_part2.hdf5

Epoch 00286: loss did not improve from 0.38608

Epoch 00287: loss improved from 0.38608 to 0.38552, saving model to model_part2.hdf5

Epoch 00288: loss improved from 0.38552 to 0.38020, saving model to model_part2.hdf5

Epoch 00289: loss did not improve from 0.38020

Epoch 00290: loss improved from 0.38020 to 0.37720, saving model to model_part2.hdf5

Epoch 00291: loss improved from 0.37720 to 0.37644, saving model to model_part2.hdf5

Epoch 00292: loss improved from 0.37644 to 0.37591, saving model to model_part2.hdf5

Epoch 00293: loss improved from 0.37591 to 0.37121, saving model to model_part2.hdf5

Epoch 00294: loss improved from 0.37121 to 0.36996, saving model to model_part2.hdf5

Epoch 00295: loss improved from 0.36996 to 0.36745, saving model to model_part2.hdf5

Epoch 00296: loss improved from 0.36745 to 0.36634, saving model to model_part2.hdf5

Epoch 00297: loss did not improve from 0.36634

Epoch 00298: loss improved from 0.36634 to 0.36211, saving model to model_part2.hdf5

Epoch 00299: loss improved from 0.36211 to 0.36010, saving model to model_part2.hdf5

Epoch 00300: loss improved from 0.36010 to 0.36005, saving model to model_part2.hdf5

Epoch 00301: loss improved from 0.36005 to 0.35745, saving model to model_part2.hdf5

Epoch 00302: loss improved from 0.35745 to 0.35526, saving model to model_part2.hdf5

Epoch 00303: loss improved from 0.35526 to 0.35285, saving model to model_part2.hdf5

Epoch 00304: loss improved from 0.35285 to 0.35136, saving model to model_part2.hdf5

Epoch 00305: loss improved from 0.35136 to 0.35045, saving model to model_part2.hdf5

Epoch 00306: loss did not improve from 0.35045

Epoch 00307: loss improved from 0.35045 to 0.34633, saving model to model_part2.hdf5

Epoch 00308: loss did not improve from 0.34633

Epoch 00309: loss improved from 0.34633 to 0.34394, saving model to model_part2.hdf5

Epoch 00310: loss improved from 0.34394 to 0.34110, saving model to model_part2.hdf5

Epoch 00311: loss improved from 0.34110 to 0.33908, saving model to model_part2.hdf5

Epoch 00312: loss improved from 0.33908 to 0.33757, saving model to model_part2.hdf5

Epoch 00313: loss did not improve from 0.33757

Epoch 00314: loss did not improve from 0.33757

Epoch 00315: loss improved from 0.33757 to 0.33695, saving model to model_part2.hdf5

Epoch 00316: loss improved from 0.33695 to 0.33100, saving model to model_part2.hdf5

Epoch 00317: loss improved from 0.33100 to 0.32926, saving model to model_part2.hdf5

Epoch 00318: loss did not improve from 0.32926

Epoch 00319: loss improved from 0.32926 to 0.32622, saving model to model_part2.hdf5

Epoch 00320: loss did not improve from 0.32622

Epoch 00321: loss improved from 0.32622 to 0.32426, saving model to model_part2.hdf5

Epoch 00322: loss improved from 0.32426 to 0.32097, saving model to model_part2.hdf5

Epoch 00323: loss improved from 0.32097 to 0.32005, saving model to model_part2.hdf5

Epoch 00324: loss improved from 0.32005 to 0.31743, saving model to model_part2.hdf5

Epoch 00325: loss did not improve from 0.31743

Epoch 00326: loss improved from 0.31743 to 0.31490, saving model to model_part2.hdf5

Epoch 00327: loss improved from 0.31490 to 0.31328, saving model to model_part2.hdf5

Epoch 00328: loss improved from 0.31328 to 0.31175, saving model to model_part2.hdf5

Epoch 00329: loss improved from 0.31175 to 0.31045, saving model to model_part2.hdf5

Epoch 00330: loss did not improve from 0.31045

Epoch 00331: loss improved from 0.31045 to 0.30767, saving model to model_part2.hdf5

Epoch 00332: loss improved from 0.30767 to 0.30602, saving model to model_part2.hdf5

Epoch 00333: loss improved from 0.30602 to 0.30485, saving model to model_part2.hdf5

Epoch 00334: loss improved from 0.30485 to 0.30232, saving model to model_part2.hdf5

Epoch 00335: loss did not improve from 0.30232

Epoch 00336: loss improved from 0.30232 to 0.30216, saving model to model_part2.hdf5

Epoch 00337: loss improved from 0.30216 to 0.29726, saving model to model_part2.hdf5

Epoch 00338: loss did not improve from 0.29726

Epoch 00339: loss improved from 0.29726 to 0.29638, saving model to model_part2.hdf5

Epoch 00340: loss improved from 0.29638 to 0.29273, saving model to model_part2.hdf5

Epoch 00341: loss improved from 0.29273 to 0.29186, saving model to model_part2.hdf5

Epoch 00342: loss improved from 0.29186 to 0.29082, saving model to model_part2.hdf5

Epoch 00343: loss improved from 0.29082 to 0.28898, saving model to model_part2.hdf5

Epoch 00344: loss did not improve from 0.28898

Epoch 00345: loss improved from 0.28898 to 0.28720, saving model to model_part2.hdf5

Epoch 00346: loss improved from 0.28720 to 0.28497, saving model to model_part2.hdf5

Epoch 00347: loss did not improve from 0.28497

Epoch 00348: loss improved from 0.28497 to 0.28413, saving model to model_part2.hdf5

Epoch 00349: loss improved from 0.28413 to 0.28037, saving model to model_part2.hdf5

Epoch 00350: loss did not improve from 0.28037

Epoch 00351: loss improved from 0.28037 to 0.27861, saving model to model_part2.hdf5

Epoch 00352: loss improved from 0.27861 to 0.27758, saving model to model_part2.hdf5
Testing the model
45/45 [==============================] - 0s 2ms/step
====================================================

====================================================
Percent Training Size  0.8
Training the Model

Epoch 00001: loss improved from inf to 1.07476, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.07476 to 1.06387, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.06387 to 1.05720, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.05720 to 1.05143, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.05143 to 1.04703, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.04703 to 1.03964, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.03964 to 1.03298, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.03298 to 1.02776, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.02776 to 1.02157, saving model to model_part2.hdf5

Epoch 00010: loss improved from 1.02157 to 1.01379, saving model to model_part2.hdf5

Epoch 00011: loss improved from 1.01379 to 1.00776, saving model to model_part2.hdf5

Epoch 00012: loss improved from 1.00776 to 1.00185, saving model to model_part2.hdf5

Epoch 00013: loss improved from 1.00185 to 0.99667, saving model to model_part2.hdf5

Epoch 00014: loss improved from 0.99667 to 0.98919, saving model to model_part2.hdf5

Epoch 00015: loss improved from 0.98919 to 0.98260, saving model to model_part2.hdf5

Epoch 00016: loss improved from 0.98260 to 0.97673, saving model to model_part2.hdf5

Epoch 00017: loss improved from 0.97673 to 0.97088, saving model to model_part2.hdf5

Epoch 00018: loss improved from 0.97088 to 0.96373, saving model to model_part2.hdf5

Epoch 00019: loss improved from 0.96373 to 0.95938, saving model to model_part2.hdf5

Epoch 00020: loss improved from 0.95938 to 0.95327, saving model to model_part2.hdf5

Epoch 00021: loss improved from 0.95327 to 0.94936, saving model to model_part2.hdf5

Epoch 00022: loss improved from 0.94936 to 0.94566, saving model to model_part2.hdf5

Epoch 00023: loss improved from 0.94566 to 0.93999, saving model to model_part2.hdf5

Epoch 00024: loss improved from 0.93999 to 0.93513, saving model to model_part2.hdf5

Epoch 00025: loss improved from 0.93513 to 0.92877, saving model to model_part2.hdf5

Epoch 00026: loss improved from 0.92877 to 0.92289, saving model to model_part2.hdf5

Epoch 00027: loss improved from 0.92289 to 0.91893, saving model to model_part2.hdf5

Epoch 00028: loss improved from 0.91893 to 0.91211, saving model to model_part2.hdf5

Epoch 00029: loss improved from 0.91211 to 0.90694, saving model to model_part2.hdf5

Epoch 00030: loss improved from 0.90694 to 0.90418, saving model to model_part2.hdf5

Epoch 00031: loss improved from 0.90418 to 0.89834, saving model to model_part2.hdf5

Epoch 00032: loss improved from 0.89834 to 0.89391, saving model to model_part2.hdf5

Epoch 00033: loss improved from 0.89391 to 0.88927, saving model to model_part2.hdf5

Epoch 00034: loss improved from 0.88927 to 0.88427, saving model to model_part2.hdf5

Epoch 00035: loss improved from 0.88427 to 0.88072, saving model to model_part2.hdf5

Epoch 00036: loss improved from 0.88072 to 0.87592, saving model to model_part2.hdf5

Epoch 00037: loss improved from 0.87592 to 0.87143, saving model to model_part2.hdf5

Epoch 00038: loss improved from 0.87143 to 0.86842, saving model to model_part2.hdf5

Epoch 00039: loss improved from 0.86842 to 0.86247, saving model to model_part2.hdf5

Epoch 00040: loss improved from 0.86247 to 0.85771, saving model to model_part2.hdf5

Epoch 00041: loss improved from 0.85771 to 0.85345, saving model to model_part2.hdf5

Epoch 00042: loss improved from 0.85345 to 0.84880, saving model to model_part2.hdf5

Epoch 00043: loss improved from 0.84880 to 0.84447, saving model to model_part2.hdf5

Epoch 00044: loss improved from 0.84447 to 0.84161, saving model to model_part2.hdf5

Epoch 00045: loss improved from 0.84161 to 0.83679, saving model to model_part2.hdf5

Epoch 00046: loss improved from 0.83679 to 0.83345, saving model to model_part2.hdf5

Epoch 00047: loss improved from 0.83345 to 0.82910, saving model to model_part2.hdf5

Epoch 00048: loss improved from 0.82910 to 0.82613, saving model to model_part2.hdf5

Epoch 00049: loss improved from 0.82613 to 0.82251, saving model to model_part2.hdf5

Epoch 00050: loss improved from 0.82251 to 0.82074, saving model to model_part2.hdf5

Epoch 00051: loss improved from 0.82074 to 0.81490, saving model to model_part2.hdf5

Epoch 00052: loss improved from 0.81490 to 0.81073, saving model to model_part2.hdf5

Epoch 00053: loss improved from 0.81073 to 0.80763, saving model to model_part2.hdf5

Epoch 00054: loss improved from 0.80763 to 0.80437, saving model to model_part2.hdf5

Epoch 00055: loss improved from 0.80437 to 0.80235, saving model to model_part2.hdf5

Epoch 00056: loss improved from 0.80235 to 0.79757, saving model to model_part2.hdf5

Epoch 00057: loss improved from 0.79757 to 0.79281, saving model to model_part2.hdf5

Epoch 00058: loss improved from 0.79281 to 0.79030, saving model to model_part2.hdf5

Epoch 00059: loss improved from 0.79030 to 0.78487, saving model to model_part2.hdf5

Epoch 00060: loss improved from 0.78487 to 0.78177, saving model to model_part2.hdf5

Epoch 00061: loss improved from 0.78177 to 0.77762, saving model to model_part2.hdf5

Epoch 00062: loss improved from 0.77762 to 0.77499, saving model to model_part2.hdf5

Epoch 00063: loss improved from 0.77499 to 0.77061, saving model to model_part2.hdf5

Epoch 00064: loss improved from 0.77061 to 0.76689, saving model to model_part2.hdf5

Epoch 00065: loss improved from 0.76689 to 0.76338, saving model to model_part2.hdf5

Epoch 00066: loss improved from 0.76338 to 0.76033, saving model to model_part2.hdf5

Epoch 00067: loss improved from 0.76033 to 0.75573, saving model to model_part2.hdf5

Epoch 00068: loss improved from 0.75573 to 0.75243, saving model to model_part2.hdf5

Epoch 00069: loss improved from 0.75243 to 0.74814, saving model to model_part2.hdf5

Epoch 00070: loss improved from 0.74814 to 0.74547, saving model to model_part2.hdf5

Epoch 00071: loss improved from 0.74547 to 0.74344, saving model to model_part2.hdf5

Epoch 00072: loss improved from 0.74344 to 0.73851, saving model to model_part2.hdf5

Epoch 00073: loss improved from 0.73851 to 0.73638, saving model to model_part2.hdf5

Epoch 00074: loss improved from 0.73638 to 0.73214, saving model to model_part2.hdf5

Epoch 00075: loss improved from 0.73214 to 0.72900, saving model to model_part2.hdf5

Epoch 00076: loss improved from 0.72900 to 0.72663, saving model to model_part2.hdf5

Epoch 00077: loss improved from 0.72663 to 0.72217, saving model to model_part2.hdf5

Epoch 00078: loss improved from 0.72217 to 0.72053, saving model to model_part2.hdf5

Epoch 00079: loss improved from 0.72053 to 0.71561, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.71561 to 0.71215, saving model to model_part2.hdf5

Epoch 00081: loss improved from 0.71215 to 0.70991, saving model to model_part2.hdf5

Epoch 00082: loss improved from 0.70991 to 0.70630, saving model to model_part2.hdf5

Epoch 00083: loss improved from 0.70630 to 0.70253, saving model to model_part2.hdf5

Epoch 00084: loss improved from 0.70253 to 0.69835, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.69835 to 0.69420, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.69420 to 0.69251, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.69251 to 0.68945, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.68945 to 0.68666, saving model to model_part2.hdf5

Epoch 00089: loss improved from 0.68666 to 0.68274, saving model to model_part2.hdf5

Epoch 00090: loss improved from 0.68274 to 0.67880, saving model to model_part2.hdf5

Epoch 00091: loss improved from 0.67880 to 0.67593, saving model to model_part2.hdf5

Epoch 00092: loss improved from 0.67593 to 0.67174, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.67174 to 0.66980, saving model to model_part2.hdf5

Epoch 00094: loss improved from 0.66980 to 0.66581, saving model to model_part2.hdf5

Epoch 00095: loss improved from 0.66581 to 0.66297, saving model to model_part2.hdf5

Epoch 00096: loss improved from 0.66297 to 0.65879, saving model to model_part2.hdf5

Epoch 00097: loss improved from 0.65879 to 0.65553, saving model to model_part2.hdf5

Epoch 00098: loss improved from 0.65553 to 0.65309, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.65309 to 0.64873, saving model to model_part2.hdf5

Epoch 00100: loss improved from 0.64873 to 0.64521, saving model to model_part2.hdf5

Epoch 00101: loss improved from 0.64521 to 0.64393, saving model to model_part2.hdf5

Epoch 00102: loss improved from 0.64393 to 0.63950, saving model to model_part2.hdf5

Epoch 00103: loss improved from 0.63950 to 0.63721, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.63721 to 0.63370, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.63370 to 0.62846, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.62846 to 0.62430, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.62430 to 0.62236, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.62236 to 0.61853, saving model to model_part2.hdf5

Epoch 00109: loss improved from 0.61853 to 0.61482, saving model to model_part2.hdf5

Epoch 00110: loss improved from 0.61482 to 0.61218, saving model to model_part2.hdf5

Epoch 00111: loss improved from 0.61218 to 0.60621, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.60621 to 0.60515, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.60515 to 0.60023, saving model to model_part2.hdf5

Epoch 00114: loss improved from 0.60023 to 0.59634, saving model to model_part2.hdf5

Epoch 00115: loss improved from 0.59634 to 0.59552, saving model to model_part2.hdf5

Epoch 00116: loss improved from 0.59552 to 0.59312, saving model to model_part2.hdf5

Epoch 00117: loss improved from 0.59312 to 0.58787, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.58787 to 0.58650, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.58650 to 0.58193, saving model to model_part2.hdf5

Epoch 00120: loss improved from 0.58193 to 0.57868, saving model to model_part2.hdf5

Epoch 00121: loss improved from 0.57868 to 0.57535, saving model to model_part2.hdf5

Epoch 00122: loss improved from 0.57535 to 0.57171, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.57171 to 0.57084, saving model to model_part2.hdf5

Epoch 00124: loss improved from 0.57084 to 0.56656, saving model to model_part2.hdf5

Epoch 00125: loss improved from 0.56656 to 0.56377, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.56377 to 0.56084, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.56084 to 0.55882, saving model to model_part2.hdf5

Epoch 00128: loss improved from 0.55882 to 0.55506, saving model to model_part2.hdf5

Epoch 00129: loss improved from 0.55506 to 0.55129, saving model to model_part2.hdf5

Epoch 00130: loss improved from 0.55129 to 0.54769, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.54769 to 0.54503, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.54503 to 0.54472, saving model to model_part2.hdf5

Epoch 00133: loss improved from 0.54472 to 0.54167, saving model to model_part2.hdf5

Epoch 00134: loss improved from 0.54167 to 0.53621, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.53621 to 0.53201, saving model to model_part2.hdf5

Epoch 00136: loss improved from 0.53201 to 0.52966, saving model to model_part2.hdf5

Epoch 00137: loss improved from 0.52966 to 0.52572, saving model to model_part2.hdf5

Epoch 00138: loss improved from 0.52572 to 0.52386, saving model to model_part2.hdf5

Epoch 00139: loss improved from 0.52386 to 0.52113, saving model to model_part2.hdf5

Epoch 00140: loss improved from 0.52113 to 0.51743, saving model to model_part2.hdf5

Epoch 00141: loss improved from 0.51743 to 0.51480, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.51480 to 0.51206, saving model to model_part2.hdf5

Epoch 00143: loss improved from 0.51206 to 0.51082, saving model to model_part2.hdf5

Epoch 00144: loss improved from 0.51082 to 0.51008, saving model to model_part2.hdf5

Epoch 00145: loss improved from 0.51008 to 0.50564, saving model to model_part2.hdf5

Epoch 00146: loss improved from 0.50564 to 0.50039, saving model to model_part2.hdf5

Epoch 00147: loss improved from 0.50039 to 0.49684, saving model to model_part2.hdf5

Epoch 00148: loss improved from 0.49684 to 0.49418, saving model to model_part2.hdf5

Epoch 00149: loss improved from 0.49418 to 0.49159, saving model to model_part2.hdf5

Epoch 00150: loss improved from 0.49159 to 0.49104, saving model to model_part2.hdf5

Epoch 00151: loss improved from 0.49104 to 0.48465, saving model to model_part2.hdf5

Epoch 00152: loss improved from 0.48465 to 0.48226, saving model to model_part2.hdf5

Epoch 00153: loss improved from 0.48226 to 0.47852, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.47852 to 0.47604, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.47604 to 0.47075, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.47075 to 0.46862, saving model to model_part2.hdf5

Epoch 00157: loss improved from 0.46862 to 0.46669, saving model to model_part2.hdf5

Epoch 00158: loss improved from 0.46669 to 0.46421, saving model to model_part2.hdf5

Epoch 00159: loss improved from 0.46421 to 0.45796, saving model to model_part2.hdf5

Epoch 00160: loss improved from 0.45796 to 0.45479, saving model to model_part2.hdf5

Epoch 00161: loss improved from 0.45479 to 0.45174, saving model to model_part2.hdf5

Epoch 00162: loss improved from 0.45174 to 0.44986, saving model to model_part2.hdf5

Epoch 00163: loss improved from 0.44986 to 0.44564, saving model to model_part2.hdf5

Epoch 00164: loss improved from 0.44564 to 0.44263, saving model to model_part2.hdf5

Epoch 00165: loss improved from 0.44263 to 0.44056, saving model to model_part2.hdf5

Epoch 00166: loss improved from 0.44056 to 0.43860, saving model to model_part2.hdf5

Epoch 00167: loss improved from 0.43860 to 0.43688, saving model to model_part2.hdf5

Epoch 00168: loss improved from 0.43688 to 0.42933, saving model to model_part2.hdf5

Epoch 00169: loss improved from 0.42933 to 0.42627, saving model to model_part2.hdf5

Epoch 00170: loss improved from 0.42627 to 0.42321, saving model to model_part2.hdf5

Epoch 00171: loss improved from 0.42321 to 0.42073, saving model to model_part2.hdf5

Epoch 00172: loss improved from 0.42073 to 0.41600, saving model to model_part2.hdf5

Epoch 00173: loss improved from 0.41600 to 0.41446, saving model to model_part2.hdf5

Epoch 00174: loss improved from 0.41446 to 0.40955, saving model to model_part2.hdf5

Epoch 00175: loss improved from 0.40955 to 0.40849, saving model to model_part2.hdf5

Epoch 00176: loss improved from 0.40849 to 0.40457, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.40457 to 0.40401, saving model to model_part2.hdf5

Epoch 00178: loss improved from 0.40401 to 0.40006, saving model to model_part2.hdf5

Epoch 00179: loss improved from 0.40006 to 0.39717, saving model to model_part2.hdf5

Epoch 00180: loss improved from 0.39717 to 0.39526, saving model to model_part2.hdf5

Epoch 00181: loss improved from 0.39526 to 0.39250, saving model to model_part2.hdf5

Epoch 00182: loss improved from 0.39250 to 0.38834, saving model to model_part2.hdf5

Epoch 00183: loss improved from 0.38834 to 0.38286, saving model to model_part2.hdf5

Epoch 00184: loss improved from 0.38286 to 0.37862, saving model to model_part2.hdf5

Epoch 00185: loss improved from 0.37862 to 0.37601, saving model to model_part2.hdf5

Epoch 00186: loss improved from 0.37601 to 0.37214, saving model to model_part2.hdf5

Epoch 00187: loss did not improve from 0.37214

Epoch 00188: loss improved from 0.37214 to 0.36707, saving model to model_part2.hdf5

Epoch 00189: loss improved from 0.36707 to 0.36327, saving model to model_part2.hdf5

Epoch 00190: loss improved from 0.36327 to 0.36008, saving model to model_part2.hdf5

Epoch 00191: loss improved from 0.36008 to 0.35723, saving model to model_part2.hdf5

Epoch 00192: loss improved from 0.35723 to 0.35612, saving model to model_part2.hdf5

Epoch 00193: loss improved from 0.35612 to 0.35136, saving model to model_part2.hdf5

Epoch 00194: loss improved from 0.35136 to 0.34757, saving model to model_part2.hdf5

Epoch 00195: loss improved from 0.34757 to 0.34555, saving model to model_part2.hdf5

Epoch 00196: loss improved from 0.34555 to 0.34256, saving model to model_part2.hdf5

Epoch 00197: loss improved from 0.34256 to 0.33899, saving model to model_part2.hdf5

Epoch 00198: loss improved from 0.33899 to 0.33548, saving model to model_part2.hdf5

Epoch 00199: loss did not improve from 0.33548

Epoch 00200: loss improved from 0.33548 to 0.33323, saving model to model_part2.hdf5

Epoch 00201: loss improved from 0.33323 to 0.32801, saving model to model_part2.hdf5

Epoch 00202: loss improved from 0.32801 to 0.32624, saving model to model_part2.hdf5

Epoch 00203: loss improved from 0.32624 to 0.32366, saving model to model_part2.hdf5

Epoch 00204: loss did not improve from 0.32366

Epoch 00205: loss improved from 0.32366 to 0.32067, saving model to model_part2.hdf5

Epoch 00206: loss improved from 0.32067 to 0.31506, saving model to model_part2.hdf5

Epoch 00207: loss improved from 0.31506 to 0.31365, saving model to model_part2.hdf5

Epoch 00208: loss improved from 0.31365 to 0.31057, saving model to model_part2.hdf5

Epoch 00209: loss improved from 0.31057 to 0.30813, saving model to model_part2.hdf5

Epoch 00210: loss improved from 0.30813 to 0.30523, saving model to model_part2.hdf5

Epoch 00211: loss improved from 0.30523 to 0.30393, saving model to model_part2.hdf5

Epoch 00212: loss improved from 0.30393 to 0.30160, saving model to model_part2.hdf5

Epoch 00213: loss improved from 0.30160 to 0.29730, saving model to model_part2.hdf5

Epoch 00214: loss improved from 0.29730 to 0.29576, saving model to model_part2.hdf5

Epoch 00215: loss improved from 0.29576 to 0.29315, saving model to model_part2.hdf5

Epoch 00216: loss improved from 0.29315 to 0.28994, saving model to model_part2.hdf5

Epoch 00217: loss did not improve from 0.28994

Epoch 00218: loss improved from 0.28994 to 0.28611, saving model to model_part2.hdf5

Epoch 00219: loss improved from 0.28611 to 0.28265, saving model to model_part2.hdf5

Epoch 00220: loss improved from 0.28265 to 0.28133, saving model to model_part2.hdf5

Epoch 00221: loss improved from 0.28133 to 0.28103, saving model to model_part2.hdf5

Epoch 00222: loss improved from 0.28103 to 0.27683, saving model to model_part2.hdf5

Epoch 00223: loss improved from 0.27683 to 0.27426, saving model to model_part2.hdf5

Epoch 00224: loss improved from 0.27426 to 0.27395, saving model to model_part2.hdf5

Epoch 00225: loss improved from 0.27395 to 0.27036, saving model to model_part2.hdf5

Epoch 00226: loss improved from 0.27036 to 0.26821, saving model to model_part2.hdf5

Epoch 00227: loss improved from 0.26821 to 0.26548, saving model to model_part2.hdf5

Epoch 00228: loss did not improve from 0.26548

Epoch 00229: loss improved from 0.26548 to 0.26235, saving model to model_part2.hdf5

Epoch 00230: loss did not improve from 0.26235

Epoch 00231: loss improved from 0.26235 to 0.25781, saving model to model_part2.hdf5

Epoch 00232: loss improved from 0.25781 to 0.25692, saving model to model_part2.hdf5
Testing the model
45/45 [==============================] - 0s 2ms/step
====================================================

====================================================
Percent Training Size  0.9
Training the Model

Epoch 00001: loss improved from inf to 1.08884, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.08884 to 1.07605, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.07605 to 1.05985, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.05985 to 1.04430, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.04430 to 1.03198, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.03198 to 1.02194, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.02194 to 1.01270, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.01270 to 1.00350, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.00350 to 0.99388, saving model to model_part2.hdf5

Epoch 00010: loss improved from 0.99388 to 0.98409, saving model to model_part2.hdf5

Epoch 00011: loss improved from 0.98409 to 0.97363, saving model to model_part2.hdf5

Epoch 00012: loss improved from 0.97363 to 0.96161, saving model to model_part2.hdf5

Epoch 00013: loss improved from 0.96161 to 0.95063, saving model to model_part2.hdf5

Epoch 00014: loss improved from 0.95063 to 0.94078, saving model to model_part2.hdf5

Epoch 00015: loss improved from 0.94078 to 0.93172, saving model to model_part2.hdf5

Epoch 00016: loss improved from 0.93172 to 0.92259, saving model to model_part2.hdf5

Epoch 00017: loss improved from 0.92259 to 0.91490, saving model to model_part2.hdf5

Epoch 00018: loss improved from 0.91490 to 0.90564, saving model to model_part2.hdf5

Epoch 00019: loss improved from 0.90564 to 0.89765, saving model to model_part2.hdf5

Epoch 00020: loss improved from 0.89765 to 0.88911, saving model to model_part2.hdf5

Epoch 00021: loss improved from 0.88911 to 0.88175, saving model to model_part2.hdf5

Epoch 00022: loss improved from 0.88175 to 0.87548, saving model to model_part2.hdf5

Epoch 00023: loss improved from 0.87548 to 0.86906, saving model to model_part2.hdf5

Epoch 00024: loss improved from 0.86906 to 0.86145, saving model to model_part2.hdf5

Epoch 00025: loss improved from 0.86145 to 0.85627, saving model to model_part2.hdf5

Epoch 00026: loss improved from 0.85627 to 0.85063, saving model to model_part2.hdf5

Epoch 00027: loss improved from 0.85063 to 0.84585, saving model to model_part2.hdf5

Epoch 00028: loss improved from 0.84585 to 0.83993, saving model to model_part2.hdf5

Epoch 00029: loss improved from 0.83993 to 0.83511, saving model to model_part2.hdf5

Epoch 00030: loss improved from 0.83511 to 0.83343, saving model to model_part2.hdf5

Epoch 00031: loss improved from 0.83343 to 0.82658, saving model to model_part2.hdf5

Epoch 00032: loss improved from 0.82658 to 0.82257, saving model to model_part2.hdf5

Epoch 00033: loss improved from 0.82257 to 0.81828, saving model to model_part2.hdf5

Epoch 00034: loss improved from 0.81828 to 0.81416, saving model to model_part2.hdf5

Epoch 00035: loss improved from 0.81416 to 0.80975, saving model to model_part2.hdf5

Epoch 00036: loss improved from 0.80975 to 0.80574, saving model to model_part2.hdf5

Epoch 00037: loss improved from 0.80574 to 0.80329, saving model to model_part2.hdf5

Epoch 00038: loss improved from 0.80329 to 0.79550, saving model to model_part2.hdf5

Epoch 00039: loss improved from 0.79550 to 0.79250, saving model to model_part2.hdf5

Epoch 00040: loss improved from 0.79250 to 0.78739, saving model to model_part2.hdf5

Epoch 00041: loss improved from 0.78739 to 0.78411, saving model to model_part2.hdf5

Epoch 00042: loss improved from 0.78411 to 0.77956, saving model to model_part2.hdf5

Epoch 00043: loss improved from 0.77956 to 0.77397, saving model to model_part2.hdf5

Epoch 00044: loss improved from 0.77397 to 0.77001, saving model to model_part2.hdf5

Epoch 00045: loss improved from 0.77001 to 0.76700, saving model to model_part2.hdf5

Epoch 00046: loss improved from 0.76700 to 0.76281, saving model to model_part2.hdf5

Epoch 00047: loss improved from 0.76281 to 0.75786, saving model to model_part2.hdf5

Epoch 00048: loss improved from 0.75786 to 0.75479, saving model to model_part2.hdf5

Epoch 00049: loss improved from 0.75479 to 0.75221, saving model to model_part2.hdf5

Epoch 00050: loss improved from 0.75221 to 0.74741, saving model to model_part2.hdf5

Epoch 00051: loss improved from 0.74741 to 0.74387, saving model to model_part2.hdf5

Epoch 00052: loss improved from 0.74387 to 0.74194, saving model to model_part2.hdf5

Epoch 00053: loss improved from 0.74194 to 0.73828, saving model to model_part2.hdf5

Epoch 00054: loss improved from 0.73828 to 0.73483, saving model to model_part2.hdf5

Epoch 00055: loss improved from 0.73483 to 0.73088, saving model to model_part2.hdf5

Epoch 00056: loss improved from 0.73088 to 0.72648, saving model to model_part2.hdf5

Epoch 00057: loss improved from 0.72648 to 0.72308, saving model to model_part2.hdf5

Epoch 00058: loss improved from 0.72308 to 0.71952, saving model to model_part2.hdf5

Epoch 00059: loss improved from 0.71952 to 0.71578, saving model to model_part2.hdf5

Epoch 00060: loss improved from 0.71578 to 0.71183, saving model to model_part2.hdf5

Epoch 00061: loss improved from 0.71183 to 0.70791, saving model to model_part2.hdf5

Epoch 00062: loss improved from 0.70791 to 0.70362, saving model to model_part2.hdf5

Epoch 00063: loss improved from 0.70362 to 0.70012, saving model to model_part2.hdf5

Epoch 00064: loss improved from 0.70012 to 0.69473, saving model to model_part2.hdf5

Epoch 00065: loss improved from 0.69473 to 0.69147, saving model to model_part2.hdf5

Epoch 00066: loss improved from 0.69147 to 0.68561, saving model to model_part2.hdf5

Epoch 00067: loss improved from 0.68561 to 0.68061, saving model to model_part2.hdf5

Epoch 00068: loss improved from 0.68061 to 0.67659, saving model to model_part2.hdf5

Epoch 00069: loss improved from 0.67659 to 0.67042, saving model to model_part2.hdf5

Epoch 00070: loss improved from 0.67042 to 0.66458, saving model to model_part2.hdf5

Epoch 00071: loss improved from 0.66458 to 0.66083, saving model to model_part2.hdf5

Epoch 00072: loss improved from 0.66083 to 0.65594, saving model to model_part2.hdf5

Epoch 00073: loss improved from 0.65594 to 0.65051, saving model to model_part2.hdf5

Epoch 00074: loss improved from 0.65051 to 0.64463, saving model to model_part2.hdf5

Epoch 00075: loss improved from 0.64463 to 0.64002, saving model to model_part2.hdf5

Epoch 00076: loss improved from 0.64002 to 0.63564, saving model to model_part2.hdf5

Epoch 00077: loss improved from 0.63564 to 0.62876, saving model to model_part2.hdf5

Epoch 00078: loss improved from 0.62876 to 0.62322, saving model to model_part2.hdf5

Epoch 00079: loss improved from 0.62322 to 0.61898, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.61898 to 0.61323, saving model to model_part2.hdf5

Epoch 00081: loss improved from 0.61323 to 0.60613, saving model to model_part2.hdf5

Epoch 00082: loss improved from 0.60613 to 0.60096, saving model to model_part2.hdf5

Epoch 00083: loss improved from 0.60096 to 0.59338, saving model to model_part2.hdf5

Epoch 00084: loss improved from 0.59338 to 0.58793, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.58793 to 0.58169, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.58169 to 0.57581, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.57581 to 0.57036, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.57036 to 0.56373, saving model to model_part2.hdf5

Epoch 00089: loss improved from 0.56373 to 0.55868, saving model to model_part2.hdf5

Epoch 00090: loss improved from 0.55868 to 0.55195, saving model to model_part2.hdf5

Epoch 00091: loss improved from 0.55195 to 0.54654, saving model to model_part2.hdf5

Epoch 00092: loss improved from 0.54654 to 0.53847, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.53847 to 0.53113, saving model to model_part2.hdf5

Epoch 00094: loss improved from 0.53113 to 0.52535, saving model to model_part2.hdf5

Epoch 00095: loss improved from 0.52535 to 0.51684, saving model to model_part2.hdf5

Epoch 00096: loss improved from 0.51684 to 0.51017, saving model to model_part2.hdf5

Epoch 00097: loss improved from 0.51017 to 0.50282, saving model to model_part2.hdf5

Epoch 00098: loss improved from 0.50282 to 0.49469, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.49469 to 0.48707, saving model to model_part2.hdf5

Epoch 00100: loss improved from 0.48707 to 0.47968, saving model to model_part2.hdf5

Epoch 00101: loss improved from 0.47968 to 0.47155, saving model to model_part2.hdf5

Epoch 00102: loss improved from 0.47155 to 0.46380, saving model to model_part2.hdf5

Epoch 00103: loss improved from 0.46380 to 0.45703, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.45703 to 0.44894, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.44894 to 0.43926, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.43926 to 0.43149, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.43149 to 0.42373, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.42373 to 0.41621, saving model to model_part2.hdf5

Epoch 00109: loss improved from 0.41621 to 0.40884, saving model to model_part2.hdf5

Epoch 00110: loss improved from 0.40884 to 0.40081, saving model to model_part2.hdf5

Epoch 00111: loss improved from 0.40081 to 0.39556, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.39556 to 0.38639, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.38639 to 0.37898, saving model to model_part2.hdf5

Epoch 00114: loss improved from 0.37898 to 0.37236, saving model to model_part2.hdf5

Epoch 00115: loss improved from 0.37236 to 0.36601, saving model to model_part2.hdf5

Epoch 00116: loss improved from 0.36601 to 0.36006, saving model to model_part2.hdf5

Epoch 00117: loss improved from 0.36006 to 0.35549, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.35549 to 0.34989, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.34989 to 0.34534, saving model to model_part2.hdf5

Epoch 00120: loss improved from 0.34534 to 0.33849, saving model to model_part2.hdf5

Epoch 00121: loss improved from 0.33849 to 0.33439, saving model to model_part2.hdf5

Epoch 00122: loss improved from 0.33439 to 0.32939, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.32939 to 0.32547, saving model to model_part2.hdf5

Epoch 00124: loss improved from 0.32547 to 0.32160, saving model to model_part2.hdf5

Epoch 00125: loss improved from 0.32160 to 0.31712, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.31712 to 0.31323, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.31323 to 0.30877, saving model to model_part2.hdf5

Epoch 00128: loss improved from 0.30877 to 0.30678, saving model to model_part2.hdf5

Epoch 00129: loss improved from 0.30678 to 0.30420, saving model to model_part2.hdf5

Epoch 00130: loss improved from 0.30420 to 0.29827, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.29827 to 0.29672, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.29672 to 0.29239, saving model to model_part2.hdf5

Epoch 00133: loss improved from 0.29239 to 0.29228, saving model to model_part2.hdf5

Epoch 00134: loss improved from 0.29228 to 0.28720, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.28720 to 0.28407, saving model to model_part2.hdf5

Epoch 00136: loss improved from 0.28407 to 0.28189, saving model to model_part2.hdf5

Epoch 00137: loss improved from 0.28189 to 0.28038, saving model to model_part2.hdf5

Epoch 00138: loss improved from 0.28038 to 0.27603, saving model to model_part2.hdf5

Epoch 00139: loss improved from 0.27603 to 0.27454, saving model to model_part2.hdf5

Epoch 00140: loss improved from 0.27454 to 0.27167, saving model to model_part2.hdf5

Epoch 00141: loss improved from 0.27167 to 0.27019, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.27019 to 0.26686, saving model to model_part2.hdf5

Epoch 00143: loss improved from 0.26686 to 0.26564, saving model to model_part2.hdf5

Epoch 00144: loss improved from 0.26564 to 0.26542, saving model to model_part2.hdf5

Epoch 00145: loss improved from 0.26542 to 0.26246, saving model to model_part2.hdf5

Epoch 00146: loss improved from 0.26246 to 0.25875, saving model to model_part2.hdf5

Epoch 00147: loss improved from 0.25875 to 0.25804, saving model to model_part2.hdf5

Epoch 00148: loss improved from 0.25804 to 0.25702, saving model to model_part2.hdf5

Epoch 00149: loss improved from 0.25702 to 0.25348, saving model to model_part2.hdf5

Epoch 00150: loss did not improve from 0.25348

Epoch 00151: loss improved from 0.25348 to 0.25103, saving model to model_part2.hdf5

Epoch 00152: loss improved from 0.25103 to 0.24913, saving model to model_part2.hdf5

Epoch 00153: loss improved from 0.24913 to 0.24755, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.24755 to 0.24627, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.24627 to 0.24623, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.24623 to 0.24351, saving model to model_part2.hdf5

Epoch 00157: loss improved from 0.24351 to 0.24155, saving model to model_part2.hdf5

Epoch 00158: loss improved from 0.24155 to 0.24077, saving model to model_part2.hdf5

Epoch 00159: loss improved from 0.24077 to 0.23928, saving model to model_part2.hdf5

Epoch 00160: loss did not improve from 0.23928

Epoch 00161: loss improved from 0.23928 to 0.23596, saving model to model_part2.hdf5

Epoch 00162: loss did not improve from 0.23596

Epoch 00163: loss improved from 0.23596 to 0.23290, saving model to model_part2.hdf5

Epoch 00164: loss did not improve from 0.23290

Epoch 00165: loss improved from 0.23290 to 0.23015, saving model to model_part2.hdf5

Epoch 00166: loss improved from 0.23015 to 0.22916, saving model to model_part2.hdf5

Epoch 00167: loss did not improve from 0.22916

Epoch 00168: loss improved from 0.22916 to 0.22851, saving model to model_part2.hdf5

Epoch 00169: loss improved from 0.22851 to 0.22609, saving model to model_part2.hdf5

Epoch 00170: loss improved from 0.22609 to 0.22442, saving model to model_part2.hdf5

Epoch 00171: loss improved from 0.22442 to 0.22415, saving model to model_part2.hdf5

Epoch 00172: loss improved from 0.22415 to 0.22202, saving model to model_part2.hdf5

Epoch 00173: loss did not improve from 0.22202

Epoch 00174: loss improved from 0.22202 to 0.22094, saving model to model_part2.hdf5

Epoch 00175: loss improved from 0.22094 to 0.21998, saving model to model_part2.hdf5

Epoch 00176: loss improved from 0.21998 to 0.21891, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.21891 to 0.21770, saving model to model_part2.hdf5

Epoch 00178: loss improved from 0.21770 to 0.21490, saving model to model_part2.hdf5

Epoch 00179: loss improved from 0.21490 to 0.21435, saving model to model_part2.hdf5

Epoch 00180: loss improved from 0.21435 to 0.21323, saving model to model_part2.hdf5

Epoch 00181: loss improved from 0.21323 to 0.21231, saving model to model_part2.hdf5

Epoch 00182: loss improved from 0.21231 to 0.21000, saving model to model_part2.hdf5

Epoch 00183: loss did not improve from 0.21000

Epoch 00184: loss did not improve from 0.21000

Epoch 00185: loss improved from 0.21000 to 0.20693, saving model to model_part2.hdf5

Epoch 00186: loss improved from 0.20693 to 0.20601, saving model to model_part2.hdf5

Epoch 00187: loss did not improve from 0.20601

Epoch 00188: loss improved from 0.20601 to 0.20386, saving model to model_part2.hdf5

Epoch 00189: loss improved from 0.20386 to 0.20263, saving model to model_part2.hdf5

Epoch 00190: loss improved from 0.20263 to 0.20231, saving model to model_part2.hdf5

Epoch 00191: loss did not improve from 0.20231

Epoch 00192: loss improved from 0.20231 to 0.19960, saving model to model_part2.hdf5

Epoch 00193: loss improved from 0.19960 to 0.19955, saving model to model_part2.hdf5

Epoch 00194: loss improved from 0.19955 to 0.19800, saving model to model_part2.hdf5

Epoch 00195: loss improved from 0.19800 to 0.19791, saving model to model_part2.hdf5

Epoch 00196: loss improved from 0.19791 to 0.19577, saving model to model_part2.hdf5

Epoch 00197: loss improved from 0.19577 to 0.19510, saving model to model_part2.hdf5
Testing the model
45/45 [==============================] - 0s 2ms/step
====================================================

====================================================
Percent Training Size  1
Training the Model

Epoch 00001: loss improved from inf to 1.09749, saving model to model_part2.hdf5

Epoch 00002: loss improved from 1.09749 to 1.09543, saving model to model_part2.hdf5

Epoch 00003: loss improved from 1.09543 to 1.09372, saving model to model_part2.hdf5

Epoch 00004: loss improved from 1.09372 to 1.09179, saving model to model_part2.hdf5

Epoch 00005: loss improved from 1.09179 to 1.08889, saving model to model_part2.hdf5

Epoch 00006: loss improved from 1.08889 to 1.08639, saving model to model_part2.hdf5

Epoch 00007: loss improved from 1.08639 to 1.08242, saving model to model_part2.hdf5

Epoch 00008: loss improved from 1.08242 to 1.07939, saving model to model_part2.hdf5

Epoch 00009: loss improved from 1.07939 to 1.07618, saving model to model_part2.hdf5

Epoch 00010: loss improved from 1.07618 to 1.07346, saving model to model_part2.hdf5

Epoch 00011: loss improved from 1.07346 to 1.06999, saving model to model_part2.hdf5

Epoch 00012: loss improved from 1.06999 to 1.06742, saving model to model_part2.hdf5

Epoch 00013: loss improved from 1.06742 to 1.06395, saving model to model_part2.hdf5

Epoch 00014: loss improved from 1.06395 to 1.06066, saving model to model_part2.hdf5

Epoch 00015: loss improved from 1.06066 to 1.05741, saving model to model_part2.hdf5

Epoch 00016: loss improved from 1.05741 to 1.05370, saving model to model_part2.hdf5

Epoch 00017: loss improved from 1.05370 to 1.04992, saving model to model_part2.hdf5

Epoch 00018: loss improved from 1.04992 to 1.04692, saving model to model_part2.hdf5

Epoch 00019: loss improved from 1.04692 to 1.04284, saving model to model_part2.hdf5

Epoch 00020: loss improved from 1.04284 to 1.03888, saving model to model_part2.hdf5

Epoch 00021: loss improved from 1.03888 to 1.03488, saving model to model_part2.hdf5

Epoch 00022: loss improved from 1.03488 to 1.03073, saving model to model_part2.hdf5

Epoch 00023: loss improved from 1.03073 to 1.02660, saving model to model_part2.hdf5

Epoch 00024: loss improved from 1.02660 to 1.02216, saving model to model_part2.hdf5

Epoch 00025: loss improved from 1.02216 to 1.01775, saving model to model_part2.hdf5

Epoch 00026: loss improved from 1.01775 to 1.01310, saving model to model_part2.hdf5

Epoch 00027: loss improved from 1.01310 to 1.00949, saving model to model_part2.hdf5

Epoch 00028: loss improved from 1.00949 to 1.00514, saving model to model_part2.hdf5

Epoch 00029: loss improved from 1.00514 to 0.99972, saving model to model_part2.hdf5

Epoch 00030: loss improved from 0.99972 to 0.99517, saving model to model_part2.hdf5

Epoch 00031: loss improved from 0.99517 to 0.99159, saving model to model_part2.hdf5

Epoch 00032: loss improved from 0.99159 to 0.98648, saving model to model_part2.hdf5

Epoch 00033: loss improved from 0.98648 to 0.98150, saving model to model_part2.hdf5

Epoch 00034: loss improved from 0.98150 to 0.97670, saving model to model_part2.hdf5

Epoch 00035: loss improved from 0.97670 to 0.97150, saving model to model_part2.hdf5

Epoch 00036: loss improved from 0.97150 to 0.96650, saving model to model_part2.hdf5

Epoch 00037: loss improved from 0.96650 to 0.96108, saving model to model_part2.hdf5

Epoch 00038: loss improved from 0.96108 to 0.95553, saving model to model_part2.hdf5

Epoch 00039: loss improved from 0.95553 to 0.94961, saving model to model_part2.hdf5

Epoch 00040: loss improved from 0.94961 to 0.94396, saving model to model_part2.hdf5

Epoch 00041: loss improved from 0.94396 to 0.93837, saving model to model_part2.hdf5

Epoch 00042: loss improved from 0.93837 to 0.93205, saving model to model_part2.hdf5

Epoch 00043: loss improved from 0.93205 to 0.92624, saving model to model_part2.hdf5

Epoch 00044: loss improved from 0.92624 to 0.92032, saving model to model_part2.hdf5

Epoch 00045: loss improved from 0.92032 to 0.91463, saving model to model_part2.hdf5

Epoch 00046: loss improved from 0.91463 to 0.90897, saving model to model_part2.hdf5

Epoch 00047: loss improved from 0.90897 to 0.90292, saving model to model_part2.hdf5

Epoch 00048: loss improved from 0.90292 to 0.89730, saving model to model_part2.hdf5

Epoch 00049: loss improved from 0.89730 to 0.89104, saving model to model_part2.hdf5

Epoch 00050: loss improved from 0.89104 to 0.88648, saving model to model_part2.hdf5

Epoch 00051: loss improved from 0.88648 to 0.88053, saving model to model_part2.hdf5

Epoch 00052: loss improved from 0.88053 to 0.87534, saving model to model_part2.hdf5

Epoch 00053: loss improved from 0.87534 to 0.86906, saving model to model_part2.hdf5

Epoch 00054: loss improved from 0.86906 to 0.86548, saving model to model_part2.hdf5

Epoch 00055: loss improved from 0.86548 to 0.85816, saving model to model_part2.hdf5

Epoch 00056: loss improved from 0.85816 to 0.85315, saving model to model_part2.hdf5

Epoch 00057: loss improved from 0.85315 to 0.84800, saving model to model_part2.hdf5

Epoch 00058: loss improved from 0.84800 to 0.84292, saving model to model_part2.hdf5

Epoch 00059: loss improved from 0.84292 to 0.83858, saving model to model_part2.hdf5

Epoch 00060: loss improved from 0.83858 to 0.83198, saving model to model_part2.hdf5

Epoch 00061: loss improved from 0.83198 to 0.82822, saving model to model_part2.hdf5

Epoch 00062: loss improved from 0.82822 to 0.82258, saving model to model_part2.hdf5

Epoch 00063: loss improved from 0.82258 to 0.81803, saving model to model_part2.hdf5

Epoch 00064: loss improved from 0.81803 to 0.81247, saving model to model_part2.hdf5

Epoch 00065: loss improved from 0.81247 to 0.80770, saving model to model_part2.hdf5

Epoch 00066: loss improved from 0.80770 to 0.80327, saving model to model_part2.hdf5

Epoch 00067: loss improved from 0.80327 to 0.79763, saving model to model_part2.hdf5

Epoch 00068: loss improved from 0.79763 to 0.79393, saving model to model_part2.hdf5

Epoch 00069: loss improved from 0.79393 to 0.78833, saving model to model_part2.hdf5

Epoch 00070: loss improved from 0.78833 to 0.78524, saving model to model_part2.hdf5

Epoch 00071: loss improved from 0.78524 to 0.77940, saving model to model_part2.hdf5

Epoch 00072: loss improved from 0.77940 to 0.77421, saving model to model_part2.hdf5

Epoch 00073: loss improved from 0.77421 to 0.76970, saving model to model_part2.hdf5

Epoch 00074: loss improved from 0.76970 to 0.76533, saving model to model_part2.hdf5

Epoch 00075: loss improved from 0.76533 to 0.76049, saving model to model_part2.hdf5

Epoch 00076: loss improved from 0.76049 to 0.75608, saving model to model_part2.hdf5

Epoch 00077: loss improved from 0.75608 to 0.75156, saving model to model_part2.hdf5

Epoch 00078: loss improved from 0.75156 to 0.74709, saving model to model_part2.hdf5

Epoch 00079: loss improved from 0.74709 to 0.74289, saving model to model_part2.hdf5

Epoch 00080: loss improved from 0.74289 to 0.73762, saving model to model_part2.hdf5

Epoch 00081: loss improved from 0.73762 to 0.73294, saving model to model_part2.hdf5

Epoch 00082: loss improved from 0.73294 to 0.72901, saving model to model_part2.hdf5

Epoch 00083: loss improved from 0.72901 to 0.72606, saving model to model_part2.hdf5

Epoch 00084: loss improved from 0.72606 to 0.72058, saving model to model_part2.hdf5

Epoch 00085: loss improved from 0.72058 to 0.71643, saving model to model_part2.hdf5

Epoch 00086: loss improved from 0.71643 to 0.71093, saving model to model_part2.hdf5

Epoch 00087: loss improved from 0.71093 to 0.70671, saving model to model_part2.hdf5

Epoch 00088: loss improved from 0.70671 to 0.70334, saving model to model_part2.hdf5

Epoch 00089: loss improved from 0.70334 to 0.69935, saving model to model_part2.hdf5

Epoch 00090: loss improved from 0.69935 to 0.69408, saving model to model_part2.hdf5

Epoch 00091: loss improved from 0.69408 to 0.68995, saving model to model_part2.hdf5

Epoch 00092: loss improved from 0.68995 to 0.68607, saving model to model_part2.hdf5

Epoch 00093: loss improved from 0.68607 to 0.68178, saving model to model_part2.hdf5

Epoch 00094: loss improved from 0.68178 to 0.67764, saving model to model_part2.hdf5

Epoch 00095: loss improved from 0.67764 to 0.67408, saving model to model_part2.hdf5

Epoch 00096: loss improved from 0.67408 to 0.66843, saving model to model_part2.hdf5

Epoch 00097: loss improved from 0.66843 to 0.66506, saving model to model_part2.hdf5

Epoch 00098: loss improved from 0.66506 to 0.65982, saving model to model_part2.hdf5

Epoch 00099: loss improved from 0.65982 to 0.65477, saving model to model_part2.hdf5

Epoch 00100: loss improved from 0.65477 to 0.65012, saving model to model_part2.hdf5

Epoch 00101: loss improved from 0.65012 to 0.64565, saving model to model_part2.hdf5

Epoch 00102: loss improved from 0.64565 to 0.64083, saving model to model_part2.hdf5

Epoch 00103: loss improved from 0.64083 to 0.63594, saving model to model_part2.hdf5

Epoch 00104: loss improved from 0.63594 to 0.63100, saving model to model_part2.hdf5

Epoch 00105: loss improved from 0.63100 to 0.62697, saving model to model_part2.hdf5

Epoch 00106: loss improved from 0.62697 to 0.62216, saving model to model_part2.hdf5

Epoch 00107: loss improved from 0.62216 to 0.61740, saving model to model_part2.hdf5

Epoch 00108: loss improved from 0.61740 to 0.61200, saving model to model_part2.hdf5

Epoch 00109: loss improved from 0.61200 to 0.60676, saving model to model_part2.hdf5

Epoch 00110: loss improved from 0.60676 to 0.60300, saving model to model_part2.hdf5

Epoch 00111: loss improved from 0.60300 to 0.59786, saving model to model_part2.hdf5

Epoch 00112: loss improved from 0.59786 to 0.59230, saving model to model_part2.hdf5

Epoch 00113: loss improved from 0.59230 to 0.58753, saving model to model_part2.hdf5

Epoch 00114: loss improved from 0.58753 to 0.58234, saving model to model_part2.hdf5

Epoch 00115: loss improved from 0.58234 to 0.57790, saving model to model_part2.hdf5

Epoch 00116: loss improved from 0.57790 to 0.57596, saving model to model_part2.hdf5

Epoch 00117: loss improved from 0.57596 to 0.56827, saving model to model_part2.hdf5

Epoch 00118: loss improved from 0.56827 to 0.56263, saving model to model_part2.hdf5

Epoch 00119: loss improved from 0.56263 to 0.55803, saving model to model_part2.hdf5

Epoch 00120: loss improved from 0.55803 to 0.55482, saving model to model_part2.hdf5

Epoch 00121: loss improved from 0.55482 to 0.54945, saving model to model_part2.hdf5

Epoch 00122: loss improved from 0.54945 to 0.54369, saving model to model_part2.hdf5

Epoch 00123: loss improved from 0.54369 to 0.53952, saving model to model_part2.hdf5

Epoch 00124: loss improved from 0.53952 to 0.53560, saving model to model_part2.hdf5

Epoch 00125: loss improved from 0.53560 to 0.52984, saving model to model_part2.hdf5

Epoch 00126: loss improved from 0.52984 to 0.52633, saving model to model_part2.hdf5

Epoch 00127: loss improved from 0.52633 to 0.52003, saving model to model_part2.hdf5

Epoch 00128: loss improved from 0.52003 to 0.51464, saving model to model_part2.hdf5

Epoch 00129: loss improved from 0.51464 to 0.50961, saving model to model_part2.hdf5

Epoch 00130: loss improved from 0.50961 to 0.50540, saving model to model_part2.hdf5

Epoch 00131: loss improved from 0.50540 to 0.50248, saving model to model_part2.hdf5

Epoch 00132: loss improved from 0.50248 to 0.49514, saving model to model_part2.hdf5

Epoch 00133: loss improved from 0.49514 to 0.48957, saving model to model_part2.hdf5

Epoch 00134: loss improved from 0.48957 to 0.48614, saving model to model_part2.hdf5

Epoch 00135: loss improved from 0.48614 to 0.48010, saving model to model_part2.hdf5

Epoch 00136: loss improved from 0.48010 to 0.47489, saving model to model_part2.hdf5

Epoch 00137: loss improved from 0.47489 to 0.46996, saving model to model_part2.hdf5

Epoch 00138: loss improved from 0.46996 to 0.46515, saving model to model_part2.hdf5

Epoch 00139: loss improved from 0.46515 to 0.46043, saving model to model_part2.hdf5

Epoch 00140: loss improved from 0.46043 to 0.45713, saving model to model_part2.hdf5

Epoch 00141: loss improved from 0.45713 to 0.45143, saving model to model_part2.hdf5

Epoch 00142: loss improved from 0.45143 to 0.44599, saving model to model_part2.hdf5

Epoch 00143: loss improved from 0.44599 to 0.44201, saving model to model_part2.hdf5

Epoch 00144: loss improved from 0.44201 to 0.43711, saving model to model_part2.hdf5

Epoch 00145: loss improved from 0.43711 to 0.43248, saving model to model_part2.hdf5

Epoch 00146: loss improved from 0.43248 to 0.42694, saving model to model_part2.hdf5

Epoch 00147: loss improved from 0.42694 to 0.42278, saving model to model_part2.hdf5

Epoch 00148: loss improved from 0.42278 to 0.41815, saving model to model_part2.hdf5

Epoch 00149: loss improved from 0.41815 to 0.41490, saving model to model_part2.hdf5

Epoch 00150: loss improved from 0.41490 to 0.40904, saving model to model_part2.hdf5

Epoch 00151: loss improved from 0.40904 to 0.40456, saving model to model_part2.hdf5

Epoch 00152: loss improved from 0.40456 to 0.40011, saving model to model_part2.hdf5

Epoch 00153: loss improved from 0.40011 to 0.39756, saving model to model_part2.hdf5

Epoch 00154: loss improved from 0.39756 to 0.39223, saving model to model_part2.hdf5

Epoch 00155: loss improved from 0.39223 to 0.38838, saving model to model_part2.hdf5

Epoch 00156: loss improved from 0.38838 to 0.38425, saving model to model_part2.hdf5

Epoch 00157: loss improved from 0.38425 to 0.38009, saving model to model_part2.hdf5

Epoch 00158: loss improved from 0.38009 to 0.37673, saving model to model_part2.hdf5

Epoch 00159: loss improved from 0.37673 to 0.37356, saving model to model_part2.hdf5

Epoch 00160: loss improved from 0.37356 to 0.36935, saving model to model_part2.hdf5

Epoch 00161: loss improved from 0.36935 to 0.36548, saving model to model_part2.hdf5

Epoch 00162: loss improved from 0.36548 to 0.36084, saving model to model_part2.hdf5

Epoch 00163: loss improved from 0.36084 to 0.35802, saving model to model_part2.hdf5

Epoch 00164: loss improved from 0.35802 to 0.35376, saving model to model_part2.hdf5

Epoch 00165: loss improved from 0.35376 to 0.35151, saving model to model_part2.hdf5

Epoch 00166: loss improved from 0.35151 to 0.34695, saving model to model_part2.hdf5

Epoch 00167: loss improved from 0.34695 to 0.34318, saving model to model_part2.hdf5

Epoch 00168: loss improved from 0.34318 to 0.33979, saving model to model_part2.hdf5

Epoch 00169: loss improved from 0.33979 to 0.33662, saving model to model_part2.hdf5

Epoch 00170: loss improved from 0.33662 to 0.33297, saving model to model_part2.hdf5

Epoch 00171: loss improved from 0.33297 to 0.32973, saving model to model_part2.hdf5

Epoch 00172: loss improved from 0.32973 to 0.32646, saving model to model_part2.hdf5

Epoch 00173: loss improved from 0.32646 to 0.32350, saving model to model_part2.hdf5

Epoch 00174: loss improved from 0.32350 to 0.32091, saving model to model_part2.hdf5

Epoch 00175: loss improved from 0.32091 to 0.31799, saving model to model_part2.hdf5

Epoch 00176: loss improved from 0.31799 to 0.31321, saving model to model_part2.hdf5

Epoch 00177: loss improved from 0.31321 to 0.30946, saving model to model_part2.hdf5

Epoch 00178: loss improved from 0.30946 to 0.30685, saving model to model_part2.hdf5

Epoch 00179: loss improved from 0.30685 to 0.30392, saving model to model_part2.hdf5

Epoch 00180: loss improved from 0.30392 to 0.30158, saving model to model_part2.hdf5

Epoch 00181: loss improved from 0.30158 to 0.29770, saving model to model_part2.hdf5

Epoch 00182: loss improved from 0.29770 to 0.29744, saving model to model_part2.hdf5

Epoch 00183: loss improved from 0.29744 to 0.29338, saving model to model_part2.hdf5

Epoch 00184: loss improved from 0.29338 to 0.29035, saving model to model_part2.hdf5

Epoch 00185: loss improved from 0.29035 to 0.28783, saving model to model_part2.hdf5

Epoch 00186: loss improved from 0.28783 to 0.28435, saving model to model_part2.hdf5

Epoch 00187: loss improved from 0.28435 to 0.28275, saving model to model_part2.hdf5

Epoch 00188: loss improved from 0.28275 to 0.27986, saving model to model_part2.hdf5

Epoch 00189: loss improved from 0.27986 to 0.27749, saving model to model_part2.hdf5

Epoch 00190: loss improved from 0.27749 to 0.27515, saving model to model_part2.hdf5

Epoch 00191: loss improved from 0.27515 to 0.27267, saving model to model_part2.hdf5

Epoch 00192: loss improved from 0.27267 to 0.27109, saving model to model_part2.hdf5

Epoch 00193: loss improved from 0.27109 to 0.26814, saving model to model_part2.hdf5

Epoch 00194: loss improved from 0.26814 to 0.26585, saving model to model_part2.hdf5

Epoch 00195: loss improved from 0.26585 to 0.26332, saving model to model_part2.hdf5

Epoch 00196: loss improved from 0.26332 to 0.26199, saving model to model_part2.hdf5

Epoch 00197: loss improved from 0.26199 to 0.25897, saving model to model_part2.hdf5

Epoch 00198: loss improved from 0.25897 to 0.25714, saving model to model_part2.hdf5

Epoch 00199: loss improved from 0.25714 to 0.25649, saving model to model_part2.hdf5

Epoch 00200: loss improved from 0.25649 to 0.25338, saving model to model_part2.hdf5

Epoch 00201: loss improved from 0.25338 to 0.25214, saving model to model_part2.hdf5

Epoch 00202: loss improved from 0.25214 to 0.24936, saving model to model_part2.hdf5

Epoch 00203: loss improved from 0.24936 to 0.24866, saving model to model_part2.hdf5

Epoch 00204: loss improved from 0.24866 to 0.24576, saving model to model_part2.hdf5

Epoch 00205: loss improved from 0.24576 to 0.24403, saving model to model_part2.hdf5

Epoch 00206: loss improved from 0.24403 to 0.24248, saving model to model_part2.hdf5

Epoch 00207: loss improved from 0.24248 to 0.24084, saving model to model_part2.hdf5

Epoch 00208: loss improved from 0.24084 to 0.23909, saving model to model_part2.hdf5

Epoch 00209: loss improved from 0.23909 to 0.23718, saving model to model_part2.hdf5

Epoch 00210: loss improved from 0.23718 to 0.23577, saving model to model_part2.hdf5

Epoch 00211: loss improved from 0.23577 to 0.23480, saving model to model_part2.hdf5

Epoch 00212: loss improved from 0.23480 to 0.23248, saving model to model_part2.hdf5

Epoch 00213: loss improved from 0.23248 to 0.23056, saving model to model_part2.hdf5

Epoch 00214: loss improved from 0.23056 to 0.22889, saving model to model_part2.hdf5

Epoch 00215: loss improved from 0.22889 to 0.22825, saving model to model_part2.hdf5

Epoch 00216: loss improved from 0.22825 to 0.22609, saving model to model_part2.hdf5

Epoch 00217: loss improved from 0.22609 to 0.22495, saving model to model_part2.hdf5

Epoch 00218: loss improved from 0.22495 to 0.22343, saving model to model_part2.hdf5

Epoch 00219: loss improved from 0.22343 to 0.22218, saving model to model_part2.hdf5

Epoch 00220: loss improved from 0.22218 to 0.22058, saving model to model_part2.hdf5

Epoch 00221: loss improved from 0.22058 to 0.21942, saving model to model_part2.hdf5

Epoch 00222: loss improved from 0.21942 to 0.21792, saving model to model_part2.hdf5

Epoch 00223: loss improved from 0.21792 to 0.21656, saving model to model_part2.hdf5

Epoch 00224: loss improved from 0.21656 to 0.21503, saving model to model_part2.hdf5

Epoch 00225: loss improved from 0.21503 to 0.21421, saving model to model_part2.hdf5

Epoch 00226: loss improved from 0.21421 to 0.21361, saving model to model_part2.hdf5

Epoch 00227: loss improved from 0.21361 to 0.21138, saving model to model_part2.hdf5

Epoch 00228: loss improved from 0.21138 to 0.21047, saving model to model_part2.hdf5

Epoch 00229: loss improved from 0.21047 to 0.20852, saving model to model_part2.hdf5

Epoch 00230: loss improved from 0.20852 to 0.20744, saving model to model_part2.hdf5

Epoch 00231: loss improved from 0.20744 to 0.20721, saving model to model_part2.hdf5

Epoch 00232: loss improved from 0.20721 to 0.20556, saving model to model_part2.hdf5

Epoch 00233: loss improved from 0.20556 to 0.20382, saving model to model_part2.hdf5

Epoch 00234: loss improved from 0.20382 to 0.20276, saving model to model_part2.hdf5

Epoch 00235: loss improved from 0.20276 to 0.20208, saving model to model_part2.hdf5

Epoch 00236: loss improved from 0.20208 to 0.20070, saving model to model_part2.hdf5

Epoch 00237: loss did not improve from 0.20070

Epoch 00238: loss improved from 0.20070 to 0.19821, saving model to model_part2.hdf5

Epoch 00239: loss improved from 0.19821 to 0.19708, saving model to model_part2.hdf5

Epoch 00240: loss improved from 0.19708 to 0.19647, saving model to model_part2.hdf5

Epoch 00241: loss improved from 0.19647 to 0.19532, saving model to model_part2.hdf5

Epoch 00242: loss improved from 0.19532 to 0.19405, saving model to model_part2.hdf5

Epoch 00243: loss improved from 0.19405 to 0.19279, saving model to model_part2.hdf5

Epoch 00244: loss improved from 0.19279 to 0.19140, saving model to model_part2.hdf5

Epoch 00245: loss improved from 0.19140 to 0.19062, saving model to model_part2.hdf5

Epoch 00246: loss improved from 0.19062 to 0.18944, saving model to model_part2.hdf5

Epoch 00247: loss improved from 0.18944 to 0.18836, saving model to model_part2.hdf5

Epoch 00248: loss improved from 0.18836 to 0.18711, saving model to model_part2.hdf5

Epoch 00249: loss improved from 0.18711 to 0.18599, saving model to model_part2.hdf5

Epoch 00250: loss improved from 0.18599 to 0.18515, saving model to model_part2.hdf5

Epoch 00251: loss improved from 0.18515 to 0.18385, saving model to model_part2.hdf5

Epoch 00252: loss improved from 0.18385 to 0.18334, saving model to model_part2.hdf5

Epoch 00253: loss improved from 0.18334 to 0.18215, saving model to model_part2.hdf5

Epoch 00254: loss improved from 0.18215 to 0.18065, saving model to model_part2.hdf5

Epoch 00255: loss improved from 0.18065 to 0.18017, saving model to model_part2.hdf5

Epoch 00256: loss improved from 0.18017 to 0.17900, saving model to model_part2.hdf5

Epoch 00257: loss improved from 0.17900 to 0.17767, saving model to model_part2.hdf5

Epoch 00258: loss improved from 0.17767 to 0.17644, saving model to model_part2.hdf5

Epoch 00259: loss improved from 0.17644 to 0.17590, saving model to model_part2.hdf5

Epoch 00260: loss improved from 0.17590 to 0.17505, saving model to model_part2.hdf5

Epoch 00261: loss improved from 0.17505 to 0.17451, saving model to model_part2.hdf5

Epoch 00262: loss improved from 0.17451 to 0.17265, saving model to model_part2.hdf5

Epoch 00263: loss improved from 0.17265 to 0.17187, saving model to model_part2.hdf5

Epoch 00264: loss improved from 0.17187 to 0.17075, saving model to model_part2.hdf5

Epoch 00265: loss improved from 0.17075 to 0.16970, saving model to model_part2.hdf5

Epoch 00266: loss improved from 0.16970 to 0.16878, saving model to model_part2.hdf5

Epoch 00267: loss improved from 0.16878 to 0.16776, saving model to model_part2.hdf5

Epoch 00268: loss improved from 0.16776 to 0.16734, saving model to model_part2.hdf5

Epoch 00269: loss improved from 0.16734 to 0.16605, saving model to model_part2.hdf5

Epoch 00270: loss improved from 0.16605 to 0.16530, saving model to model_part2.hdf5

Epoch 00271: loss improved from 0.16530 to 0.16426, saving model to model_part2.hdf5

Epoch 00272: loss improved from 0.16426 to 0.16321, saving model to model_part2.hdf5

Epoch 00273: loss improved from 0.16321 to 0.16249, saving model to model_part2.hdf5

Epoch 00274: loss improved from 0.16249 to 0.16169, saving model to model_part2.hdf5

Epoch 00275: loss improved from 0.16169 to 0.16081, saving model to model_part2.hdf5

Epoch 00276: loss improved from 0.16081 to 0.15990, saving model to model_part2.hdf5

Epoch 00277: loss improved from 0.15990 to 0.15921, saving model to model_part2.hdf5

Epoch 00278: loss improved from 0.15921 to 0.15784, saving model to model_part2.hdf5

Epoch 00279: loss improved from 0.15784 to 0.15724, saving model to model_part2.hdf5

Epoch 00280: loss improved from 0.15724 to 0.15624, saving model to model_part2.hdf5

Epoch 00281: loss improved from 0.15624 to 0.15578, saving model to model_part2.hdf5

Epoch 00282: loss improved from 0.15578 to 0.15510, saving model to model_part2.hdf5

Epoch 00283: loss improved from 0.15510 to 0.15380, saving model to model_part2.hdf5

Epoch 00284: loss improved from 0.15380 to 0.15329, saving model to model_part2.hdf5

Epoch 00285: loss improved from 0.15329 to 0.15217, saving model to model_part2.hdf5

Epoch 00286: loss improved from 0.15217 to 0.15148, saving model to model_part2.hdf5

Epoch 00287: loss improved from 0.15148 to 0.15082, saving model to model_part2.hdf5

Epoch 00288: loss improved from 0.15082 to 0.14989, saving model to model_part2.hdf5

Epoch 00289: loss improved from 0.14989 to 0.14924, saving model to model_part2.hdf5

Epoch 00290: loss improved from 0.14924 to 0.14808, saving model to model_part2.hdf5

Epoch 00291: loss improved from 0.14808 to 0.14771, saving model to model_part2.hdf5

Epoch 00292: loss improved from 0.14771 to 0.14678, saving model to model_part2.hdf5

Epoch 00293: loss improved from 0.14678 to 0.14609, saving model to model_part2.hdf5

Epoch 00294: loss improved from 0.14609 to 0.14510, saving model to model_part2.hdf5

Epoch 00295: loss improved from 0.14510 to 0.14493, saving model to model_part2.hdf5

Epoch 00296: loss improved from 0.14493 to 0.14395, saving model to model_part2.hdf5

Epoch 00297: loss improved from 0.14395 to 0.14296, saving model to model_part2.hdf5

Epoch 00298: loss improved from 0.14296 to 0.14254, saving model to model_part2.hdf5

Epoch 00299: loss improved from 0.14254 to 0.14162, saving model to model_part2.hdf5

Epoch 00300: loss improved from 0.14162 to 0.14086, saving model to model_part2.hdf5

Epoch 00301: loss improved from 0.14086 to 0.14020, saving model to model_part2.hdf5

Epoch 00302: loss improved from 0.14020 to 0.13957, saving model to model_part2.hdf5

Epoch 00303: loss improved from 0.13957 to 0.13872, saving model to model_part2.hdf5

Epoch 00304: loss improved from 0.13872 to 0.13802, saving model to model_part2.hdf5

Epoch 00305: loss improved from 0.13802 to 0.13726, saving model to model_part2.hdf5

Epoch 00306: loss improved from 0.13726 to 0.13650, saving model to model_part2.hdf5

Epoch 00307: loss improved from 0.13650 to 0.13583, saving model to model_part2.hdf5

Epoch 00308: loss improved from 0.13583 to 0.13522, saving model to model_part2.hdf5

Epoch 00309: loss improved from 0.13522 to 0.13439, saving model to model_part2.hdf5

Epoch 00310: loss improved from 0.13439 to 0.13390, saving model to model_part2.hdf5

Epoch 00311: loss improved from 0.13390 to 0.13317, saving model to model_part2.hdf5

Epoch 00312: loss improved from 0.13317 to 0.13228, saving model to model_part2.hdf5

Epoch 00313: loss improved from 0.13228 to 0.13154, saving model to model_part2.hdf5

Epoch 00314: loss improved from 0.13154 to 0.13108, saving model to model_part2.hdf5

Epoch 00315: loss improved from 0.13108 to 0.13077, saving model to model_part2.hdf5

Epoch 00316: loss improved from 0.13077 to 0.12972, saving model to model_part2.hdf5

Epoch 00317: loss improved from 0.12972 to 0.12902, saving model to model_part2.hdf5

Epoch 00318: loss improved from 0.12902 to 0.12829, saving model to model_part2.hdf5

Epoch 00319: loss improved from 0.12829 to 0.12778, saving model to model_part2.hdf5

Epoch 00320: loss improved from 0.12778 to 0.12718, saving model to model_part2.hdf5

Epoch 00321: loss improved from 0.12718 to 0.12640, saving model to model_part2.hdf5

Epoch 00322: loss improved from 0.12640 to 0.12608, saving model to model_part2.hdf5

Epoch 00323: loss improved from 0.12608 to 0.12510, saving model to model_part2.hdf5

Epoch 00324: loss improved from 0.12510 to 0.12445, saving model to model_part2.hdf5

Epoch 00325: loss improved from 0.12445 to 0.12385, saving model to model_part2.hdf5

Epoch 00326: loss improved from 0.12385 to 0.12325, saving model to model_part2.hdf5

Epoch 00327: loss improved from 0.12325 to 0.12258, saving model to model_part2.hdf5

Epoch 00328: loss improved from 0.12258 to 0.12193, saving model to model_part2.hdf5

Epoch 00329: loss improved from 0.12193 to 0.12141, saving model to model_part2.hdf5

Epoch 00330: loss improved from 0.12141 to 0.12072, saving model to model_part2.hdf5

Epoch 00331: loss improved from 0.12072 to 0.12005, saving model to model_part2.hdf5

Epoch 00332: loss improved from 0.12005 to 0.11946, saving model to model_part2.hdf5

Epoch 00333: loss improved from 0.11946 to 0.11890, saving model to model_part2.hdf5

Epoch 00334: loss improved from 0.11890 to 0.11831, saving model to model_part2.hdf5

Epoch 00335: loss improved from 0.11831 to 0.11777, saving model to model_part2.hdf5

Epoch 00336: loss improved from 0.11777 to 0.11703, saving model to model_part2.hdf5

Epoch 00337: loss improved from 0.11703 to 0.11675, saving model to model_part2.hdf5

Epoch 00338: loss improved from 0.11675 to 0.11602, saving model to model_part2.hdf5

Epoch 00339: loss improved from 0.11602 to 0.11532, saving model to model_part2.hdf5

Epoch 00340: loss improved from 0.11532 to 0.11466, saving model to model_part2.hdf5

Epoch 00341: loss improved from 0.11466 to 0.11402, saving model to model_part2.hdf5

Epoch 00342: loss improved from 0.11402 to 0.11370, saving model to model_part2.hdf5

Epoch 00343: loss improved from 0.11370 to 0.11303, saving model to model_part2.hdf5

Epoch 00344: loss improved from 0.11303 to 0.11242, saving model to model_part2.hdf5

Epoch 00345: loss improved from 0.11242 to 0.11182, saving model to model_part2.hdf5

Epoch 00346: loss improved from 0.11182 to 0.11120, saving model to model_part2.hdf5

Epoch 00347: loss improved from 0.11120 to 0.11067, saving model to model_part2.hdf5

Epoch 00348: loss improved from 0.11067 to 0.11002, saving model to model_part2.hdf5

Epoch 00349: loss improved from 0.11002 to 0.10953, saving model to model_part2.hdf5

Epoch 00350: loss improved from 0.10953 to 0.10892, saving model to model_part2.hdf5

Epoch 00351: loss improved from 0.10892 to 0.10836, saving model to model_part2.hdf5

Epoch 00352: loss improved from 0.10836 to 0.10780, saving model to model_part2.hdf5

Epoch 00353: loss improved from 0.10780 to 0.10735, saving model to model_part2.hdf5

Epoch 00354: loss improved from 0.10735 to 0.10666, saving model to model_part2.hdf5

Epoch 00355: loss improved from 0.10666 to 0.10606, saving model to model_part2.hdf5

Epoch 00356: loss improved from 0.10606 to 0.10568, saving model to model_part2.hdf5

Epoch 00357: loss improved from 0.10568 to 0.10507, saving model to model_part2.hdf5

Epoch 00358: loss improved from 0.10507 to 0.10451, saving model to model_part2.hdf5

Epoch 00359: loss improved from 0.10451 to 0.10395, saving model to model_part2.hdf5

Epoch 00360: loss improved from 0.10395 to 0.10351, saving model to model_part2.hdf5

Epoch 00361: loss improved from 0.10351 to 0.10294, saving model to model_part2.hdf5

Epoch 00362: loss improved from 0.10294 to 0.10235, saving model to model_part2.hdf5

Epoch 00363: loss improved from 0.10235 to 0.10196, saving model to model_part2.hdf5

Epoch 00364: loss improved from 0.10196 to 0.10134, saving model to model_part2.hdf5

Epoch 00365: loss improved from 0.10134 to 0.10076, saving model to model_part2.hdf5

Epoch 00366: loss improved from 0.10076 to 0.10031, saving model to model_part2.hdf5

Epoch 00367: loss improved from 0.10031 to 0.09989, saving model to model_part2.hdf5

Epoch 00368: loss improved from 0.09989 to 0.09928, saving model to model_part2.hdf5

Epoch 00369: loss improved from 0.09928 to 0.09873, saving model to model_part2.hdf5

Epoch 00370: loss improved from 0.09873 to 0.09821, saving model to model_part2.hdf5

Epoch 00371: loss improved from 0.09821 to 0.09785, saving model to model_part2.hdf5

Epoch 00372: loss improved from 0.09785 to 0.09734, saving model to model_part2.hdf5

Epoch 00373: loss improved from 0.09734 to 0.09677, saving model to model_part2.hdf5

Epoch 00374: loss improved from 0.09677 to 0.09626, saving model to model_part2.hdf5

Epoch 00375: loss improved from 0.09626 to 0.09573, saving model to model_part2.hdf5

Epoch 00376: loss improved from 0.09573 to 0.09523, saving model to model_part2.hdf5

Epoch 00377: loss improved from 0.09523 to 0.09475, saving model to model_part2.hdf5

Epoch 00378: loss improved from 0.09475 to 0.09429, saving model to model_part2.hdf5

Epoch 00379: loss improved from 0.09429 to 0.09377, saving model to model_part2.hdf5

Epoch 00380: loss improved from 0.09377 to 0.09328, saving model to model_part2.hdf5

Epoch 00381: loss improved from 0.09328 to 0.09283, saving model to model_part2.hdf5

Epoch 00382: loss improved from 0.09283 to 0.09240, saving model to model_part2.hdf5

Epoch 00383: loss improved from 0.09240 to 0.09187, saving model to model_part2.hdf5

Epoch 00384: loss improved from 0.09187 to 0.09145, saving model to model_part2.hdf5

Epoch 00385: loss improved from 0.09145 to 0.09091, saving model to model_part2.hdf5

Epoch 00386: loss improved from 0.09091 to 0.09042, saving model to model_part2.hdf5

Epoch 00387: loss improved from 0.09042 to 0.08993, saving model to model_part2.hdf5

Epoch 00388: loss improved from 0.08993 to 0.08946, saving model to model_part2.hdf5

Epoch 00389: loss improved from 0.08946 to 0.08902, saving model to model_part2.hdf5

Epoch 00390: loss improved from 0.08902 to 0.08853, saving model to model_part2.hdf5

Epoch 00391: loss improved from 0.08853 to 0.08805, saving model to model_part2.hdf5

Epoch 00392: loss improved from 0.08805 to 0.08760, saving model to model_part2.hdf5

Epoch 00393: loss improved from 0.08760 to 0.08724, saving model to model_part2.hdf5

Epoch 00394: loss improved from 0.08724 to 0.08672, saving model to model_part2.hdf5

Epoch 00395: loss improved from 0.08672 to 0.08628, saving model to model_part2.hdf5

Epoch 00396: loss improved from 0.08628 to 0.08580, saving model to model_part2.hdf5

Epoch 00397: loss improved from 0.08580 to 0.08536, saving model to model_part2.hdf5

Epoch 00398: loss improved from 0.08536 to 0.08490, saving model to model_part2.hdf5

Epoch 00399: loss improved from 0.08490 to 0.08444, saving model to model_part2.hdf5

Epoch 00400: loss improved from 0.08444 to 0.08412, saving model to model_part2.hdf5

Epoch 00401: loss improved from 0.08412 to 0.08363, saving model to model_part2.hdf5

Epoch 00402: loss improved from 0.08363 to 0.08316, saving model to model_part2.hdf5

Epoch 00403: loss improved from 0.08316 to 0.08271, saving model to model_part2.hdf5

Epoch 00404: loss improved from 0.08271 to 0.08227, saving model to model_part2.hdf5

Epoch 00405: loss improved from 0.08227 to 0.08183, saving model to model_part2.hdf5

Epoch 00406: loss improved from 0.08183 to 0.08139, saving model to model_part2.hdf5

Epoch 00407: loss improved from 0.08139 to 0.08095, saving model to model_part2.hdf5

Epoch 00408: loss improved from 0.08095 to 0.08057, saving model to model_part2.hdf5

Epoch 00409: loss improved from 0.08057 to 0.08011, saving model to model_part2.hdf5

Epoch 00410: loss improved from 0.08011 to 0.07969, saving model to model_part2.hdf5

Epoch 00411: loss improved from 0.07969 to 0.07929, saving model to model_part2.hdf5

Epoch 00412: loss improved from 0.07929 to 0.07883, saving model to model_part2.hdf5

Epoch 00413: loss improved from 0.07883 to 0.07841, saving model to model_part2.hdf5

Epoch 00414: loss improved from 0.07841 to 0.07800, saving model to model_part2.hdf5

Epoch 00415: loss improved from 0.07800 to 0.07758, saving model to model_part2.hdf5

Epoch 00416: loss improved from 0.07758 to 0.07716, saving model to model_part2.hdf5

Epoch 00417: loss improved from 0.07716 to 0.07699, saving model to model_part2.hdf5

Epoch 00418: loss improved from 0.07699 to 0.07643, saving model to model_part2.hdf5

Epoch 00419: loss improved from 0.07643 to 0.07602, saving model to model_part2.hdf5

Epoch 00420: loss improved from 0.07602 to 0.07561, saving model to model_part2.hdf5

Epoch 00421: loss improved from 0.07561 to 0.07519, saving model to model_part2.hdf5

Epoch 00422: loss improved from 0.07519 to 0.07481, saving model to model_part2.hdf5

Epoch 00423: loss improved from 0.07481 to 0.07440, saving model to model_part2.hdf5

Epoch 00424: loss improved from 0.07440 to 0.07400, saving model to model_part2.hdf5

Epoch 00425: loss improved from 0.07400 to 0.07360, saving model to model_part2.hdf5

Epoch 00426: loss improved from 0.07360 to 0.07320, saving model to model_part2.hdf5

Epoch 00427: loss improved from 0.07320 to 0.07281, saving model to model_part2.hdf5

Epoch 00428: loss improved from 0.07281 to 0.07243, saving model to model_part2.hdf5

Epoch 00429: loss improved from 0.07243 to 0.07203, saving model to model_part2.hdf5

Epoch 00430: loss improved from 0.07203 to 0.07167, saving model to model_part2.hdf5

Epoch 00431: loss improved from 0.07167 to 0.07130, saving model to model_part2.hdf5

Epoch 00432: loss improved from 0.07130 to 0.07089, saving model to model_part2.hdf5

Epoch 00433: loss improved from 0.07089 to 0.07050, saving model to model_part2.hdf5

Epoch 00434: loss improved from 0.07050 to 0.07012, saving model to model_part2.hdf5

Epoch 00435: loss improved from 0.07012 to 0.06975, saving model to model_part2.hdf5

Epoch 00436: loss improved from 0.06975 to 0.06939, saving model to model_part2.hdf5

Epoch 00437: loss improved from 0.06939 to 0.06901, saving model to model_part2.hdf5

Epoch 00438: loss improved from 0.06901 to 0.06864, saving model to model_part2.hdf5

Epoch 00439: loss improved from 0.06864 to 0.06826, saving model to model_part2.hdf5

Epoch 00440: loss improved from 0.06826 to 0.06791, saving model to model_part2.hdf5

Epoch 00441: loss improved from 0.06791 to 0.06757, saving model to model_part2.hdf5

Epoch 00442: loss improved from 0.06757 to 0.06720, saving model to model_part2.hdf5

Epoch 00443: loss improved from 0.06720 to 0.06684, saving model to model_part2.hdf5

Epoch 00444: loss improved from 0.06684 to 0.06647, saving model to model_part2.hdf5

Epoch 00445: loss improved from 0.06647 to 0.06611, saving model to model_part2.hdf5

Epoch 00446: loss improved from 0.06611 to 0.06575, saving model to model_part2.hdf5

Epoch 00447: loss improved from 0.06575 to 0.06541, saving model to model_part2.hdf5

Epoch 00448: loss improved from 0.06541 to 0.06507, saving model to model_part2.hdf5

Epoch 00449: loss improved from 0.06507 to 0.06482, saving model to model_part2.hdf5

Epoch 00450: loss improved from 0.06482 to 0.06441, saving model to model_part2.hdf5

Epoch 00451: loss improved from 0.06441 to 0.06406, saving model to model_part2.hdf5

Epoch 00452: loss improved from 0.06406 to 0.06370, saving model to model_part2.hdf5

Epoch 00453: loss improved from 0.06370 to 0.06336, saving model to model_part2.hdf5

Epoch 00454: loss improved from 0.06336 to 0.06302, saving model to model_part2.hdf5

Epoch 00455: loss improved from 0.06302 to 0.06270, saving model to model_part2.hdf5

Epoch 00456: loss improved from 0.06270 to 0.06235, saving model to model_part2.hdf5

Epoch 00457: loss improved from 0.06235 to 0.06200, saving model to model_part2.hdf5

Epoch 00458: loss improved from 0.06200 to 0.06166, saving model to model_part2.hdf5

Epoch 00459: loss improved from 0.06166 to 0.06133, saving model to model_part2.hdf5

Epoch 00460: loss improved from 0.06133 to 0.06101, saving model to model_part2.hdf5

Epoch 00461: loss improved from 0.06101 to 0.06068, saving model to model_part2.hdf5

Epoch 00462: loss improved from 0.06068 to 0.06034, saving model to model_part2.hdf5

Epoch 00463: loss improved from 0.06034 to 0.06004, saving model to model_part2.hdf5

Epoch 00464: loss improved from 0.06004 to 0.05970, saving model to model_part2.hdf5

Epoch 00465: loss improved from 0.05970 to 0.05936, saving model to model_part2.hdf5

Epoch 00466: loss improved from 0.05936 to 0.05904, saving model to model_part2.hdf5

Epoch 00467: loss improved from 0.05904 to 0.05872, saving model to model_part2.hdf5

Epoch 00468: loss improved from 0.05872 to 0.05840, saving model to model_part2.hdf5

Epoch 00469: loss improved from 0.05840 to 0.05809, saving model to model_part2.hdf5

Epoch 00470: loss improved from 0.05809 to 0.05779, saving model to model_part2.hdf5

Epoch 00471: loss improved from 0.05779 to 0.05748, saving model to model_part2.hdf5

Epoch 00472: loss improved from 0.05748 to 0.05718, saving model to model_part2.hdf5

Epoch 00473: loss improved from 0.05718 to 0.05687, saving model to model_part2.hdf5

Epoch 00474: loss improved from 0.05687 to 0.05656, saving model to model_part2.hdf5

Epoch 00475: loss improved from 0.05656 to 0.05629, saving model to model_part2.hdf5

Epoch 00476: loss improved from 0.05629 to 0.05596, saving model to model_part2.hdf5

Epoch 00477: loss improved from 0.05596 to 0.05568, saving model to model_part2.hdf5

Epoch 00478: loss improved from 0.05568 to 0.05538, saving model to model_part2.hdf5

Epoch 00479: loss improved from 0.05538 to 0.05507, saving model to model_part2.hdf5

Epoch 00480: loss improved from 0.05507 to 0.05477, saving model to model_part2.hdf5

Epoch 00481: loss improved from 0.05477 to 0.05446, saving model to model_part2.hdf5

Epoch 00482: loss improved from 0.05446 to 0.05416, saving model to model_part2.hdf5

Epoch 00483: loss improved from 0.05416 to 0.05385, saving model to model_part2.hdf5

Epoch 00484: loss improved from 0.05385 to 0.05356, saving model to model_part2.hdf5

Epoch 00485: loss improved from 0.05356 to 0.05327, saving model to model_part2.hdf5

Epoch 00486: loss improved from 0.05327 to 0.05298, saving model to model_part2.hdf5

Epoch 00487: loss improved from 0.05298 to 0.05269, saving model to model_part2.hdf5

Epoch 00488: loss improved from 0.05269 to 0.05240, saving model to model_part2.hdf5

Epoch 00489: loss improved from 0.05240 to 0.05210, saving model to model_part2.hdf5

Epoch 00490: loss improved from 0.05210 to 0.05182, saving model to model_part2.hdf5

Epoch 00491: loss improved from 0.05182 to 0.05155, saving model to model_part2.hdf5

Epoch 00492: loss improved from 0.05155 to 0.05127, saving model to model_part2.hdf5

Epoch 00493: loss improved from 0.05127 to 0.05099, saving model to model_part2.hdf5

Epoch 00494: loss improved from 0.05099 to 0.05072, saving model to model_part2.hdf5

Epoch 00495: loss improved from 0.05072 to 0.05045, saving model to model_part2.hdf5

Epoch 00496: loss improved from 0.05045 to 0.05017, saving model to model_part2.hdf5

Epoch 00497: loss improved from 0.05017 to 0.04989, saving model to model_part2.hdf5

Epoch 00498: loss improved from 0.04989 to 0.04961, saving model to model_part2.hdf5

Epoch 00499: loss improved from 0.04961 to 0.04934, saving model to model_part2.hdf5

Epoch 00500: loss improved from 0.04934 to 0.04907, saving model to model_part2.hdf5

Epoch 00501: loss improved from 0.04907 to 0.04881, saving model to model_part2.hdf5

Epoch 00502: loss improved from 0.04881 to 0.04854, saving model to model_part2.hdf5

Epoch 00503: loss improved from 0.04854 to 0.04827, saving model to model_part2.hdf5

Epoch 00504: loss improved from 0.04827 to 0.04800, saving model to model_part2.hdf5

Epoch 00505: loss improved from 0.04800 to 0.04773, saving model to model_part2.hdf5

Epoch 00506: loss improved from 0.04773 to 0.04747, saving model to model_part2.hdf5

Epoch 00507: loss improved from 0.04747 to 0.04721, saving model to model_part2.hdf5

Epoch 00508: loss improved from 0.04721 to 0.04695, saving model to model_part2.hdf5

Epoch 00509: loss improved from 0.04695 to 0.04670, saving model to model_part2.hdf5

Epoch 00510: loss improved from 0.04670 to 0.04644, saving model to model_part2.hdf5

Epoch 00511: loss improved from 0.04644 to 0.04618, saving model to model_part2.hdf5

Epoch 00512: loss improved from 0.04618 to 0.04593, saving model to model_part2.hdf5

Epoch 00513: loss improved from 0.04593 to 0.04568, saving model to model_part2.hdf5

Epoch 00514: loss improved from 0.04568 to 0.04542, saving model to model_part2.hdf5

Epoch 00515: loss improved from 0.04542 to 0.04521, saving model to model_part2.hdf5

Epoch 00516: loss improved from 0.04521 to 0.04494, saving model to model_part2.hdf5

Epoch 00517: loss improved from 0.04494 to 0.04469, saving model to model_part2.hdf5

Epoch 00518: loss improved from 0.04469 to 0.04443, saving model to model_part2.hdf5

Epoch 00519: loss improved from 0.04443 to 0.04419, saving model to model_part2.hdf5

Epoch 00520: loss improved from 0.04419 to 0.04396, saving model to model_part2.hdf5

Epoch 00521: loss improved from 0.04396 to 0.04372, saving model to model_part2.hdf5

Epoch 00522: loss improved from 0.04372 to 0.04348, saving model to model_part2.hdf5

Epoch 00523: loss improved from 0.04348 to 0.04323, saving model to model_part2.hdf5

Epoch 00524: loss improved from 0.04323 to 0.04299, saving model to model_part2.hdf5

Epoch 00525: loss improved from 0.04299 to 0.04274, saving model to model_part2.hdf5

Epoch 00526: loss improved from 0.04274 to 0.04250, saving model to model_part2.hdf5

Epoch 00527: loss improved from 0.04250 to 0.04227, saving model to model_part2.hdf5

Epoch 00528: loss improved from 0.04227 to 0.04204, saving model to model_part2.hdf5

Epoch 00529: loss improved from 0.04204 to 0.04181, saving model to model_part2.hdf5

Epoch 00530: loss improved from 0.04181 to 0.04158, saving model to model_part2.hdf5

Epoch 00531: loss improved from 0.04158 to 0.04137, saving model to model_part2.hdf5

Epoch 00532: loss improved from 0.04137 to 0.04112, saving model to model_part2.hdf5

Epoch 00533: loss improved from 0.04112 to 0.04091, saving model to model_part2.hdf5

Epoch 00534: loss improved from 0.04091 to 0.04068, saving model to model_part2.hdf5

Epoch 00535: loss improved from 0.04068 to 0.04046, saving model to model_part2.hdf5

Epoch 00536: loss improved from 0.04046 to 0.04024, saving model to model_part2.hdf5

Epoch 00537: loss improved from 0.04024 to 0.04001, saving model to model_part2.hdf5

Epoch 00538: loss improved from 0.04001 to 0.03980, saving model to model_part2.hdf5

Epoch 00539: loss improved from 0.03980 to 0.03959, saving model to model_part2.hdf5

Epoch 00540: loss improved from 0.03959 to 0.03937, saving model to model_part2.hdf5

Epoch 00541: loss improved from 0.03937 to 0.03915, saving model to model_part2.hdf5

Epoch 00542: loss improved from 0.03915 to 0.03894, saving model to model_part2.hdf5

Epoch 00543: loss improved from 0.03894 to 0.03871, saving model to model_part2.hdf5

Epoch 00544: loss improved from 0.03871 to 0.03849, saving model to model_part2.hdf5

Epoch 00545: loss improved from 0.03849 to 0.03828, saving model to model_part2.hdf5

Epoch 00546: loss improved from 0.03828 to 0.03807, saving model to model_part2.hdf5

Epoch 00547: loss improved from 0.03807 to 0.03786, saving model to model_part2.hdf5

Epoch 00548: loss improved from 0.03786 to 0.03765, saving model to model_part2.hdf5

Epoch 00549: loss improved from 0.03765 to 0.03744, saving model to model_part2.hdf5

Epoch 00550: loss improved from 0.03744 to 0.03723, saving model to model_part2.hdf5

Epoch 00551: loss improved from 0.03723 to 0.03703, saving model to model_part2.hdf5

Epoch 00552: loss improved from 0.03703 to 0.03683, saving model to model_part2.hdf5

Epoch 00553: loss improved from 0.03683 to 0.03663, saving model to model_part2.hdf5

Epoch 00554: loss improved from 0.03663 to 0.03642, saving model to model_part2.hdf5

Epoch 00555: loss improved from 0.03642 to 0.03622, saving model to model_part2.hdf5

Epoch 00556: loss improved from 0.03622 to 0.03606, saving model to model_part2.hdf5

Epoch 00557: loss improved from 0.03606 to 0.03582, saving model to model_part2.hdf5

Epoch 00558: loss improved from 0.03582 to 0.03562, saving model to model_part2.hdf5

Epoch 00559: loss improved from 0.03562 to 0.03542, saving model to model_part2.hdf5

Epoch 00560: loss improved from 0.03542 to 0.03522, saving model to model_part2.hdf5

Epoch 00561: loss improved from 0.03522 to 0.03502, saving model to model_part2.hdf5

Epoch 00562: loss improved from 0.03502 to 0.03483, saving model to model_part2.hdf5

Epoch 00563: loss improved from 0.03483 to 0.03463, saving model to model_part2.hdf5

Epoch 00564: loss improved from 0.03463 to 0.03444, saving model to model_part2.hdf5

Epoch 00565: loss improved from 0.03444 to 0.03425, saving model to model_part2.hdf5

Epoch 00566: loss improved from 0.03425 to 0.03406, saving model to model_part2.hdf5

Epoch 00567: loss improved from 0.03406 to 0.03387, saving model to model_part2.hdf5

Epoch 00568: loss improved from 0.03387 to 0.03369, saving model to model_part2.hdf5

Epoch 00569: loss improved from 0.03369 to 0.03350, saving model to model_part2.hdf5

Epoch 00570: loss improved from 0.03350 to 0.03331, saving model to model_part2.hdf5

Epoch 00571: loss improved from 0.03331 to 0.03312, saving model to model_part2.hdf5

Epoch 00572: loss improved from 0.03312 to 0.03293, saving model to model_part2.hdf5

Epoch 00573: loss improved from 0.03293 to 0.03275, saving model to model_part2.hdf5

Epoch 00574: loss improved from 0.03275 to 0.03257, saving model to model_part2.hdf5

Epoch 00575: loss improved from 0.03257 to 0.03238, saving model to model_part2.hdf5

Epoch 00576: loss improved from 0.03238 to 0.03220, saving model to model_part2.hdf5

Epoch 00577: loss improved from 0.03220 to 0.03202, saving model to model_part2.hdf5

Epoch 00578: loss improved from 0.03202 to 0.03184, saving model to model_part2.hdf5

Epoch 00579: loss improved from 0.03184 to 0.03167, saving model to model_part2.hdf5

Epoch 00580: loss improved from 0.03167 to 0.03149, saving model to model_part2.hdf5

Epoch 00581: loss improved from 0.03149 to 0.03132, saving model to model_part2.hdf5

Epoch 00582: loss improved from 0.03132 to 0.03115, saving model to model_part2.hdf5

Epoch 00583: loss improved from 0.03115 to 0.03097, saving model to model_part2.hdf5

Epoch 00584: loss improved from 0.03097 to 0.03080, saving model to model_part2.hdf5

Epoch 00585: loss improved from 0.03080 to 0.03063, saving model to model_part2.hdf5

Epoch 00586: loss improved from 0.03063 to 0.03048, saving model to model_part2.hdf5

Epoch 00587: loss improved from 0.03048 to 0.03029, saving model to model_part2.hdf5

Epoch 00588: loss improved from 0.03029 to 0.03012, saving model to model_part2.hdf5

Epoch 00589: loss improved from 0.03012 to 0.02995, saving model to model_part2.hdf5

Epoch 00590: loss improved from 0.02995 to 0.02978, saving model to model_part2.hdf5

Epoch 00591: loss improved from 0.02978 to 0.02962, saving model to model_part2.hdf5

Epoch 00592: loss improved from 0.02962 to 0.02946, saving model to model_part2.hdf5

Epoch 00593: loss improved from 0.02946 to 0.02930, saving model to model_part2.hdf5

Epoch 00594: loss improved from 0.02930 to 0.02914, saving model to model_part2.hdf5

Epoch 00595: loss improved from 0.02914 to 0.02898, saving model to model_part2.hdf5

Epoch 00596: loss improved from 0.02898 to 0.02882, saving model to model_part2.hdf5

Epoch 00597: loss improved from 0.02882 to 0.02866, saving model to model_part2.hdf5

Epoch 00598: loss improved from 0.02866 to 0.02849, saving model to model_part2.hdf5

Epoch 00599: loss improved from 0.02849 to 0.02833, saving model to model_part2.hdf5

Epoch 00600: loss improved from 0.02833 to 0.02817, saving model to model_part2.hdf5

Epoch 00601: loss improved from 0.02817 to 0.02803, saving model to model_part2.hdf5

Epoch 00602: loss improved from 0.02803 to 0.02786, saving model to model_part2.hdf5

Epoch 00603: loss improved from 0.02786 to 0.02770, saving model to model_part2.hdf5

Epoch 00604: loss improved from 0.02770 to 0.02754, saving model to model_part2.hdf5

Epoch 00605: loss improved from 0.02754 to 0.02738, saving model to model_part2.hdf5

Epoch 00606: loss improved from 0.02738 to 0.02723, saving model to model_part2.hdf5

Epoch 00607: loss improved from 0.02723 to 0.02708, saving model to model_part2.hdf5

Epoch 00608: loss improved from 0.02708 to 0.02692, saving model to model_part2.hdf5

Epoch 00609: loss improved from 0.02692 to 0.02677, saving model to model_part2.hdf5

Epoch 00610: loss improved from 0.02677 to 0.02662, saving model to model_part2.hdf5

Epoch 00611: loss improved from 0.02662 to 0.02647, saving model to model_part2.hdf5

Epoch 00612: loss improved from 0.02647 to 0.02633, saving model to model_part2.hdf5

Epoch 00613: loss improved from 0.02633 to 0.02618, saving model to model_part2.hdf5

Epoch 00614: loss improved from 0.02618 to 0.02603, saving model to model_part2.hdf5

Epoch 00615: loss improved from 0.02603 to 0.02590, saving model to model_part2.hdf5

Epoch 00616: loss improved from 0.02590 to 0.02575, saving model to model_part2.hdf5

Epoch 00617: loss improved from 0.02575 to 0.02560, saving model to model_part2.hdf5

Epoch 00618: loss improved from 0.02560 to 0.02546, saving model to model_part2.hdf5

Epoch 00619: loss improved from 0.02546 to 0.02531, saving model to model_part2.hdf5

Epoch 00620: loss improved from 0.02531 to 0.02517, saving model to model_part2.hdf5

Epoch 00621: loss improved from 0.02517 to 0.02502, saving model to model_part2.hdf5

Epoch 00622: loss improved from 0.02502 to 0.02488, saving model to model_part2.hdf5

Epoch 00623: loss improved from 0.02488 to 0.02474, saving model to model_part2.hdf5

Epoch 00624: loss improved from 0.02474 to 0.02461, saving model to model_part2.hdf5

Epoch 00625: loss improved from 0.02461 to 0.02447, saving model to model_part2.hdf5

Epoch 00626: loss improved from 0.02447 to 0.02433, saving model to model_part2.hdf5

Epoch 00627: loss improved from 0.02433 to 0.02419, saving model to model_part2.hdf5

Epoch 00628: loss improved from 0.02419 to 0.02406, saving model to model_part2.hdf5

Epoch 00629: loss improved from 0.02406 to 0.02392, saving model to model_part2.hdf5

Epoch 00630: loss improved from 0.02392 to 0.02378, saving model to model_part2.hdf5

Epoch 00631: loss improved from 0.02378 to 0.02365, saving model to model_part2.hdf5

Epoch 00632: loss improved from 0.02365 to 0.02351, saving model to model_part2.hdf5

Epoch 00633: loss improved from 0.02351 to 0.02338, saving model to model_part2.hdf5

Epoch 00634: loss improved from 0.02338 to 0.02325, saving model to model_part2.hdf5

Epoch 00635: loss improved from 0.02325 to 0.02311, saving model to model_part2.hdf5

Epoch 00636: loss improved from 0.02311 to 0.02298, saving model to model_part2.hdf5

Epoch 00637: loss improved from 0.02298 to 0.02285, saving model to model_part2.hdf5

Epoch 00638: loss improved from 0.02285 to 0.02272, saving model to model_part2.hdf5

Epoch 00639: loss improved from 0.02272 to 0.02260, saving model to model_part2.hdf5

Epoch 00640: loss improved from 0.02260 to 0.02247, saving model to model_part2.hdf5

Epoch 00641: loss improved from 0.02247 to 0.02234, saving model to model_part2.hdf5

Epoch 00642: loss improved from 0.02234 to 0.02222, saving model to model_part2.hdf5

Epoch 00643: loss improved from 0.02222 to 0.02210, saving model to model_part2.hdf5

Epoch 00644: loss improved from 0.02210 to 0.02196, saving model to model_part2.hdf5

Epoch 00645: loss improved from 0.02196 to 0.02184, saving model to model_part2.hdf5

Epoch 00646: loss improved from 0.02184 to 0.02172, saving model to model_part2.hdf5

Epoch 00647: loss improved from 0.02172 to 0.02160, saving model to model_part2.hdf5

Epoch 00648: loss improved from 0.02160 to 0.02148, saving model to model_part2.hdf5

Epoch 00649: loss improved from 0.02148 to 0.02136, saving model to model_part2.hdf5

Epoch 00650: loss improved from 0.02136 to 0.02123, saving model to model_part2.hdf5

Epoch 00651: loss improved from 0.02123 to 0.02112, saving model to model_part2.hdf5

Epoch 00652: loss improved from 0.02112 to 0.02100, saving model to model_part2.hdf5

Epoch 00653: loss improved from 0.02100 to 0.02088, saving model to model_part2.hdf5

Epoch 00654: loss improved from 0.02088 to 0.02076, saving model to model_part2.hdf5

Epoch 00655: loss improved from 0.02076 to 0.02065, saving model to model_part2.hdf5

Epoch 00656: loss improved from 0.02065 to 0.02053, saving model to model_part2.hdf5

Epoch 00657: loss improved from 0.02053 to 0.02042, saving model to model_part2.hdf5

Epoch 00658: loss improved from 0.02042 to 0.02031, saving model to model_part2.hdf5

Epoch 00659: loss improved from 0.02031 to 0.02019, saving model to model_part2.hdf5

Epoch 00660: loss improved from 0.02019 to 0.02007, saving model to model_part2.hdf5

Epoch 00661: loss improved from 0.02007 to 0.01996, saving model to model_part2.hdf5

Epoch 00662: loss improved from 0.01996 to 0.01985, saving model to model_part2.hdf5

Epoch 00663: loss improved from 0.01985 to 0.01974, saving model to model_part2.hdf5

Epoch 00664: loss improved from 0.01974 to 0.01962, saving model to model_part2.hdf5

Epoch 00665: loss improved from 0.01962 to 0.01951, saving model to model_part2.hdf5

Epoch 00666: loss improved from 0.01951 to 0.01940, saving model to model_part2.hdf5

Epoch 00667: loss improved from 0.01940 to 0.01929, saving model to model_part2.hdf5

Epoch 00668: loss improved from 0.01929 to 0.01918, saving model to model_part2.hdf5

Epoch 00669: loss improved from 0.01918 to 0.01908, saving model to model_part2.hdf5

Epoch 00670: loss improved from 0.01908 to 0.01897, saving model to model_part2.hdf5

Epoch 00671: loss improved from 0.01897 to 0.01886, saving model to model_part2.hdf5

Epoch 00672: loss improved from 0.01886 to 0.01876, saving model to model_part2.hdf5

Epoch 00673: loss improved from 0.01876 to 0.01865, saving model to model_part2.hdf5

Epoch 00674: loss improved from 0.01865 to 0.01854, saving model to model_part2.hdf5

Epoch 00675: loss improved from 0.01854 to 0.01843, saving model to model_part2.hdf5

Epoch 00676: loss improved from 0.01843 to 0.01833, saving model to model_part2.hdf5

Epoch 00677: loss improved from 0.01833 to 0.01822, saving model to model_part2.hdf5

Epoch 00678: loss improved from 0.01822 to 0.01812, saving model to model_part2.hdf5

Epoch 00679: loss improved from 0.01812 to 0.01802, saving model to model_part2.hdf5

Epoch 00680: loss improved from 0.01802 to 0.01791, saving model to model_part2.hdf5

Epoch 00681: loss improved from 0.01791 to 0.01781, saving model to model_part2.hdf5

Epoch 00682: loss improved from 0.01781 to 0.01771, saving model to model_part2.hdf5

Epoch 00683: loss improved from 0.01771 to 0.01761, saving model to model_part2.hdf5

Epoch 00684: loss improved from 0.01761 to 0.01751, saving model to model_part2.hdf5

Epoch 00685: loss improved from 0.01751 to 0.01741, saving model to model_part2.hdf5

Epoch 00686: loss improved from 0.01741 to 0.01732, saving model to model_part2.hdf5

Epoch 00687: loss improved from 0.01732 to 0.01722, saving model to model_part2.hdf5

Epoch 00688: loss improved from 0.01722 to 0.01712, saving model to model_part2.hdf5

Epoch 00689: loss improved from 0.01712 to 0.01702, saving model to model_part2.hdf5

Epoch 00690: loss improved from 0.01702 to 0.01692, saving model to model_part2.hdf5

Epoch 00691: loss improved from 0.01692 to 0.01683, saving model to model_part2.hdf5

Epoch 00692: loss improved from 0.01683 to 0.01673, saving model to model_part2.hdf5

Epoch 00693: loss improved from 0.01673 to 0.01665, saving model to model_part2.hdf5

Epoch 00694: loss improved from 0.01665 to 0.01654, saving model to model_part2.hdf5

Epoch 00695: loss improved from 0.01654 to 0.01645, saving model to model_part2.hdf5

Epoch 00696: loss improved from 0.01645 to 0.01635, saving model to model_part2.hdf5

Epoch 00697: loss improved from 0.01635 to 0.01626, saving model to model_part2.hdf5

Epoch 00698: loss improved from 0.01626 to 0.01617, saving model to model_part2.hdf5

Epoch 00699: loss improved from 0.01617 to 0.01608, saving model to model_part2.hdf5

Epoch 00700: loss improved from 0.01608 to 0.01599, saving model to model_part2.hdf5

Epoch 00701: loss improved from 0.01599 to 0.01589, saving model to model_part2.hdf5

Epoch 00702: loss improved from 0.01589 to 0.01580, saving model to model_part2.hdf5

Epoch 00703: loss improved from 0.01580 to 0.01571, saving model to model_part2.hdf5

Epoch 00704: loss improved from 0.01571 to 0.01562, saving model to model_part2.hdf5

Epoch 00705: loss improved from 0.01562 to 0.01553, saving model to model_part2.hdf5

Epoch 00706: loss improved from 0.01553 to 0.01544, saving model to model_part2.hdf5

Epoch 00707: loss improved from 0.01544 to 0.01536, saving model to model_part2.hdf5

Epoch 00708: loss improved from 0.01536 to 0.01527, saving model to model_part2.hdf5

Epoch 00709: loss improved from 0.01527 to 0.01519, saving model to model_part2.hdf5

Epoch 00710: loss improved from 0.01519 to 0.01510, saving model to model_part2.hdf5

Epoch 00711: loss improved from 0.01510 to 0.01501, saving model to model_part2.hdf5

Epoch 00712: loss improved from 0.01501 to 0.01493, saving model to model_part2.hdf5

Epoch 00713: loss improved from 0.01493 to 0.01484, saving model to model_part2.hdf5

Epoch 00714: loss improved from 0.01484 to 0.01476, saving model to model_part2.hdf5

Epoch 00715: loss improved from 0.01476 to 0.01468, saving model to model_part2.hdf5

Epoch 00716: loss improved from 0.01468 to 0.01459, saving model to model_part2.hdf5

Epoch 00717: loss improved from 0.01459 to 0.01451, saving model to model_part2.hdf5

Epoch 00718: loss improved from 0.01451 to 0.01443, saving model to model_part2.hdf5

Epoch 00719: loss improved from 0.01443 to 0.01435, saving model to model_part2.hdf5

Epoch 00720: loss improved from 0.01435 to 0.01427, saving model to model_part2.hdf5

Epoch 00721: loss improved from 0.01427 to 0.01418, saving model to model_part2.hdf5

Epoch 00722: loss improved from 0.01418 to 0.01410, saving model to model_part2.hdf5

Epoch 00723: loss improved from 0.01410 to 0.01402, saving model to model_part2.hdf5

Epoch 00724: loss improved from 0.01402 to 0.01394, saving model to model_part2.hdf5

Epoch 00725: loss improved from 0.01394 to 0.01386, saving model to model_part2.hdf5

Epoch 00726: loss improved from 0.01386 to 0.01378, saving model to model_part2.hdf5

Epoch 00727: loss improved from 0.01378 to 0.01370, saving model to model_part2.hdf5

Epoch 00728: loss improved from 0.01370 to 0.01363, saving model to model_part2.hdf5

Epoch 00729: loss improved from 0.01363 to 0.01355, saving model to model_part2.hdf5

Epoch 00730: loss improved from 0.01355 to 0.01347, saving model to model_part2.hdf5

Epoch 00731: loss improved from 0.01347 to 0.01339, saving model to model_part2.hdf5

Epoch 00732: loss improved from 0.01339 to 0.01331, saving model to model_part2.hdf5

Epoch 00733: loss improved from 0.01331 to 0.01324, saving model to model_part2.hdf5

Epoch 00734: loss improved from 0.01324 to 0.01316, saving model to model_part2.hdf5

Epoch 00735: loss improved from 0.01316 to 0.01309, saving model to model_part2.hdf5

Epoch 00736: loss improved from 0.01309 to 0.01302, saving model to model_part2.hdf5

Epoch 00737: loss improved from 0.01302 to 0.01295, saving model to model_part2.hdf5

Epoch 00738: loss improved from 0.01295 to 0.01287, saving model to model_part2.hdf5

Epoch 00739: loss improved from 0.01287 to 0.01280, saving model to model_part2.hdf5

Epoch 00740: loss improved from 0.01280 to 0.01272, saving model to model_part2.hdf5

Epoch 00741: loss improved from 0.01272 to 0.01265, saving model to model_part2.hdf5

Epoch 00742: loss improved from 0.01265 to 0.01258, saving model to model_part2.hdf5

Epoch 00743: loss improved from 0.01258 to 0.01250, saving model to model_part2.hdf5

Epoch 00744: loss improved from 0.01250 to 0.01243, saving model to model_part2.hdf5

Epoch 00745: loss improved from 0.01243 to 0.01236, saving model to model_part2.hdf5

Epoch 00746: loss improved from 0.01236 to 0.01229, saving model to model_part2.hdf5

Epoch 00747: loss improved from 0.01229 to 0.01222, saving model to model_part2.hdf5

Epoch 00748: loss improved from 0.01222 to 0.01215, saving model to model_part2.hdf5

Epoch 00749: loss improved from 0.01215 to 0.01208, saving model to model_part2.hdf5

Epoch 00750: loss improved from 0.01208 to 0.01201, saving model to model_part2.hdf5

Epoch 00751: loss improved from 0.01201 to 0.01195, saving model to model_part2.hdf5

Epoch 00752: loss improved from 0.01195 to 0.01188, saving model to model_part2.hdf5

Epoch 00753: loss improved from 0.01188 to 0.01181, saving model to model_part2.hdf5

Epoch 00754: loss improved from 0.01181 to 0.01174, saving model to model_part2.hdf5

Epoch 00755: loss improved from 0.01174 to 0.01168, saving model to model_part2.hdf5

Epoch 00756: loss improved from 0.01168 to 0.01161, saving model to model_part2.hdf5

Epoch 00757: loss improved from 0.01161 to 0.01154, saving model to model_part2.hdf5

Epoch 00758: loss improved from 0.01154 to 0.01148, saving model to model_part2.hdf5

Epoch 00759: loss improved from 0.01148 to 0.01141, saving model to model_part2.hdf5

Epoch 00760: loss improved from 0.01141 to 0.01135, saving model to model_part2.hdf5

Epoch 00761: loss improved from 0.01135 to 0.01128, saving model to model_part2.hdf5

Epoch 00762: loss improved from 0.01128 to 0.01122, saving model to model_part2.hdf5

Epoch 00763: loss improved from 0.01122 to 0.01115, saving model to model_part2.hdf5

Epoch 00764: loss improved from 0.01115 to 0.01109, saving model to model_part2.hdf5

Epoch 00765: loss improved from 0.01109 to 0.01103, saving model to model_part2.hdf5

Epoch 00766: loss improved from 0.01103 to 0.01096, saving model to model_part2.hdf5

Epoch 00767: loss improved from 0.01096 to 0.01090, saving model to model_part2.hdf5

Epoch 00768: loss improved from 0.01090 to 0.01084, saving model to model_part2.hdf5

Epoch 00769: loss improved from 0.01084 to 0.01078, saving model to model_part2.hdf5

Epoch 00770: loss improved from 0.01078 to 0.01072, saving model to model_part2.hdf5

Epoch 00771: loss improved from 0.01072 to 0.01066, saving model to model_part2.hdf5

Epoch 00772: loss improved from 0.01066 to 0.01060, saving model to model_part2.hdf5

Epoch 00773: loss improved from 0.01060 to 0.01054, saving model to model_part2.hdf5

Epoch 00774: loss improved from 0.01054 to 0.01048, saving model to model_part2.hdf5

Epoch 00775: loss improved from 0.01048 to 0.01042, saving model to model_part2.hdf5

Epoch 00776: loss improved from 0.01042 to 0.01035, saving model to model_part2.hdf5

Epoch 00777: loss improved from 0.01035 to 0.01030, saving model to model_part2.hdf5

Epoch 00778: loss improved from 0.01030 to 0.01024, saving model to model_part2.hdf5

Epoch 00779: loss improved from 0.01024 to 0.01018, saving model to model_part2.hdf5

Epoch 00780: loss improved from 0.01018 to 0.01012, saving model to model_part2.hdf5

Epoch 00781: loss improved from 0.01012 to 0.01006, saving model to model_part2.hdf5

Epoch 00782: loss improved from 0.01006 to 0.01001, saving model to model_part2.hdf5

Epoch 00783: loss improved from 0.01001 to 0.00995, saving model to model_part2.hdf5

Epoch 00784: loss improved from 0.00995 to 0.00989, saving model to model_part2.hdf5

Epoch 00785: loss improved from 0.00989 to 0.00983, saving model to model_part2.hdf5

Epoch 00786: loss improved from 0.00983 to 0.00977, saving model to model_part2.hdf5

Epoch 00787: loss improved from 0.00977 to 0.00972, saving model to model_part2.hdf5

Epoch 00788: loss improved from 0.00972 to 0.00966, saving model to model_part2.hdf5

Epoch 00789: loss improved from 0.00966 to 0.00961, saving model to model_part2.hdf5

Epoch 00790: loss improved from 0.00961 to 0.00955, saving model to model_part2.hdf5

Epoch 00791: loss improved from 0.00955 to 0.00950, saving model to model_part2.hdf5

Epoch 00792: loss improved from 0.00950 to 0.00944, saving model to model_part2.hdf5

Epoch 00793: loss improved from 0.00944 to 0.00939, saving model to model_part2.hdf5

Epoch 00794: loss improved from 0.00939 to 0.00934, saving model to model_part2.hdf5

Epoch 00795: loss improved from 0.00934 to 0.00928, saving model to model_part2.hdf5

Epoch 00796: loss improved from 0.00928 to 0.00923, saving model to model_part2.hdf5

Epoch 00797: loss improved from 0.00923 to 0.00918, saving model to model_part2.hdf5

Epoch 00798: loss improved from 0.00918 to 0.00912, saving model to model_part2.hdf5

Epoch 00799: loss improved from 0.00912 to 0.00907, saving model to model_part2.hdf5

Epoch 00800: loss improved from 0.00907 to 0.00902, saving model to model_part2.hdf5

Epoch 00801: loss improved from 0.00902 to 0.00898, saving model to model_part2.hdf5

Epoch 00802: loss improved from 0.00898 to 0.00892, saving model to model_part2.hdf5

Epoch 00803: loss improved from 0.00892 to 0.00887, saving model to model_part2.hdf5

Epoch 00804: loss improved from 0.00887 to 0.00881, saving model to model_part2.hdf5

Epoch 00805: loss improved from 0.00881 to 0.00876, saving model to model_part2.hdf5

Epoch 00806: loss improved from 0.00876 to 0.00871, saving model to model_part2.hdf5

Epoch 00807: loss improved from 0.00871 to 0.00866, saving model to model_part2.hdf5

Epoch 00808: loss improved from 0.00866 to 0.00861, saving model to model_part2.hdf5

Epoch 00809: loss improved from 0.00861 to 0.00857, saving model to model_part2.hdf5

Epoch 00810: loss improved from 0.00857 to 0.00852, saving model to model_part2.hdf5

Epoch 00811: loss improved from 0.00852 to 0.00847, saving model to model_part2.hdf5

Epoch 00812: loss improved from 0.00847 to 0.00842, saving model to model_part2.hdf5

Epoch 00813: loss improved from 0.00842 to 0.00837, saving model to model_part2.hdf5

Epoch 00814: loss improved from 0.00837 to 0.00832, saving model to model_part2.hdf5

Epoch 00815: loss improved from 0.00832 to 0.00828, saving model to model_part2.hdf5

Epoch 00816: loss improved from 0.00828 to 0.00823, saving model to model_part2.hdf5

Epoch 00817: loss improved from 0.00823 to 0.00818, saving model to model_part2.hdf5

Epoch 00818: loss improved from 0.00818 to 0.00814, saving model to model_part2.hdf5

Epoch 00819: loss improved from 0.00814 to 0.00809, saving model to model_part2.hdf5

Epoch 00820: loss improved from 0.00809 to 0.00804, saving model to model_part2.hdf5

Epoch 00821: loss improved from 0.00804 to 0.00800, saving model to model_part2.hdf5

Epoch 00822: loss improved from 0.00800 to 0.00795, saving model to model_part2.hdf5

Epoch 00823: loss improved from 0.00795 to 0.00791, saving model to model_part2.hdf5

Epoch 00824: loss improved from 0.00791 to 0.00786, saving model to model_part2.hdf5

Epoch 00825: loss improved from 0.00786 to 0.00781, saving model to model_part2.hdf5

Epoch 00826: loss improved from 0.00781 to 0.00777, saving model to model_part2.hdf5

Epoch 00827: loss improved from 0.00777 to 0.00772, saving model to model_part2.hdf5

Epoch 00828: loss improved from 0.00772 to 0.00768, saving model to model_part2.hdf5

Epoch 00829: loss improved from 0.00768 to 0.00763, saving model to model_part2.hdf5

Epoch 00830: loss improved from 0.00763 to 0.00759, saving model to model_part2.hdf5

Epoch 00831: loss improved from 0.00759 to 0.00755, saving model to model_part2.hdf5

Epoch 00832: loss improved from 0.00755 to 0.00750, saving model to model_part2.hdf5

Epoch 00833: loss improved from 0.00750 to 0.00746, saving model to model_part2.hdf5

Epoch 00834: loss improved from 0.00746 to 0.00742, saving model to model_part2.hdf5

Epoch 00835: loss improved from 0.00742 to 0.00737, saving model to model_part2.hdf5

Epoch 00836: loss improved from 0.00737 to 0.00733, saving model to model_part2.hdf5

Epoch 00837: loss improved from 0.00733 to 0.00729, saving model to model_part2.hdf5

Epoch 00838: loss improved from 0.00729 to 0.00725, saving model to model_part2.hdf5

Epoch 00839: loss improved from 0.00725 to 0.00720, saving model to model_part2.hdf5

Epoch 00840: loss improved from 0.00720 to 0.00716, saving model to model_part2.hdf5

Epoch 00841: loss improved from 0.00716 to 0.00712, saving model to model_part2.hdf5

Epoch 00842: loss improved from 0.00712 to 0.00708, saving model to model_part2.hdf5

Epoch 00843: loss improved from 0.00708 to 0.00704, saving model to model_part2.hdf5

Epoch 00844: loss improved from 0.00704 to 0.00700, saving model to model_part2.hdf5

Epoch 00845: loss improved from 0.00700 to 0.00696, saving model to model_part2.hdf5

Epoch 00846: loss improved from 0.00696 to 0.00692, saving model to model_part2.hdf5

Epoch 00847: loss improved from 0.00692 to 0.00688, saving model to model_part2.hdf5

Epoch 00848: loss improved from 0.00688 to 0.00684, saving model to model_part2.hdf5

Epoch 00849: loss improved from 0.00684 to 0.00680, saving model to model_part2.hdf5

Epoch 00850: loss improved from 0.00680 to 0.00676, saving model to model_part2.hdf5

Epoch 00851: loss improved from 0.00676 to 0.00672, saving model to model_part2.hdf5

Epoch 00852: loss improved from 0.00672 to 0.00669, saving model to model_part2.hdf5

Epoch 00853: loss improved from 0.00669 to 0.00665, saving model to model_part2.hdf5

Epoch 00854: loss improved from 0.00665 to 0.00661, saving model to model_part2.hdf5

Epoch 00855: loss improved from 0.00661 to 0.00657, saving model to model_part2.hdf5

Epoch 00856: loss improved from 0.00657 to 0.00653, saving model to model_part2.hdf5

Epoch 00857: loss improved from 0.00653 to 0.00650, saving model to model_part2.hdf5

Epoch 00858: loss improved from 0.00650 to 0.00646, saving model to model_part2.hdf5

Epoch 00859: loss improved from 0.00646 to 0.00642, saving model to model_part2.hdf5

Epoch 00860: loss improved from 0.00642 to 0.00638, saving model to model_part2.hdf5

Epoch 00861: loss improved from 0.00638 to 0.00635, saving model to model_part2.hdf5

Epoch 00862: loss improved from 0.00635 to 0.00631, saving model to model_part2.hdf5

Epoch 00863: loss improved from 0.00631 to 0.00628, saving model to model_part2.hdf5

Epoch 00864: loss improved from 0.00628 to 0.00624, saving model to model_part2.hdf5

Epoch 00865: loss improved from 0.00624 to 0.00620, saving model to model_part2.hdf5

Epoch 00866: loss improved from 0.00620 to 0.00617, saving model to model_part2.hdf5

Epoch 00867: loss improved from 0.00617 to 0.00613, saving model to model_part2.hdf5

Epoch 00868: loss improved from 0.00613 to 0.00610, saving model to model_part2.hdf5

Epoch 00869: loss improved from 0.00610 to 0.00606, saving model to model_part2.hdf5

Epoch 00870: loss improved from 0.00606 to 0.00603, saving model to model_part2.hdf5

Epoch 00871: loss improved from 0.00603 to 0.00600, saving model to model_part2.hdf5

Epoch 00872: loss improved from 0.00600 to 0.00596, saving model to model_part2.hdf5

Epoch 00873: loss improved from 0.00596 to 0.00592, saving model to model_part2.hdf5

Epoch 00874: loss improved from 0.00592 to 0.00589, saving model to model_part2.hdf5

Epoch 00875: loss improved from 0.00589 to 0.00585, saving model to model_part2.hdf5

Epoch 00876: loss improved from 0.00585 to 0.00582, saving model to model_part2.hdf5

Epoch 00877: loss improved from 0.00582 to 0.00579, saving model to model_part2.hdf5

Epoch 00878: loss improved from 0.00579 to 0.00575, saving model to model_part2.hdf5

Epoch 00879: loss improved from 0.00575 to 0.00572, saving model to model_part2.hdf5

Epoch 00880: loss improved from 0.00572 to 0.00569, saving model to model_part2.hdf5

Epoch 00881: loss improved from 0.00569 to 0.00566, saving model to model_part2.hdf5

Epoch 00882: loss improved from 0.00566 to 0.00562, saving model to model_part2.hdf5

Epoch 00883: loss improved from 0.00562 to 0.00559, saving model to model_part2.hdf5

Epoch 00884: loss improved from 0.00559 to 0.00556, saving model to model_part2.hdf5

Epoch 00885: loss improved from 0.00556 to 0.00552, saving model to model_part2.hdf5

Epoch 00886: loss improved from 0.00552 to 0.00549, saving model to model_part2.hdf5

Epoch 00887: loss improved from 0.00549 to 0.00546, saving model to model_part2.hdf5

Epoch 00888: loss improved from 0.00546 to 0.00543, saving model to model_part2.hdf5

Epoch 00889: loss improved from 0.00543 to 0.00540, saving model to model_part2.hdf5

Epoch 00890: loss improved from 0.00540 to 0.00537, saving model to model_part2.hdf5

Epoch 00891: loss improved from 0.00537 to 0.00534, saving model to model_part2.hdf5

Epoch 00892: loss improved from 0.00534 to 0.00530, saving model to model_part2.hdf5

Epoch 00893: loss improved from 0.00530 to 0.00527, saving model to model_part2.hdf5

Epoch 00894: loss improved from 0.00527 to 0.00524, saving model to model_part2.hdf5

Epoch 00895: loss improved from 0.00524 to 0.00521, saving model to model_part2.hdf5

Epoch 00896: loss improved from 0.00521 to 0.00518, saving model to model_part2.hdf5

Epoch 00897: loss improved from 0.00518 to 0.00515, saving model to model_part2.hdf5

Epoch 00898: loss improved from 0.00515 to 0.00512, saving model to model_part2.hdf5

Epoch 00899: loss improved from 0.00512 to 0.00509, saving model to model_part2.hdf5

Epoch 00900: loss improved from 0.00509 to 0.00506, saving model to model_part2.hdf5

Epoch 00901: loss improved from 0.00506 to 0.00504, saving model to model_part2.hdf5

Epoch 00902: loss improved from 0.00504 to 0.00501, saving model to model_part2.hdf5

Epoch 00903: loss improved from 0.00501 to 0.00498, saving model to model_part2.hdf5

Epoch 00904: loss improved from 0.00498 to 0.00495, saving model to model_part2.hdf5

Epoch 00905: loss improved from 0.00495 to 0.00492, saving model to model_part2.hdf5

Epoch 00906: loss improved from 0.00492 to 0.00489, saving model to model_part2.hdf5

Epoch 00907: loss improved from 0.00489 to 0.00486, saving model to model_part2.hdf5

Epoch 00908: loss improved from 0.00486 to 0.00484, saving model to model_part2.hdf5

Epoch 00909: loss improved from 0.00484 to 0.00481, saving model to model_part2.hdf5

Epoch 00910: loss improved from 0.00481 to 0.00478, saving model to model_part2.hdf5

Epoch 00911: loss improved from 0.00478 to 0.00475, saving model to model_part2.hdf5

Epoch 00912: loss improved from 0.00475 to 0.00472, saving model to model_part2.hdf5

Epoch 00913: loss improved from 0.00472 to 0.00470, saving model to model_part2.hdf5

Epoch 00914: loss improved from 0.00470 to 0.00467, saving model to model_part2.hdf5

Epoch 00915: loss improved from 0.00467 to 0.00464, saving model to model_part2.hdf5

Epoch 00916: loss improved from 0.00464 to 0.00462, saving model to model_part2.hdf5

Epoch 00917: loss improved from 0.00462 to 0.00459, saving model to model_part2.hdf5

Epoch 00918: loss improved from 0.00459 to 0.00456, saving model to model_part2.hdf5

Epoch 00919: loss improved from 0.00456 to 0.00454, saving model to model_part2.hdf5

Epoch 00920: loss improved from 0.00454 to 0.00451, saving model to model_part2.hdf5

Epoch 00921: loss improved from 0.00451 to 0.00449, saving model to model_part2.hdf5

Epoch 00922: loss improved from 0.00449 to 0.00446, saving model to model_part2.hdf5

Epoch 00923: loss improved from 0.00446 to 0.00443, saving model to model_part2.hdf5

Epoch 00924: loss improved from 0.00443 to 0.00441, saving model to model_part2.hdf5

Epoch 00925: loss improved from 0.00441 to 0.00438, saving model to model_part2.hdf5

Epoch 00926: loss improved from 0.00438 to 0.00436, saving model to model_part2.hdf5

Epoch 00927: loss improved from 0.00436 to 0.00433, saving model to model_part2.hdf5

Epoch 00928: loss improved from 0.00433 to 0.00431, saving model to model_part2.hdf5

Epoch 00929: loss improved from 0.00431 to 0.00428, saving model to model_part2.hdf5

Epoch 00930: loss improved from 0.00428 to 0.00426, saving model to model_part2.hdf5

Epoch 00931: loss improved from 0.00426 to 0.00423, saving model to model_part2.hdf5

Epoch 00932: loss improved from 0.00423 to 0.00421, saving model to model_part2.hdf5

Epoch 00933: loss improved from 0.00421 to 0.00419, saving model to model_part2.hdf5

Epoch 00934: loss improved from 0.00419 to 0.00416, saving model to model_part2.hdf5

Epoch 00935: loss improved from 0.00416 to 0.00414, saving model to model_part2.hdf5

Epoch 00936: loss improved from 0.00414 to 0.00411, saving model to model_part2.hdf5

Epoch 00937: loss improved from 0.00411 to 0.00409, saving model to model_part2.hdf5

Epoch 00938: loss improved from 0.00409 to 0.00406, saving model to model_part2.hdf5

Epoch 00939: loss improved from 0.00406 to 0.00404, saving model to model_part2.hdf5

Epoch 00940: loss improved from 0.00404 to 0.00402, saving model to model_part2.hdf5

Epoch 00941: loss improved from 0.00402 to 0.00400, saving model to model_part2.hdf5

Epoch 00942: loss improved from 0.00400 to 0.00397, saving model to model_part2.hdf5

Epoch 00943: loss improved from 0.00397 to 0.00395, saving model to model_part2.hdf5

Epoch 00944: loss improved from 0.00395 to 0.00393, saving model to model_part2.hdf5

Epoch 00945: loss improved from 0.00393 to 0.00390, saving model to model_part2.hdf5

Epoch 00946: loss improved from 0.00390 to 0.00388, saving model to model_part2.hdf5

Epoch 00947: loss improved from 0.00388 to 0.00386, saving model to model_part2.hdf5

Epoch 00948: loss improved from 0.00386 to 0.00384, saving model to model_part2.hdf5

Epoch 00949: loss improved from 0.00384 to 0.00381, saving model to model_part2.hdf5

Epoch 00950: loss improved from 0.00381 to 0.00379, saving model to model_part2.hdf5

Epoch 00951: loss improved from 0.00379 to 0.00377, saving model to model_part2.hdf5

Epoch 00952: loss improved from 0.00377 to 0.00375, saving model to model_part2.hdf5

Epoch 00953: loss improved from 0.00375 to 0.00373, saving model to model_part2.hdf5

Epoch 00954: loss improved from 0.00373 to 0.00371, saving model to model_part2.hdf5

Epoch 00955: loss improved from 0.00371 to 0.00368, saving model to model_part2.hdf5

Epoch 00956: loss improved from 0.00368 to 0.00366, saving model to model_part2.hdf5

Epoch 00957: loss improved from 0.00366 to 0.00364, saving model to model_part2.hdf5

Epoch 00958: loss improved from 0.00364 to 0.00362, saving model to model_part2.hdf5

Epoch 00959: loss improved from 0.00362 to 0.00360, saving model to model_part2.hdf5

Epoch 00960: loss improved from 0.00360 to 0.00358, saving model to model_part2.hdf5

Epoch 00961: loss improved from 0.00358 to 0.00356, saving model to model_part2.hdf5

Epoch 00962: loss improved from 0.00356 to 0.00354, saving model to model_part2.hdf5

Epoch 00963: loss improved from 0.00354 to 0.00352, saving model to model_part2.hdf5

Epoch 00964: loss improved from 0.00352 to 0.00350, saving model to model_part2.hdf5

Epoch 00965: loss improved from 0.00350 to 0.00348, saving model to model_part2.hdf5

Epoch 00966: loss improved from 0.00348 to 0.00346, saving model to model_part2.hdf5

Epoch 00967: loss improved from 0.00346 to 0.00344, saving model to model_part2.hdf5

Epoch 00968: loss improved from 0.00344 to 0.00342, saving model to model_part2.hdf5

Epoch 00969: loss improved from 0.00342 to 0.00340, saving model to model_part2.hdf5

Epoch 00970: loss improved from 0.00340 to 0.00338, saving model to model_part2.hdf5

Epoch 00971: loss improved from 0.00338 to 0.00336, saving model to model_part2.hdf5

Epoch 00972: loss improved from 0.00336 to 0.00334, saving model to model_part2.hdf5

Epoch 00973: loss improved from 0.00334 to 0.00332, saving model to model_part2.hdf5

Epoch 00974: loss improved from 0.00332 to 0.00330, saving model to model_part2.hdf5

Epoch 00975: loss improved from 0.00330 to 0.00328, saving model to model_part2.hdf5

Epoch 00976: loss improved from 0.00328 to 0.00326, saving model to model_part2.hdf5

Epoch 00977: loss improved from 0.00326 to 0.00324, saving model to model_part2.hdf5

Epoch 00978: loss improved from 0.00324 to 0.00323, saving model to model_part2.hdf5

Epoch 00979: loss improved from 0.00323 to 0.00321, saving model to model_part2.hdf5

Epoch 00980: loss improved from 0.00321 to 0.00319, saving model to model_part2.hdf5

Epoch 00981: loss improved from 0.00319 to 0.00317, saving model to model_part2.hdf5

Epoch 00982: loss improved from 0.00317 to 0.00315, saving model to model_part2.hdf5

Epoch 00983: loss improved from 0.00315 to 0.00313, saving model to model_part2.hdf5

Epoch 00984: loss improved from 0.00313 to 0.00312, saving model to model_part2.hdf5

Epoch 00985: loss improved from 0.00312 to 0.00310, saving model to model_part2.hdf5

Epoch 00986: loss improved from 0.00310 to 0.00308, saving model to model_part2.hdf5

Epoch 00987: loss improved from 0.00308 to 0.00306, saving model to model_part2.hdf5

Epoch 00988: loss improved from 0.00306 to 0.00305, saving model to model_part2.hdf5

Epoch 00989: loss improved from 0.00305 to 0.00303, saving model to model_part2.hdf5

Epoch 00990: loss improved from 0.00303 to 0.00301, saving model to model_part2.hdf5

Epoch 00991: loss improved from 0.00301 to 0.00299, saving model to model_part2.hdf5

Epoch 00992: loss improved from 0.00299 to 0.00298, saving model to model_part2.hdf5

Epoch 00993: loss improved from 0.00298 to 0.00296, saving model to model_part2.hdf5

Epoch 00994: loss improved from 0.00296 to 0.00294, saving model to model_part2.hdf5

Epoch 00995: loss improved from 0.00294 to 0.00292, saving model to model_part2.hdf5

Epoch 00996: loss improved from 0.00292 to 0.00291, saving model to model_part2.hdf5

Epoch 00997: loss improved from 0.00291 to 0.00289, saving model to model_part2.hdf5

Epoch 00998: loss improved from 0.00289 to 0.00287, saving model to model_part2.hdf5

Epoch 00999: loss improved from 0.00287 to 0.00286, saving model to model_part2.hdf5

Epoch 01000: loss improved from 0.00286 to 0.00284, saving model to model_part2.hdf5

Epoch 01001: loss improved from 0.00284 to 0.00282, saving model to model_part2.hdf5

Epoch 01002: loss improved from 0.00282 to 0.00281, saving model to model_part2.hdf5

Epoch 01003: loss improved from 0.00281 to 0.00279, saving model to model_part2.hdf5

Epoch 01004: loss improved from 0.00279 to 0.00278, saving model to model_part2.hdf5

Epoch 01005: loss improved from 0.00278 to 0.00276, saving model to model_part2.hdf5

Epoch 01006: loss improved from 0.00276 to 0.00274, saving model to model_part2.hdf5

Epoch 01007: loss improved from 0.00274 to 0.00273, saving model to model_part2.hdf5

Epoch 01008: loss improved from 0.00273 to 0.00271, saving model to model_part2.hdf5

Epoch 01009: loss improved from 0.00271 to 0.00270, saving model to model_part2.hdf5

Epoch 01010: loss improved from 0.00270 to 0.00268, saving model to model_part2.hdf5

Epoch 01011: loss improved from 0.00268 to 0.00266, saving model to model_part2.hdf5

Epoch 01012: loss improved from 0.00266 to 0.00265, saving model to model_part2.hdf5

Epoch 01013: loss improved from 0.00265 to 0.00263, saving model to model_part2.hdf5

Epoch 01014: loss improved from 0.00263 to 0.00262, saving model to model_part2.hdf5

Epoch 01015: loss improved from 0.00262 to 0.00260, saving model to model_part2.hdf5

Epoch 01016: loss improved from 0.00260 to 0.00259, saving model to model_part2.hdf5

Epoch 01017: loss improved from 0.00259 to 0.00257, saving model to model_part2.hdf5

Epoch 01018: loss improved from 0.00257 to 0.00256, saving model to model_part2.hdf5

Epoch 01019: loss improved from 0.00256 to 0.00254, saving model to model_part2.hdf5

Epoch 01020: loss improved from 0.00254 to 0.00253, saving model to model_part2.hdf5

Epoch 01021: loss improved from 0.00253 to 0.00251, saving model to model_part2.hdf5

Epoch 01022: loss improved from 0.00251 to 0.00250, saving model to model_part2.hdf5

Epoch 01023: loss improved from 0.00250 to 0.00248, saving model to model_part2.hdf5

Epoch 01024: loss improved from 0.00248 to 0.00247, saving model to model_part2.hdf5

Epoch 01025: loss improved from 0.00247 to 0.00246, saving model to model_part2.hdf5

Epoch 01026: loss improved from 0.00246 to 0.00244, saving model to model_part2.hdf5

Epoch 01027: loss improved from 0.00244 to 0.00243, saving model to model_part2.hdf5

Epoch 01028: loss improved from 0.00243 to 0.00241, saving model to model_part2.hdf5

Epoch 01029: loss improved from 0.00241 to 0.00240, saving model to model_part2.hdf5

Epoch 01030: loss improved from 0.00240 to 0.00239, saving model to model_part2.hdf5

Epoch 01031: loss improved from 0.00239 to 0.00237, saving model to model_part2.hdf5

Epoch 01032: loss improved from 0.00237 to 0.00236, saving model to model_part2.hdf5

Epoch 01033: loss improved from 0.00236 to 0.00235, saving model to model_part2.hdf5

Epoch 01034: loss improved from 0.00235 to 0.00233, saving model to model_part2.hdf5

Epoch 01035: loss improved from 0.00233 to 0.00232, saving model to model_part2.hdf5

Epoch 01036: loss improved from 0.00232 to 0.00231, saving model to model_part2.hdf5

Epoch 01037: loss improved from 0.00231 to 0.00229, saving model to model_part2.hdf5

Epoch 01038: loss improved from 0.00229 to 0.00228, saving model to model_part2.hdf5

Epoch 01039: loss improved from 0.00228 to 0.00227, saving model to model_part2.hdf5

Epoch 01040: loss improved from 0.00227 to 0.00225, saving model to model_part2.hdf5

Epoch 01041: loss improved from 0.00225 to 0.00224, saving model to model_part2.hdf5

Epoch 01042: loss improved from 0.00224 to 0.00223, saving model to model_part2.hdf5

Epoch 01043: loss improved from 0.00223 to 0.00222, saving model to model_part2.hdf5

Epoch 01044: loss improved from 0.00222 to 0.00220, saving model to model_part2.hdf5

Epoch 01045: loss improved from 0.00220 to 0.00219, saving model to model_part2.hdf5

Epoch 01046: loss improved from 0.00219 to 0.00218, saving model to model_part2.hdf5

Epoch 01047: loss improved from 0.00218 to 0.00216, saving model to model_part2.hdf5

Epoch 01048: loss improved from 0.00216 to 0.00215, saving model to model_part2.hdf5

Epoch 01049: loss improved from 0.00215 to 0.00214, saving model to model_part2.hdf5

Epoch 01050: loss improved from 0.00214 to 0.00213, saving model to model_part2.hdf5

Epoch 01051: loss improved from 0.00213 to 0.00212, saving model to model_part2.hdf5

Epoch 01052: loss improved from 0.00212 to 0.00210, saving model to model_part2.hdf5

Epoch 01053: loss improved from 0.00210 to 0.00209, saving model to model_part2.hdf5

Epoch 01054: loss improved from 0.00209 to 0.00208, saving model to model_part2.hdf5

Epoch 01055: loss improved from 0.00208 to 0.00207, saving model to model_part2.hdf5

Epoch 01056: loss improved from 0.00207 to 0.00205, saving model to model_part2.hdf5

Epoch 01057: loss improved from 0.00205 to 0.00204, saving model to model_part2.hdf5

Epoch 01058: loss improved from 0.00204 to 0.00203, saving model to model_part2.hdf5

Epoch 01059: loss improved from 0.00203 to 0.00202, saving model to model_part2.hdf5

Epoch 01060: loss improved from 0.00202 to 0.00201, saving model to model_part2.hdf5

Epoch 01061: loss improved from 0.00201 to 0.00200, saving model to model_part2.hdf5

Epoch 01062: loss improved from 0.00200 to 0.00198, saving model to model_part2.hdf5

Epoch 01063: loss improved from 0.00198 to 0.00197, saving model to model_part2.hdf5

Epoch 01064: loss improved from 0.00197 to 0.00196, saving model to model_part2.hdf5

Epoch 01065: loss improved from 0.00196 to 0.00195, saving model to model_part2.hdf5

Epoch 01066: loss improved from 0.00195 to 0.00194, saving model to model_part2.hdf5

Epoch 01067: loss improved from 0.00194 to 0.00193, saving model to model_part2.hdf5

Epoch 01068: loss improved from 0.00193 to 0.00192, saving model to model_part2.hdf5

Epoch 01069: loss improved from 0.00192 to 0.00191, saving model to model_part2.hdf5

Epoch 01070: loss improved from 0.00191 to 0.00189, saving model to model_part2.hdf5

Epoch 01071: loss improved from 0.00189 to 0.00188, saving model to model_part2.hdf5

Epoch 01072: loss improved from 0.00188 to 0.00187, saving model to model_part2.hdf5

Epoch 01073: loss improved from 0.00187 to 0.00186, saving model to model_part2.hdf5

Epoch 01074: loss improved from 0.00186 to 0.00185, saving model to model_part2.hdf5

Epoch 01075: loss improved from 0.00185 to 0.00184, saving model to model_part2.hdf5

Epoch 01076: loss improved from 0.00184 to 0.00183, saving model to model_part2.hdf5

Epoch 01077: loss improved from 0.00183 to 0.00182, saving model to model_part2.hdf5

Epoch 01078: loss improved from 0.00182 to 0.00181, saving model to model_part2.hdf5

Epoch 01079: loss improved from 0.00181 to 0.00180, saving model to model_part2.hdf5

Epoch 01080: loss improved from 0.00180 to 0.00179, saving model to model_part2.hdf5

Epoch 01081: loss improved from 0.00179 to 0.00178, saving model to model_part2.hdf5

Epoch 01082: loss improved from 0.00178 to 0.00177, saving model to model_part2.hdf5

Epoch 01083: loss improved from 0.00177 to 0.00176, saving model to model_part2.hdf5

Epoch 01084: loss improved from 0.00176 to 0.00175, saving model to model_part2.hdf5

Epoch 01085: loss improved from 0.00175 to 0.00174, saving model to model_part2.hdf5

Epoch 01086: loss improved from 0.00174 to 0.00173, saving model to model_part2.hdf5

Epoch 01087: loss improved from 0.00173 to 0.00172, saving model to model_part2.hdf5

Epoch 01088: loss improved from 0.00172 to 0.00171, saving model to model_part2.hdf5

Epoch 01089: loss improved from 0.00171 to 0.00170, saving model to model_part2.hdf5

Epoch 01090: loss improved from 0.00170 to 0.00169, saving model to model_part2.hdf5

Epoch 01091: loss improved from 0.00169 to 0.00168, saving model to model_part2.hdf5

Epoch 01092: loss improved from 0.00168 to 0.00167, saving model to model_part2.hdf5

Epoch 01093: loss improved from 0.00167 to 0.00166, saving model to model_part2.hdf5

Epoch 01094: loss improved from 0.00166 to 0.00165, saving model to model_part2.hdf5

Epoch 01095: loss improved from 0.00165 to 0.00164, saving model to model_part2.hdf5

Epoch 01096: loss improved from 0.00164 to 0.00163, saving model to model_part2.hdf5

Epoch 01097: loss improved from 0.00163 to 0.00162, saving model to model_part2.hdf5

Epoch 01098: loss improved from 0.00162 to 0.00161, saving model to model_part2.hdf5

Epoch 01099: loss improved from 0.00161 to 0.00160, saving model to model_part2.hdf5

Epoch 01100: loss improved from 0.00160 to 0.00159, saving model to model_part2.hdf5

Epoch 01101: loss improved from 0.00159 to 0.00158, saving model to model_part2.hdf5

Epoch 01102: loss improved from 0.00158 to 0.00158, saving model to model_part2.hdf5

Epoch 01103: loss improved from 0.00158 to 0.00157, saving model to model_part2.hdf5

Epoch 01104: loss improved from 0.00157 to 0.00156, saving model to model_part2.hdf5

Epoch 01105: loss improved from 0.00156 to 0.00155, saving model to model_part2.hdf5

Epoch 01106: loss improved from 0.00155 to 0.00154, saving model to model_part2.hdf5

Epoch 01107: loss improved from 0.00154 to 0.00153, saving model to model_part2.hdf5

Epoch 01108: loss improved from 0.00153 to 0.00152, saving model to model_part2.hdf5

Epoch 01109: loss improved from 0.00152 to 0.00151, saving model to model_part2.hdf5

Epoch 01110: loss improved from 0.00151 to 0.00150, saving model to model_part2.hdf5

Epoch 01111: loss improved from 0.00150 to 0.00149, saving model to model_part2.hdf5

Epoch 01112: loss improved from 0.00149 to 0.00149, saving model to model_part2.hdf5

Epoch 01113: loss improved from 0.00149 to 0.00148, saving model to model_part2.hdf5

Epoch 01114: loss improved from 0.00148 to 0.00147, saving model to model_part2.hdf5

Epoch 01115: loss improved from 0.00147 to 0.00146, saving model to model_part2.hdf5

Epoch 01116: loss improved from 0.00146 to 0.00145, saving model to model_part2.hdf5

Epoch 01117: loss improved from 0.00145 to 0.00144, saving model to model_part2.hdf5

Epoch 01118: loss improved from 0.00144 to 0.00144, saving model to model_part2.hdf5

Epoch 01119: loss improved from 0.00144 to 0.00143, saving model to model_part2.hdf5

Epoch 01120: loss improved from 0.00143 to 0.00142, saving model to model_part2.hdf5

Epoch 01121: loss improved from 0.00142 to 0.00141, saving model to model_part2.hdf5

Epoch 01122: loss improved from 0.00141 to 0.00140, saving model to model_part2.hdf5

Epoch 01123: loss improved from 0.00140 to 0.00139, saving model to model_part2.hdf5

Epoch 01124: loss improved from 0.00139 to 0.00139, saving model to model_part2.hdf5

Epoch 01125: loss improved from 0.00139 to 0.00138, saving model to model_part2.hdf5

Epoch 01126: loss improved from 0.00138 to 0.00137, saving model to model_part2.hdf5

Epoch 01127: loss improved from 0.00137 to 0.00136, saving model to model_part2.hdf5

Epoch 01128: loss improved from 0.00136 to 0.00135, saving model to model_part2.hdf5

Epoch 01129: loss improved from 0.00135 to 0.00135, saving model to model_part2.hdf5

Epoch 01130: loss improved from 0.00135 to 0.00134, saving model to model_part2.hdf5

Epoch 01131: loss improved from 0.00134 to 0.00133, saving model to model_part2.hdf5

Epoch 01132: loss improved from 0.00133 to 0.00132, saving model to model_part2.hdf5

Epoch 01133: loss improved from 0.00132 to 0.00132, saving model to model_part2.hdf5

Epoch 01134: loss improved from 0.00132 to 0.00131, saving model to model_part2.hdf5

Epoch 01135: loss improved from 0.00131 to 0.00130, saving model to model_part2.hdf5

Epoch 01136: loss improved from 0.00130 to 0.00129, saving model to model_part2.hdf5

Epoch 01137: loss improved from 0.00129 to 0.00129, saving model to model_part2.hdf5

Epoch 01138: loss improved from 0.00129 to 0.00128, saving model to model_part2.hdf5

Epoch 01139: loss improved from 0.00128 to 0.00127, saving model to model_part2.hdf5

Epoch 01140: loss improved from 0.00127 to 0.00126, saving model to model_part2.hdf5

Epoch 01141: loss improved from 0.00126 to 0.00126, saving model to model_part2.hdf5

Epoch 01142: loss improved from 0.00126 to 0.00125, saving model to model_part2.hdf5

Epoch 01143: loss improved from 0.00125 to 0.00124, saving model to model_part2.hdf5

Epoch 01144: loss improved from 0.00124 to 0.00123, saving model to model_part2.hdf5

Epoch 01145: loss improved from 0.00123 to 0.00123, saving model to model_part2.hdf5

Epoch 01146: loss improved from 0.00123 to 0.00122, saving model to model_part2.hdf5

Epoch 01147: loss improved from 0.00122 to 0.00121, saving model to model_part2.hdf5

Epoch 01148: loss improved from 0.00121 to 0.00121, saving model to model_part2.hdf5

Epoch 01149: loss improved from 0.00121 to 0.00120, saving model to model_part2.hdf5

Epoch 01150: loss improved from 0.00120 to 0.00119, saving model to model_part2.hdf5

Epoch 01151: loss improved from 0.00119 to 0.00118, saving model to model_part2.hdf5

Epoch 01152: loss improved from 0.00118 to 0.00118, saving model to model_part2.hdf5

Epoch 01153: loss improved from 0.00118 to 0.00117, saving model to model_part2.hdf5

Epoch 01154: loss improved from 0.00117 to 0.00116, saving model to model_part2.hdf5

Epoch 01155: loss improved from 0.00116 to 0.00116, saving model to model_part2.hdf5

Epoch 01156: loss improved from 0.00116 to 0.00115, saving model to model_part2.hdf5

Epoch 01157: loss improved from 0.00115 to 0.00114, saving model to model_part2.hdf5

Epoch 01158: loss improved from 0.00114 to 0.00114, saving model to model_part2.hdf5

Epoch 01159: loss improved from 0.00114 to 0.00113, saving model to model_part2.hdf5

Epoch 01160: loss improved from 0.00113 to 0.00113, saving model to model_part2.hdf5

Epoch 01161: loss improved from 0.00113 to 0.00112, saving model to model_part2.hdf5

Epoch 01162: loss improved from 0.00112 to 0.00111, saving model to model_part2.hdf5

Epoch 01163: loss improved from 0.00111 to 0.00111, saving model to model_part2.hdf5

Epoch 01164: loss improved from 0.00111 to 0.00110, saving model to model_part2.hdf5

Epoch 01165: loss improved from 0.00110 to 0.00109, saving model to model_part2.hdf5

Epoch 01166: loss improved from 0.00109 to 0.00109, saving model to model_part2.hdf5

Epoch 01167: loss improved from 0.00109 to 0.00108, saving model to model_part2.hdf5

Epoch 01168: loss improved from 0.00108 to 0.00107, saving model to model_part2.hdf5

Epoch 01169: loss improved from 0.00107 to 0.00107, saving model to model_part2.hdf5

Epoch 01170: loss improved from 0.00107 to 0.00106, saving model to model_part2.hdf5

Epoch 01171: loss improved from 0.00106 to 0.00106, saving model to model_part2.hdf5

Epoch 01172: loss improved from 0.00106 to 0.00105, saving model to model_part2.hdf5

Epoch 01173: loss improved from 0.00105 to 0.00104, saving model to model_part2.hdf5

Epoch 01174: loss improved from 0.00104 to 0.00104, saving model to model_part2.hdf5

Epoch 01175: loss improved from 0.00104 to 0.00103, saving model to model_part2.hdf5

Epoch 01176: loss improved from 0.00103 to 0.00102, saving model to model_part2.hdf5

Epoch 01177: loss improved from 0.00102 to 0.00102, saving model to model_part2.hdf5

Epoch 01178: loss improved from 0.00102 to 0.00101, saving model to model_part2.hdf5

Epoch 01179: loss improved from 0.00101 to 0.00101, saving model to model_part2.hdf5

Epoch 01180: loss improved from 0.00101 to 0.00100, saving model to model_part2.hdf5

Epoch 01181: loss improved from 0.00100 to 0.00100, saving model to model_part2.hdf5

Epoch 01182: loss improved from 0.00100 to 0.00099, saving model to model_part2.hdf5

Epoch 01183: loss improved from 0.00099 to 0.00098, saving model to model_part2.hdf5

Epoch 01184: loss improved from 0.00098 to 0.00098, saving model to model_part2.hdf5

Epoch 01185: loss improved from 0.00098 to 0.00097, saving model to model_part2.hdf5

Epoch 01186: loss improved from 0.00097 to 0.00097, saving model to model_part2.hdf5

Epoch 01187: loss improved from 0.00097 to 0.00096, saving model to model_part2.hdf5

Epoch 01188: loss improved from 0.00096 to 0.00096, saving model to model_part2.hdf5

Epoch 01189: loss improved from 0.00096 to 0.00095, saving model to model_part2.hdf5

Epoch 01190: loss improved from 0.00095 to 0.00095, saving model to model_part2.hdf5

Epoch 01191: loss improved from 0.00095 to 0.00094, saving model to model_part2.hdf5

Epoch 01192: loss improved from 0.00094 to 0.00093, saving model to model_part2.hdf5

Epoch 01193: loss improved from 0.00093 to 0.00093, saving model to model_part2.hdf5

Epoch 01194: loss improved from 0.00093 to 0.00092, saving model to model_part2.hdf5

Epoch 01195: loss improved from 0.00092 to 0.00092, saving model to model_part2.hdf5

Epoch 01196: loss improved from 0.00092 to 0.00091, saving model to model_part2.hdf5

Epoch 01197: loss improved from 0.00091 to 0.00091, saving model to model_part2.hdf5

Epoch 01198: loss improved from 0.00091 to 0.00090, saving model to model_part2.hdf5

Epoch 01199: loss improved from 0.00090 to 0.00090, saving model to model_part2.hdf5

Epoch 01200: loss improved from 0.00090 to 0.00089, saving model to model_part2.hdf5

Epoch 01201: loss improved from 0.00089 to 0.00089, saving model to model_part2.hdf5

Epoch 01202: loss improved from 0.00089 to 0.00088, saving model to model_part2.hdf5

Epoch 01203: loss improved from 0.00088 to 0.00088, saving model to model_part2.hdf5

Epoch 01204: loss improved from 0.00088 to 0.00087, saving model to model_part2.hdf5

Epoch 01205: loss improved from 0.00087 to 0.00087, saving model to model_part2.hdf5

Epoch 01206: loss improved from 0.00087 to 0.00086, saving model to model_part2.hdf5

Epoch 01207: loss improved from 0.00086 to 0.00086, saving model to model_part2.hdf5

Epoch 01208: loss improved from 0.00086 to 0.00085, saving model to model_part2.hdf5

Epoch 01209: loss improved from 0.00085 to 0.00085, saving model to model_part2.hdf5

Epoch 01210: loss improved from 0.00085 to 0.00084, saving model to model_part2.hdf5

Epoch 01211: loss improved from 0.00084 to 0.00084, saving model to model_part2.hdf5

Epoch 01212: loss improved from 0.00084 to 0.00083, saving model to model_part2.hdf5

Epoch 01213: loss improved from 0.00083 to 0.00083, saving model to model_part2.hdf5

Epoch 01214: loss improved from 0.00083 to 0.00082, saving model to model_part2.hdf5

Epoch 01215: loss improved from 0.00082 to 0.00082, saving model to model_part2.hdf5

Epoch 01216: loss improved from 0.00082 to 0.00081, saving model to model_part2.hdf5

Epoch 01217: loss improved from 0.00081 to 0.00081, saving model to model_part2.hdf5

Epoch 01218: loss improved from 0.00081 to 0.00080, saving model to model_part2.hdf5

Epoch 01219: loss improved from 0.00080 to 0.00080, saving model to model_part2.hdf5

Epoch 01220: loss improved from 0.00080 to 0.00079, saving model to model_part2.hdf5

Epoch 01221: loss improved from 0.00079 to 0.00079, saving model to model_part2.hdf5

Epoch 01222: loss improved from 0.00079 to 0.00078, saving model to model_part2.hdf5

Epoch 01223: loss improved from 0.00078 to 0.00078, saving model to model_part2.hdf5

Epoch 01224: loss improved from 0.00078 to 0.00078, saving model to model_part2.hdf5

Epoch 01225: loss improved from 0.00078 to 0.00077, saving model to model_part2.hdf5

Epoch 01226: loss improved from 0.00077 to 0.00077, saving model to model_part2.hdf5

Epoch 01227: loss improved from 0.00077 to 0.00076, saving model to model_part2.hdf5

Epoch 01228: loss improved from 0.00076 to 0.00076, saving model to model_part2.hdf5

Epoch 01229: loss improved from 0.00076 to 0.00075, saving model to model_part2.hdf5

Epoch 01230: loss improved from 0.00075 to 0.00075, saving model to model_part2.hdf5

Epoch 01231: loss improved from 0.00075 to 0.00074, saving model to model_part2.hdf5

Epoch 01232: loss improved from 0.00074 to 0.00074, saving model to model_part2.hdf5

Epoch 01233: loss improved from 0.00074 to 0.00074, saving model to model_part2.hdf5

Epoch 01234: loss improved from 0.00074 to 0.00073, saving model to model_part2.hdf5

Epoch 01235: loss improved from 0.00073 to 0.00073, saving model to model_part2.hdf5

Epoch 01236: loss improved from 0.00073 to 0.00072, saving model to model_part2.hdf5

Epoch 01237: loss improved from 0.00072 to 0.00072, saving model to model_part2.hdf5

Epoch 01238: loss improved from 0.00072 to 0.00072, saving model to model_part2.hdf5

Epoch 01239: loss improved from 0.00072 to 0.00071, saving model to model_part2.hdf5

Epoch 01240: loss improved from 0.00071 to 0.00071, saving model to model_part2.hdf5

Epoch 01241: loss improved from 0.00071 to 0.00070, saving model to model_part2.hdf5

Epoch 01242: loss improved from 0.00070 to 0.00070, saving model to model_part2.hdf5

Epoch 01243: loss improved from 0.00070 to 0.00070, saving model to model_part2.hdf5

Epoch 01244: loss improved from 0.00070 to 0.00069, saving model to model_part2.hdf5

Epoch 01245: loss improved from 0.00069 to 0.00069, saving model to model_part2.hdf5

Epoch 01246: loss improved from 0.00069 to 0.00068, saving model to model_part2.hdf5

Epoch 01247: loss improved from 0.00068 to 0.00068, saving model to model_part2.hdf5

Epoch 01248: loss improved from 0.00068 to 0.00068, saving model to model_part2.hdf5

Epoch 01249: loss improved from 0.00068 to 0.00067, saving model to model_part2.hdf5

Epoch 01250: loss improved from 0.00067 to 0.00067, saving model to model_part2.hdf5

Epoch 01251: loss improved from 0.00067 to 0.00066, saving model to model_part2.hdf5

Epoch 01252: loss improved from 0.00066 to 0.00066, saving model to model_part2.hdf5

Epoch 01253: loss improved from 0.00066 to 0.00066, saving model to model_part2.hdf5

Epoch 01254: loss improved from 0.00066 to 0.00065, saving model to model_part2.hdf5

Epoch 01255: loss improved from 0.00065 to 0.00065, saving model to model_part2.hdf5

Epoch 01256: loss improved from 0.00065 to 0.00064, saving model to model_part2.hdf5

Epoch 01257: loss improved from 0.00064 to 0.00064, saving model to model_part2.hdf5

Epoch 01258: loss improved from 0.00064 to 0.00064, saving model to model_part2.hdf5

Epoch 01259: loss improved from 0.00064 to 0.00063, saving model to model_part2.hdf5

Epoch 01260: loss improved from 0.00063 to 0.00063, saving model to model_part2.hdf5

Epoch 01261: loss improved from 0.00063 to 0.00063, saving model to model_part2.hdf5

Epoch 01262: loss improved from 0.00063 to 0.00062, saving model to model_part2.hdf5

Epoch 01263: loss improved from 0.00062 to 0.00062, saving model to model_part2.hdf5

Epoch 01264: loss improved from 0.00062 to 0.00062, saving model to model_part2.hdf5

Epoch 01265: loss improved from 0.00062 to 0.00061, saving model to model_part2.hdf5

Epoch 01266: loss improved from 0.00061 to 0.00061, saving model to model_part2.hdf5

Epoch 01267: loss improved from 0.00061 to 0.00060, saving model to model_part2.hdf5

Epoch 01268: loss improved from 0.00060 to 0.00060, saving model to model_part2.hdf5

Epoch 01269: loss improved from 0.00060 to 0.00060, saving model to model_part2.hdf5

Epoch 01270: loss improved from 0.00060 to 0.00059, saving model to model_part2.hdf5

Epoch 01271: loss improved from 0.00059 to 0.00059, saving model to model_part2.hdf5

Epoch 01272: loss improved from 0.00059 to 0.00059, saving model to model_part2.hdf5

Epoch 01273: loss improved from 0.00059 to 0.00058, saving model to model_part2.hdf5

Epoch 01274: loss improved from 0.00058 to 0.00058, saving model to model_part2.hdf5

Epoch 01275: loss improved from 0.00058 to 0.00058, saving model to model_part2.hdf5

Epoch 01276: loss improved from 0.00058 to 0.00057, saving model to model_part2.hdf5

Epoch 01277: loss improved from 0.00057 to 0.00057, saving model to model_part2.hdf5

Epoch 01278: loss improved from 0.00057 to 0.00057, saving model to model_part2.hdf5

Epoch 01279: loss improved from 0.00057 to 0.00056, saving model to model_part2.hdf5

Epoch 01280: loss improved from 0.00056 to 0.00056, saving model to model_part2.hdf5

Epoch 01281: loss improved from 0.00056 to 0.00056, saving model to model_part2.hdf5

Epoch 01282: loss improved from 0.00056 to 0.00055, saving model to model_part2.hdf5

Epoch 01283: loss improved from 0.00055 to 0.00055, saving model to model_part2.hdf5

Epoch 01284: loss improved from 0.00055 to 0.00055, saving model to model_part2.hdf5

Epoch 01285: loss improved from 0.00055 to 0.00054, saving model to model_part2.hdf5

Epoch 01286: loss improved from 0.00054 to 0.00054, saving model to model_part2.hdf5

Epoch 01287: loss improved from 0.00054 to 0.00054, saving model to model_part2.hdf5

Epoch 01288: loss improved from 0.00054 to 0.00053, saving model to model_part2.hdf5

Epoch 01289: loss improved from 0.00053 to 0.00053, saving model to model_part2.hdf5

Epoch 01290: loss improved from 0.00053 to 0.00053, saving model to model_part2.hdf5

Epoch 01291: loss improved from 0.00053 to 0.00053, saving model to model_part2.hdf5

Epoch 01292: loss improved from 0.00053 to 0.00052, saving model to model_part2.hdf5

Epoch 01293: loss improved from 0.00052 to 0.00052, saving model to model_part2.hdf5

Epoch 01294: loss improved from 0.00052 to 0.00052, saving model to model_part2.hdf5

Epoch 01295: loss improved from 0.00052 to 0.00051, saving model to model_part2.hdf5

Epoch 01296: loss improved from 0.00051 to 0.00051, saving model to model_part2.hdf5

Epoch 01297: loss improved from 0.00051 to 0.00051, saving model to model_part2.hdf5

Epoch 01298: loss improved from 0.00051 to 0.00050, saving model to model_part2.hdf5

Epoch 01299: loss improved from 0.00050 to 0.00050, saving model to model_part2.hdf5

Epoch 01300: loss improved from 0.00050 to 0.00050, saving model to model_part2.hdf5

Epoch 01301: loss improved from 0.00050 to 0.00050, saving model to model_part2.hdf5

Epoch 01302: loss improved from 0.00050 to 0.00049, saving model to model_part2.hdf5

Epoch 01303: loss improved from 0.00049 to 0.00049, saving model to model_part2.hdf5

Epoch 01304: loss improved from 0.00049 to 0.00049, saving model to model_part2.hdf5

Epoch 01305: loss improved from 0.00049 to 0.00048, saving model to model_part2.hdf5

Epoch 01306: loss improved from 0.00048 to 0.00048, saving model to model_part2.hdf5

Epoch 01307: loss improved from 0.00048 to 0.00048, saving model to model_part2.hdf5

Epoch 01308: loss improved from 0.00048 to 0.00048, saving model to model_part2.hdf5

Epoch 01309: loss improved from 0.00048 to 0.00047, saving model to model_part2.hdf5

Epoch 01310: loss improved from 0.00047 to 0.00047, saving model to model_part2.hdf5

Epoch 01311: loss improved from 0.00047 to 0.00047, saving model to model_part2.hdf5

Epoch 01312: loss improved from 0.00047 to 0.00047, saving model to model_part2.hdf5

Epoch 01313: loss improved from 0.00047 to 0.00046, saving model to model_part2.hdf5

Epoch 01314: loss improved from 0.00046 to 0.00046, saving model to model_part2.hdf5

Epoch 01315: loss improved from 0.00046 to 0.00046, saving model to model_part2.hdf5

Epoch 01316: loss improved from 0.00046 to 0.00046, saving model to model_part2.hdf5

Epoch 01317: loss improved from 0.00046 to 0.00045, saving model to model_part2.hdf5

Epoch 01318: loss improved from 0.00045 to 0.00045, saving model to model_part2.hdf5

Epoch 01319: loss improved from 0.00045 to 0.00045, saving model to model_part2.hdf5

Epoch 01320: loss improved from 0.00045 to 0.00044, saving model to model_part2.hdf5

Epoch 01321: loss improved from 0.00044 to 0.00044, saving model to model_part2.hdf5

Epoch 01322: loss improved from 0.00044 to 0.00044, saving model to model_part2.hdf5

Epoch 01323: loss improved from 0.00044 to 0.00044, saving model to model_part2.hdf5

Epoch 01324: loss improved from 0.00044 to 0.00043, saving model to model_part2.hdf5

Epoch 01325: loss improved from 0.00043 to 0.00043, saving model to model_part2.hdf5

Epoch 01326: loss improved from 0.00043 to 0.00043, saving model to model_part2.hdf5

Epoch 01327: loss improved from 0.00043 to 0.00043, saving model to model_part2.hdf5

Epoch 01328: loss improved from 0.00043 to 0.00042, saving model to model_part2.hdf5

Epoch 01329: loss improved from 0.00042 to 0.00042, saving model to model_part2.hdf5

Epoch 01330: loss improved from 0.00042 to 0.00042, saving model to model_part2.hdf5

Epoch 01331: loss improved from 0.00042 to 0.00042, saving model to model_part2.hdf5

Epoch 01332: loss improved from 0.00042 to 0.00041, saving model to model_part2.hdf5

Epoch 01333: loss improved from 0.00041 to 0.00041, saving model to model_part2.hdf5

Epoch 01334: loss improved from 0.00041 to 0.00041, saving model to model_part2.hdf5

Epoch 01335: loss improved from 0.00041 to 0.00041, saving model to model_part2.hdf5

Epoch 01336: loss improved from 0.00041 to 0.00041, saving model to model_part2.hdf5

Epoch 01337: loss improved from 0.00041 to 0.00040, saving model to model_part2.hdf5

Epoch 01338: loss improved from 0.00040 to 0.00040, saving model to model_part2.hdf5

Epoch 01339: loss improved from 0.00040 to 0.00040, saving model to model_part2.hdf5

Epoch 01340: loss improved from 0.00040 to 0.00040, saving model to model_part2.hdf5

Epoch 01341: loss improved from 0.00040 to 0.00039, saving model to model_part2.hdf5

Epoch 01342: loss improved from 0.00039 to 0.00039, saving model to model_part2.hdf5

Epoch 01343: loss improved from 0.00039 to 0.00039, saving model to model_part2.hdf5

Epoch 01344: loss improved from 0.00039 to 0.00039, saving model to model_part2.hdf5

Epoch 01345: loss improved from 0.00039 to 0.00038, saving model to model_part2.hdf5

Epoch 01346: loss improved from 0.00038 to 0.00038, saving model to model_part2.hdf5

Epoch 01347: loss improved from 0.00038 to 0.00038, saving model to model_part2.hdf5

Epoch 01348: loss improved from 0.00038 to 0.00038, saving model to model_part2.hdf5

Epoch 01349: loss improved from 0.00038 to 0.00038, saving model to model_part2.hdf5

Epoch 01350: loss improved from 0.00038 to 0.00037, saving model to model_part2.hdf5

Epoch 01351: loss improved from 0.00037 to 0.00037, saving model to model_part2.hdf5

Epoch 01352: loss improved from 0.00037 to 0.00037, saving model to model_part2.hdf5

Epoch 01353: loss improved from 0.00037 to 0.00037, saving model to model_part2.hdf5

Epoch 01354: loss improved from 0.00037 to 0.00036, saving model to model_part2.hdf5

Epoch 01355: loss improved from 0.00036 to 0.00036, saving model to model_part2.hdf5

Epoch 01356: loss improved from 0.00036 to 0.00036, saving model to model_part2.hdf5

Epoch 01357: loss improved from 0.00036 to 0.00036, saving model to model_part2.hdf5

Epoch 01358: loss improved from 0.00036 to 0.00036, saving model to model_part2.hdf5

Epoch 01359: loss improved from 0.00036 to 0.00035, saving model to model_part2.hdf5

Epoch 01360: loss improved from 0.00035 to 0.00035, saving model to model_part2.hdf5

Epoch 01361: loss improved from 0.00035 to 0.00035, saving model to model_part2.hdf5

Epoch 01362: loss improved from 0.00035 to 0.00035, saving model to model_part2.hdf5

Epoch 01363: loss improved from 0.00035 to 0.00035, saving model to model_part2.hdf5

Epoch 01364: loss improved from 0.00035 to 0.00034, saving model to model_part2.hdf5

Epoch 01365: loss improved from 0.00034 to 0.00034, saving model to model_part2.hdf5

Epoch 01366: loss improved from 0.00034 to 0.00034, saving model to model_part2.hdf5

Epoch 01367: loss improved from 0.00034 to 0.00034, saving model to model_part2.hdf5

Epoch 01368: loss improved from 0.00034 to 0.00034, saving model to model_part2.hdf5

Epoch 01369: loss improved from 0.00034 to 0.00033, saving model to model_part2.hdf5

Epoch 01370: loss improved from 0.00033 to 0.00033, saving model to model_part2.hdf5

Epoch 01371: loss improved from 0.00033 to 0.00033, saving model to model_part2.hdf5

Epoch 01372: loss improved from 0.00033 to 0.00033, saving model to model_part2.hdf5

Epoch 01373: loss improved from 0.00033 to 0.00033, saving model to model_part2.hdf5

Epoch 01374: loss improved from 0.00033 to 0.00032, saving model to model_part2.hdf5

Epoch 01375: loss improved from 0.00032 to 0.00032, saving model to model_part2.hdf5

Epoch 01376: loss improved from 0.00032 to 0.00032, saving model to model_part2.hdf5

Epoch 01377: loss improved from 0.00032 to 0.00032, saving model to model_part2.hdf5

Epoch 01378: loss improved from 0.00032 to 0.00032, saving model to model_part2.hdf5

Epoch 01379: loss improved from 0.00032 to 0.00032, saving model to model_part2.hdf5

Epoch 01380: loss improved from 0.00032 to 0.00031, saving model to model_part2.hdf5

Epoch 01381: loss improved from 0.00031 to 0.00031, saving model to model_part2.hdf5

Epoch 01382: loss improved from 0.00031 to 0.00031, saving model to model_part2.hdf5

Epoch 01383: loss improved from 0.00031 to 0.00031, saving model to model_part2.hdf5

Epoch 01384: loss improved from 0.00031 to 0.00031, saving model to model_part2.hdf5

Epoch 01385: loss improved from 0.00031 to 0.00030, saving model to model_part2.hdf5

Epoch 01386: loss improved from 0.00030 to 0.00030, saving model to model_part2.hdf5

Epoch 01387: loss improved from 0.00030 to 0.00030, saving model to model_part2.hdf5

Epoch 01388: loss improved from 0.00030 to 0.00030, saving model to model_part2.hdf5

Epoch 01389: loss improved from 0.00030 to 0.00030, saving model to model_part2.hdf5

Epoch 01390: loss improved from 0.00030 to 0.00030, saving model to model_part2.hdf5

Epoch 01391: loss improved from 0.00030 to 0.00029, saving model to model_part2.hdf5

Epoch 01392: loss improved from 0.00029 to 0.00029, saving model to model_part2.hdf5

Epoch 01393: loss improved from 0.00029 to 0.00029, saving model to model_part2.hdf5

Epoch 01394: loss improved from 0.00029 to 0.00029, saving model to model_part2.hdf5

Epoch 01395: loss improved from 0.00029 to 0.00029, saving model to model_part2.hdf5

Epoch 01396: loss improved from 0.00029 to 0.00029, saving model to model_part2.hdf5

Epoch 01397: loss improved from 0.00029 to 0.00028, saving model to model_part2.hdf5

Epoch 01398: loss improved from 0.00028 to 0.00028, saving model to model_part2.hdf5

Epoch 01399: loss improved from 0.00028 to 0.00028, saving model to model_part2.hdf5

Epoch 01400: loss improved from 0.00028 to 0.00028, saving model to model_part2.hdf5

Epoch 01401: loss improved from 0.00028 to 0.00028, saving model to model_part2.hdf5

Epoch 01402: loss improved from 0.00028 to 0.00028, saving model to model_part2.hdf5

Epoch 01403: loss improved from 0.00028 to 0.00027, saving model to model_part2.hdf5

Epoch 01404: loss improved from 0.00027 to 0.00027, saving model to model_part2.hdf5

Epoch 01405: loss improved from 0.00027 to 0.00027, saving model to model_part2.hdf5

Epoch 01406: loss improved from 0.00027 to 0.00027, saving model to model_part2.hdf5

Epoch 01407: loss improved from 0.00027 to 0.00027, saving model to model_part2.hdf5

Epoch 01408: loss improved from 0.00027 to 0.00027, saving model to model_part2.hdf5

Epoch 01409: loss improved from 0.00027 to 0.00027, saving model to model_part2.hdf5

Epoch 01410: loss improved from 0.00027 to 0.00026, saving model to model_part2.hdf5

Epoch 01411: loss improved from 0.00026 to 0.00026, saving model to model_part2.hdf5

Epoch 01412: loss improved from 0.00026 to 0.00026, saving model to model_part2.hdf5

Epoch 01413: loss improved from 0.00026 to 0.00026, saving model to model_part2.hdf5

Epoch 01414: loss improved from 0.00026 to 0.00026, saving model to model_part2.hdf5

Epoch 01415: loss improved from 0.00026 to 0.00026, saving model to model_part2.hdf5

Epoch 01416: loss improved from 0.00026 to 0.00025, saving model to model_part2.hdf5

Epoch 01417: loss improved from 0.00025 to 0.00025, saving model to model_part2.hdf5

Epoch 01418: loss improved from 0.00025 to 0.00025, saving model to model_part2.hdf5

Epoch 01419: loss improved from 0.00025 to 0.00025, saving model to model_part2.hdf5

Epoch 01420: loss improved from 0.00025 to 0.00025, saving model to model_part2.hdf5

Epoch 01421: loss improved from 0.00025 to 0.00025, saving model to model_part2.hdf5

Epoch 01422: loss improved from 0.00025 to 0.00025, saving model to model_part2.hdf5

Epoch 01423: loss improved from 0.00025 to 0.00024, saving model to model_part2.hdf5

Epoch 01424: loss improved from 0.00024 to 0.00024, saving model to model_part2.hdf5

Epoch 01425: loss improved from 0.00024 to 0.00024, saving model to model_part2.hdf5

Epoch 01426: loss improved from 0.00024 to 0.00024, saving model to model_part2.hdf5

Epoch 01427: loss improved from 0.00024 to 0.00024, saving model to model_part2.hdf5

Epoch 01428: loss improved from 0.00024 to 0.00024, saving model to model_part2.hdf5

Epoch 01429: loss improved from 0.00024 to 0.00024, saving model to model_part2.hdf5

Epoch 01430: loss improved from 0.00024 to 0.00023, saving model to model_part2.hdf5

Epoch 01431: loss improved from 0.00023 to 0.00023, saving model to model_part2.hdf5

Epoch 01432: loss improved from 0.00023 to 0.00023, saving model to model_part2.hdf5

Epoch 01433: loss improved from 0.00023 to 0.00023, saving model to model_part2.hdf5

Epoch 01434: loss improved from 0.00023 to 0.00023, saving model to model_part2.hdf5

Epoch 01435: loss improved from 0.00023 to 0.00023, saving model to model_part2.hdf5

Epoch 01436: loss improved from 0.00023 to 0.00023, saving model to model_part2.hdf5

Epoch 01437: loss improved from 0.00023 to 0.00023, saving model to model_part2.hdf5

Epoch 01438: loss improved from 0.00023 to 0.00022, saving model to model_part2.hdf5

Epoch 01439: loss improved from 0.00022 to 0.00022, saving model to model_part2.hdf5

Epoch 01440: loss improved from 0.00022 to 0.00022, saving model to model_part2.hdf5

Epoch 01441: loss improved from 0.00022 to 0.00022, saving model to model_part2.hdf5

Epoch 01442: loss improved from 0.00022 to 0.00022, saving model to model_part2.hdf5

Epoch 01443: loss improved from 0.00022 to 0.00022, saving model to model_part2.hdf5

Epoch 01444: loss improved from 0.00022 to 0.00022, saving model to model_part2.hdf5

Epoch 01445: loss improved from 0.00022 to 0.00022, saving model to model_part2.hdf5

Epoch 01446: loss improved from 0.00022 to 0.00021, saving model to model_part2.hdf5

Epoch 01447: loss improved from 0.00021 to 0.00021, saving model to model_part2.hdf5

Epoch 01448: loss improved from 0.00021 to 0.00021, saving model to model_part2.hdf5

Epoch 01449: loss improved from 0.00021 to 0.00021, saving model to model_part2.hdf5

Epoch 01450: loss improved from 0.00021 to 0.00021, saving model to model_part2.hdf5

Epoch 01451: loss improved from 0.00021 to 0.00021, saving model to model_part2.hdf5

Epoch 01452: loss improved from 0.00021 to 0.00021, saving model to model_part2.hdf5

Epoch 01453: loss improved from 0.00021 to 0.00021, saving model to model_part2.hdf5

Epoch 01454: loss improved from 0.00021 to 0.00020, saving model to model_part2.hdf5

Epoch 01455: loss improved from 0.00020 to 0.00020, saving model to model_part2.hdf5

Epoch 01456: loss improved from 0.00020 to 0.00020, saving model to model_part2.hdf5

Epoch 01457: loss improved from 0.00020 to 0.00020, saving model to model_part2.hdf5

Epoch 01458: loss improved from 0.00020 to 0.00020, saving model to model_part2.hdf5

Epoch 01459: loss improved from 0.00020 to 0.00020, saving model to model_part2.hdf5

Epoch 01460: loss improved from 0.00020 to 0.00020, saving model to model_part2.hdf5

Epoch 01461: loss improved from 0.00020 to 0.00020, saving model to model_part2.hdf5

Epoch 01462: loss improved from 0.00020 to 0.00020, saving model to model_part2.hdf5

Epoch 01463: loss improved from 0.00020 to 0.00019, saving model to model_part2.hdf5

Epoch 01464: loss improved from 0.00019 to 0.00019, saving model to model_part2.hdf5

Epoch 01465: loss improved from 0.00019 to 0.00019, saving model to model_part2.hdf5

Epoch 01466: loss improved from 0.00019 to 0.00019, saving model to model_part2.hdf5

Epoch 01467: loss improved from 0.00019 to 0.00019, saving model to model_part2.hdf5

Epoch 01468: loss improved from 0.00019 to 0.00019, saving model to model_part2.hdf5

Epoch 01469: loss improved from 0.00019 to 0.00019, saving model to model_part2.hdf5

Epoch 01470: loss improved from 0.00019 to 0.00019, saving model to model_part2.hdf5

Epoch 01471: loss improved from 0.00019 to 0.00019, saving model to model_part2.hdf5

Epoch 01472: loss improved from 0.00019 to 0.00018, saving model to model_part2.hdf5

Epoch 01473: loss improved from 0.00018 to 0.00018, saving model to model_part2.hdf5

Epoch 01474: loss improved from 0.00018 to 0.00018, saving model to model_part2.hdf5

Epoch 01475: loss improved from 0.00018 to 0.00018, saving model to model_part2.hdf5

Epoch 01476: loss improved from 0.00018 to 0.00018, saving model to model_part2.hdf5

Epoch 01477: loss improved from 0.00018 to 0.00018, saving model to model_part2.hdf5

Epoch 01478: loss improved from 0.00018 to 0.00018, saving model to model_part2.hdf5

Epoch 01479: loss improved from 0.00018 to 0.00018, saving model to model_part2.hdf5

Epoch 01480: loss improved from 0.00018 to 0.00018, saving model to model_part2.hdf5

Epoch 01481: loss improved from 0.00018 to 0.00017, saving model to model_part2.hdf5

Epoch 01482: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01483: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01484: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01485: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01486: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01487: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01488: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01489: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01490: loss improved from 0.00017 to 0.00017, saving model to model_part2.hdf5

Epoch 01491: loss improved from 0.00017 to 0.00016, saving model to model_part2.hdf5

Epoch 01492: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01493: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01494: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01495: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01496: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01497: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01498: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01499: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01500: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01501: loss improved from 0.00016 to 0.00016, saving model to model_part2.hdf5

Epoch 01502: loss improved from 0.00016 to 0.00015, saving model to model_part2.hdf5

Epoch 01503: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01504: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01505: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01506: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01507: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01508: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01509: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01510: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01511: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01512: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01513: loss improved from 0.00015 to 0.00015, saving model to model_part2.hdf5

Epoch 01514: loss improved from 0.00015 to 0.00014, saving model to model_part2.hdf5

Epoch 01515: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01516: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01517: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01518: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01519: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01520: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01521: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01522: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01523: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01524: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01525: loss improved from 0.00014 to 0.00014, saving model to model_part2.hdf5

Epoch 01526: loss improved from 0.00014 to 0.00013, saving model to model_part2.hdf5

Epoch 01527: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01528: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01529: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01530: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01531: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01532: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01533: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01534: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01535: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01536: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01537: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01538: loss improved from 0.00013 to 0.00013, saving model to model_part2.hdf5

Epoch 01539: loss improved from 0.00013 to 0.00012, saving model to model_part2.hdf5

Epoch 01540: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01541: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01542: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01543: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01544: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01545: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01546: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01547: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01548: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01549: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01550: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01551: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01552: loss improved from 0.00012 to 0.00012, saving model to model_part2.hdf5

Epoch 01553: loss improved from 0.00012 to 0.00011, saving model to model_part2.hdf5

Epoch 01554: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01555: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01556: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01557: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01558: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01559: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01560: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01561: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01562: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01563: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01564: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01565: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01566: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01567: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01568: loss improved from 0.00011 to 0.00011, saving model to model_part2.hdf5

Epoch 01569: loss improved from 0.00011 to 0.00010, saving model to model_part2.hdf5

Epoch 01570: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01571: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01572: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01573: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01574: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01575: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01576: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01577: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01578: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01579: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01580: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01581: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01582: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01583: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01584: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01585: loss improved from 0.00010 to 0.00010, saving model to model_part2.hdf5

Epoch 01586: loss improved from 0.00010 to 0.00009, saving model to model_part2.hdf5

Epoch 01587: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01588: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01589: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01590: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01591: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01592: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01593: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01594: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01595: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01596: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01597: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01598: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01599: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01600: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01601: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01602: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01603: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01604: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01605: loss improved from 0.00009 to 0.00009, saving model to model_part2.hdf5

Epoch 01606: loss improved from 0.00009 to 0.00008, saving model to model_part2.hdf5

Epoch 01607: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01608: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01609: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01610: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01611: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01612: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01613: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01614: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01615: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01616: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01617: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01618: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01619: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01620: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01621: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01622: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01623: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01624: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01625: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01626: loss improved from 0.00008 to 0.00008, saving model to model_part2.hdf5

Epoch 01627: loss improved from 0.00008 to 0.00007, saving model to model_part2.hdf5

Epoch 01628: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01629: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01630: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01631: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01632: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01633: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01634: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01635: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01636: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01637: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01638: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01639: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01640: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01641: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01642: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01643: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01644: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01645: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01646: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01647: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01648: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01649: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01650: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01651: loss improved from 0.00007 to 0.00007, saving model to model_part2.hdf5

Epoch 01652: loss improved from 0.00007 to 0.00006, saving model to model_part2.hdf5

Epoch 01653: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01654: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01655: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01656: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01657: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01658: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01659: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01660: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01661: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01662: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01663: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01664: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01665: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01666: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01667: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01668: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01669: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01670: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01671: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01672: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01673: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01674: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01675: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01676: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01677: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01678: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01679: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01680: loss improved from 0.00006 to 0.00006, saving model to model_part2.hdf5

Epoch 01681: loss improved from 0.00006 to 0.00005, saving model to model_part2.hdf5

Epoch 01682: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01683: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01684: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01685: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01686: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01687: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01688: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01689: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01690: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01691: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01692: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01693: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01694: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01695: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01696: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01697: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01698: loss did not improve from 0.00005

Epoch 01699: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01700: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01701: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01702: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01703: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01704: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01705: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01706: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01707: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01708: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01709: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01710: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01711: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01712: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01713: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01714: loss improved from 0.00005 to 0.00005, saving model to model_part2.hdf5

Epoch 01715: loss improved from 0.00005 to 0.00004, saving model to model_part2.hdf5

Epoch 01716: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01717: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01718: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01719: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01720: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01721: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01722: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01723: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01724: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01725: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01726: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01727: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01728: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01729: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01730: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01731: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01732: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01733: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01734: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01735: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01736: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01737: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01738: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01739: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01740: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01741: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01742: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01743: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01744: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01745: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01746: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01747: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01748: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01749: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01750: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01751: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01752: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01753: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01754: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01755: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01756: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01757: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01758: loss improved from 0.00004 to 0.00004, saving model to model_part2.hdf5

Epoch 01759: loss improved from 0.00004 to 0.00003, saving model to model_part2.hdf5

Epoch 01760: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01761: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01762: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01763: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01764: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01765: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01766: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01767: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01768: loss did not improve from 0.00003

Epoch 01769: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01770: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01771: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01772: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01773: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01774: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01775: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01776: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01777: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01778: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01779: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01780: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01781: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01782: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01783: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01784: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01785: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01786: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01787: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01788: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01789: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01790: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01791: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01792: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01793: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01794: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01795: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01796: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01797: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01798: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01799: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01800: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01801: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01802: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01803: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01804: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01805: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01806: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01807: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01808: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01809: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01810: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01811: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01812: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01813: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01814: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01815: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01816: loss improved from 0.00003 to 0.00003, saving model to model_part2.hdf5

Epoch 01817: loss improved from 0.00003 to 0.00002, saving model to model_part2.hdf5

Epoch 01818: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01819: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01820: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01821: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01822: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01823: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01824: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01825: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01826: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01827: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01828: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01829: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01830: loss did not improve from 0.00002

Epoch 01831: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01832: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01833: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01834: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01835: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01836: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01837: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01838: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01839: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01840: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01841: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01842: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01843: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01844: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01845: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01846: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01847: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01848: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01849: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01850: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01851: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01852: loss did not improve from 0.00002

Epoch 01853: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01854: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01855: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01856: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01857: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01858: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01859: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01860: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01861: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01862: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01863: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01864: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01865: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01866: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01867: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01868: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01869: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01870: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01871: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01872: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01873: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01874: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01875: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01876: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01877: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01878: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01879: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01880: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01881: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01882: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01883: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01884: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01885: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01886: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01887: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01888: loss did not improve from 0.00002

Epoch 01889: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01890: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01891: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01892: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01893: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01894: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01895: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01896: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01897: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01898: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01899: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01900: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01901: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01902: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01903: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01904: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01905: loss improved from 0.00002 to 0.00002, saving model to model_part2.hdf5

Epoch 01906: loss improved from 0.00002 to 0.00001, saving model to model_part2.hdf5

Epoch 01907: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01908: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01909: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01910: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01911: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01912: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01913: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01914: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01915: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01916: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01917: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01918: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01919: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01920: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01921: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01922: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01923: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01924: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01925: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01926: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01927: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01928: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01929: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01930: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01931: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01932: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01933: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01934: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01935: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01936: loss did not improve from 0.00001

Epoch 01937: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01938: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01939: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01940: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01941: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01942: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01943: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01944: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01945: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01946: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01947: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01948: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01949: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01950: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01951: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01952: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01953: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01954: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01955: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01956: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01957: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01958: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01959: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01960: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01961: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01962: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01963: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01964: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01965: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01966: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01967: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01968: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01969: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01970: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01971: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01972: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01973: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01974: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01975: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01976: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01977: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01978: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01979: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01980: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01981: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01982: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01983: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01984: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01985: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01986: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01987: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01988: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01989: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01990: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01991: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01992: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01993: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01994: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01995: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01996: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01997: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01998: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 01999: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5

Epoch 02000: loss improved from 0.00001 to 0.00001, saving model to model_part2.hdf5
Testing the model
45/45 [==============================] - 0s 2ms/step
====================================================

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Percent Training Size&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Percent Features vs Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhU5fXA8e/JRhLIAiRsSdjX4AISFsGyuALiVhWlWrVVqWtraxfrVkWt1l9r7YK21lqXtiLaakUR3IIooBAEBEICYQ9bEgKEPdv5/XFvdIwDmZDcmUlyPs8zD3fuenIT5sx973vPK6qKMcYYU1tEqAMwxhgTnixBGGOM8csShDHGGL8sQRhjjPHLEoQxxhi/LEEYY4zxyxKEMcYYvyxBGERkk4gcFpEDIrJLRP4hIm1CHZcvN8azj7N8rIhUuz9DzWtWIxz3eRF5uKH7CTci0sM9X0+FOhYTvixBmBoXqGob4DRgKHBvfXcgIlGNHlX9bFfVNj6vC0IcTzick2O5BtgDXCkirYJ54DA+J6YWSxDma1R1G/AOcBKAiCSJyN9FZIeIbBORh0Uk0l12nYgsEJHfi0gp8IA7/0YRWSMi+0UkV0ROc+d3EZH/iEixiGwUkR/WHFdEHhCRmSLyorvdahHJcpe9BHQFZrlXBj+vz88kIhEicpeIrBeR3e5x2vksf1VEdorIPhGZLyID3flTgauAn/tekYiIikhvn+2/vMpwr2QKReQXIrIT+Ic7f5KILBeRvSKyUERO8dn+F+653S8i+SJylp+fYYQbY6TPvEtE5At3epiI5IhImXsV+EQdp+UanC8BFcDXEqmIDBSR90Sk1N3X3e78SBG52z2P+0VkqYhkiEh395xE+exjnojc4E5/4+9ERHqJyIfu76NERP4lIsk+22eIyH/dv5XdIvJnEWnlxnSyz3odxLn6Ta3j5zUnwBKE+RoRyQAmAsvcWS8AlUBvYDBwLnCDzybDgQ1AB+AREbkcJ1FcAyQCFwK7RSQCmAWsANKAs4A7ROQ8n31dCMwAkoE3gT8DqOp3gS24Vzmq+ng9f6wfAhcDY4AuON+cp/ssfwfo4/4MnwP/co/7jDv9eD2vSDoB7YBuwFQ3QT4H/ABoD/wVeNP9wOsH3AYMVdUE4DxgU+0dquqnwEHgTJ/Z3wH+7U7/AfiDqiYCvYCZxwpORL4FpOOc65k4v6uaZQnA+8AcnHPVG/jAXfwTYArO30ci8H3gUCAnhFp/J4AAj7rHGABk8NUXjEjgLWAz0B3n72WGqh51Y77aZ79TgPdVtTjAOEx9qKq9WvgL5wPpALAX5z/lU0Ac0BE4CsT5rDsFyHanrwO21NrXXOBHfo4x3M+6vwT+4U4/gPMfvWZZJnC4VoxnH+dnGAtUuz9DzWuyu2wNcJbPup1xvjlH+dlPMqBAkvv+eeDhWuso0Nvn/ZfruHGUA7E+y58GHqq1j3ychNUbKALOBqLr+D09DDznTifgJIxu7vv5wINASgC/72eBN9zp091z0cHn97vsGNvlAxf5md/dPSdRPvPmATcc6+/Ezz4urjmuG1PxMX4/w4GtQIT7Pqfm92yvxn/ZFYSpcbGqJqtqN1W9RVUP43wDjgZ2uE0je3G+/Xbw2W5rrf1kAOv97L8b0KVmP+6+7sZJQjV2+kwfAmLr2V693f0Zal4136K7Aa/7HHcNUAV0dJtNHnObTcr46tt7Sj2OW1uxqh7xed8NuLPWz54BdFHVAuAOnARZJCIzRKTLMfb7b+Db4twz+DbwuapudpddD/QF8kRkiYhM8rcDEYkDLuerq6RFOFdn33FXOdbvr65ldfna34nbNDTDbVorA/7JV+c8A9isqpW1d6Kqn+EkxjEi0h8nwb55gjGZOliCMMezFecKIsXnQzdRVQf6rFO7HPBWnCYOf/vaWOsDPEFVJwYYS0PKDm8FJtQ6dqw691u+A1yE8w0+CefbMDhNIMc67iEg3ud9pzpi3Qo8Uuv48ar6MoCq/ltVz8BJJAr8xt8Poaq5OFd4E/h68xKquk5Vp+Ak798Ar4lIaz+7uQSneegp957GTpwmnJpmpmP9/o637KD7b33OyaPuvFPUaRa7mq/O+Vag63G+HLzgrv9d4LVaydg0IksQ5phUdQfwLvA7EUl0b/b2EpExx9nsWeCnIjJEHL1FpBuwGChzb8jGud/cTxKRoQGGswvoeYI/yl9w7o90AxCRVBG5yF2WgJMEd+N8wP06gOMuB77j/gzjcZqKjudvwE0iMtw9J61F5HwRSRCRfiJypntVcAQ4jHN1cyz/xrmnMhp4tWamiFwtIqmqWtPMxjH2cy3O/ZCTgUHuaxQwyL35+xbQSUTucO+RJIjIcHfbZ4GHRKSP+3OcIiLt1Wn/3wZc7Z6T73PsJFMjAbdZU0TSgJ/5LFsM7AAec89VrIiM8ln+Ek6iuxp4sY7jmAawBGHqcg0QA+Ti3Nx9DacN3y9VfRXnJuS/gf3AG0A7Va3C6S0zCNgIlOB84CQFGMejwL1uE81P6/kz/AGnGeJdEdkPfIrTlg3OB8xmnA+4XHeZr78Dme5x33Dn/cj9Wfbi9HJ6g+NQ1RzgRpyb7nuAApx2eYBWwGM452MnzhXA3cfZ3cs49zk+VNUSn/njgdUicsD9ea+s/c3a/SA+C3hSVXf6vJbi3JS+VlX3A+e4P99OYB0wzt3FEzg3td8FytxzE+cuuxHnQ343MBBYeLxzgnO/5DRgH/A28N+aBT5/K71xmr8KgSt8lhfidCZQ4OM6jmMaQFRtwCBjTNMiIs/h3HOq9/M6JnD2wIoxpkkRke44N+kHhzaS5s+amIwxTYaIPASsAv5PVTeGOp7mzpqYjDHG+GVXEMYYY/xqNvcgUlJStHv37qEOwxhjmpSlS5eWqKrfWlbNJkF0796dnJycUIdhjDFNiohsPtYya2IyxhjjlyUIY4wxflmCMMYY45clCGOMMX5ZgjDGGOOXJQhjjDF+WYIwxhjjlyUIY4wJwId5u1i1bV+owwgqSxDGGFOHvJ1l3PBCDt9+eiFvfbE91OEEjSUIY4w5DlVl2qxcEmKjOSUtidv+vYyn562nJRQ6tQRhjDHH8W7uLhau382Pz+7DP28YzgWnduE3c/K4+/VVVFZVhzo8TzWbWkzGGNPYjlZW8cjba+jToQ1XjehGdGQEf7hiEF3bxTE9ez3b9h5m+ncGkxAbHepQPWFXEMYYcwzPfbKJLaWHuP+CTKIjnY/LiAjhZ+f157Fvn8yCghIu/8siduw7HOJIvWEJwhhj/CgqO8KfP1zH2QM68q0+36yGfeWwrvzjuqEU7jnMxdMXsHp78+vhZAnCGGP8eHxuPuVV1dxz/oBjrjO6byqv3Xw6ESJM/ssisvOLghih9yxBGGNMLSu27uW1pYV8f1QPeqS0Pu66/Tsl8sato+ie0pobXsjhX58dc3iFJscShDHG+FBVHpy1mpQ2Mdx2Zu+AtumYGMvMH5zOmL6p3PP6Kh59Zw3V1U2/G6wlCGOM8fHmiu18vmUvPz+vf716J7VuFcUz3x3C1SO68tePNnD7y8s4UlHlYaTes26uxhjjOlReyaOz8zg5LYnLhqTXe/uoyAgeuugkurVrza/fWcOOfYf52zVZtG/TyoNovWdXEMYY4/rLvPXsLDvCry7IJCJCTmgfIsKNo3vy1HdOY/X2Mr799EI2FB9o5EiDwxKEMcYAW0sP8df5G7jg1C5kdW/X4P1NOLkzL08dwYEjlXz76YUs3ljaCFEGlyUIY4wBHnsnDxG4a0L/RtvnaV3b8voto2jXOoarn/2M/y3f1mj7DgZPE4SIjBeRfBEpEJG7/CzvJiIfiMgXIjJPRNJ9ll0rIuvc17VexmmMadk+3bCbt1fu4KYxvUhLjmvUfXdtH89/bx7JoK7J/GjGcqZnFzSZQn+eJQgRiQSmAxOATGCKiGTWWu23wIuqegowDXjU3bYd8CtgODAM+JWItPUqVmNMy1VV7VRr7ZIUyw9G9/LkGMnxMbx0/TAuGtSF/5ubz13/WUlFEyj05+UVxDCgQFU3qGo5MAO4qNY6mcAH7nS2z/LzgPdUtVRV9wDvAeM9jNUY00LNzNlK7o4yfjlxAHExkZ4dp1VUJE9eMYgfntmbV3K28v3nl1B2pMKz4zUGLxNEGrDV532hO8/XCuBSd/oSIEFE2ge4LSIyVURyRCSnuLi40QI3xrQM+w5X8Nu5+Qzt3pZJp3T2/Hgiwk/O7cfjl53CovW7ufzpRWzbG76F/rxMEP76iNVuePspMEZElgFjgG1AZYDboqrPqGqWqmalpn6zmJYxxhzPnz5YR+mhcn51wUBETqxb64mYnJXB898bxva9h7lk+oKwHcrUywRRCGT4vE8HvjZWn6puV9Vvq+pg4B533r5AtjXGmIZYX3yA5xduYvKQDE5KSwr68c/ok8JrN48kOjKCyX9dxId5u4IeQ128TBBLgD4i0kNEYoArgTd9VxCRFBGpieGXwHPu9FzgXBFp696cPtedZ4wxjeKRt9cQGx3JT8/rF7IY+nVK4PVbRtIz1Sn099KiTSGLxR/PEoSqVgK34XywrwFmqupqEZkmIhe6q40F8kVkLdAReMTdthR4CCfJLAGmufOMMabBsvOL+DCviB+e1ZvUhNCWweiQGMsrU0/nzP4duO9/q3nk7dywKfQnTaU/bl2ysrI0Jycn1GEYY8JcRVU15z05H1WYe8doYqLC43nhqmrlobdyeX7hJsYP7MTvrxjkaa+qGiKyVFWz/C0LjzNjjDFB8uKizWwoPsi95w8Im+QAEBkhPHDhQO6blMnc3J1M+dunlBw4GtKYwufsGGOMx3YfOMqT76/lW31SOLN/h1CH49f1Z/Tg6auGkLezjEueWkBBUegK/VmCMMa0GE+8t5ZD5VXcPykzqN1a62v8SZ2YMfV0DpdXcenTC/l0w+6QxGEJwhjTIuRuL+PlxVv47ohu9OmYEOpw6jQoI5nXbxlFakIrvvv3z3hjWfAL/VmCMMY0e6rKtLdWkxQXzY/P7hvqcAKW0S6e/9w0kiHd2nLHK8v50wfrglrozxKEMabZm7NqJ59uKOUn5/YjKT7wYUTDQVJ8NC9+fzjfHpzG795by89e+4LyyuAU+rMhR40xzdqRiioemb2G/p0SmDI0o+4NwlBMVAS/m3wqXdvH8+T769ix7zBPXTWEpDhvk51dQRhjmrW/f7KRwj2HuX9SJlGRTfcjT0S44+y+/PbyU1m8sZTL/7KQwj2HPD1m0z1bxhhTh537jjA9u4DzBnZkZO+UUIfTKC4bks4L3xvGjn1HuOSphXxRuNezY1mCMMY0W4/PyaOySrlnYu2xypq2kb1T+O/NI4mJjOCKv37K+7neFPqzBGGMaZY+37KH/y7bxg3f6kHX9vGhDqfR9emYwOu3jqRvxzbMXb3Tk2PYTWpjTLNTXa08OCuXDgmtuGVc71CH45kOCbHMmHo6kRHePPRnVxDGmGbn9WXbWLF1L78Y3582rZr39+C4mEjPakpZgjDGNCsHj1bymzl5nJqRzCWDvzFSsakHSxDGmGblqXkFFO0/yv2TMonwqOmlpbAEYYxpNrbsPsTfPt7IJYPTGNKtbajDafIsQRhjmo1fz15DpAi/GN8/1KE0C5YgjDHNwsL1JcxZvZNbx/WiU1JsqMNpFixBGGOavMqqaqbNyiUtOY4bvtUz1OE0G5YgjDFN3owlW8nbuZ97zh9AbLT34zi3FJ4mCBEZLyL5IlIgInf5Wd5VRLJFZJmIfCEiE9350SLygoisFJE1IvJLL+M0xjRd+w5V8Lt38xneox0TTuoU6nCaFc8ShIhEAtOBCUAmMEVEahdEuReYqaqDgSuBp9z5lwOtVPVkYAjwAxHp7lWsxpim68kP1rLvcAX3XxDew4g2RV5eQQwDClR1g6qWAzOAi2qto0CiO50EbPeZ31pEooA4oBwo8zBWY0wTVFC0nxcXbebKYV0Z2CUp1OE0O14miDRgq8/7QneerweAq0WkEJgN3O7Ofw04COwAtgC/VdXS2gcQkakikiMiOcXFxY0cvjEmnDnDiK4hPiaSO89pOsOINiVeJgh/13q1B1OdAjyvqunAROAlEYnAufqoAroAPYA7ReQbXRNU9RlVzVLVrNTU1MaN3hgT1rLzi5i/tpgfndWH9m1ahTqcZsnLBFEI+I7vl85XTUg1rgdmAqjqIiAWSAG+A8xR1QpVLQIWAFkexmqMaULKK6t56K019ExtzTWndw91OM2WlwliCdBHRHqISAzOTeg3a62zBTgLQEQG4CSIYnf+meJoDYwA8jyM1RjThLywcBMbSw5y36RMzyqZGg8ThKpWArcBc4E1OL2VVovINBG50F3tTuBGEVkBvAxcp6qK0/upDbAKJ9H8Q1W/8CpWY0zTUbz/KH/8YB3j+qUyrl+HUIfTrHlaKF1VZ+PcfPadd7/PdC4wys92B3C6uhpjzNf87t18DldUce+k5jWMaDiyazNjTJOxats+XsnZynUju9MrtU2ow2n2LEEYY5oEVWXarFzaxsdw+1l9Qh1Oi2AJwhjTJLy9cgeLN5Xy03P7kRQXHepwWgRLEMaYsHe4vIpHZ+cxoHMiVwzNqHsD0ygsQRhjwt4z8zewbe9hfnVBJpE2jGjQWIIwxoS17XsP8/RHBZx/cmdG9Gwf6nBaFEsQxpiw9ps5eajCXRNsGNFgswRhjAlbOZtK+d/y7Uwd3ZOMdvGhDqfFsQRhjAlL1dXKg7Ny6ZQYy81je4U6nBbJEoQxJiy99nkhK7ft464J/YmP8bTogzkGSxDGmLCz/0gFj8/J57SuyVw0qEuow2mxLC0bY8LO9Oz1lBw4yt+vzbJhREPIriCMMWFlU8lBnvtkI5cNSefUjORQh9Oi2RWEMS3UXz5az/qiA6EO4xtWbS8jOlL4+Xn9Qh1Ki2cJwpgWqHDPIR57J4+28dHERUeGOpyvEREeuHAgHRJjQx1Ki2cJwpgWaF5+MQCv3jSS3h2sbLbxz+5BGNMCzcsvIqNdHL1SW4c6FBPGLEEY08IcqahiQcFuxvXrYD2EzHFZgjCmhVm8sZTDFVU2nrOpkyUIY1qY7PwiWkVFWGVUUydLEMa0MB/lF3N6r/bExYRX7yUTfjxNECIyXkTyRaRARO7ys7yriGSLyDIR+UJEJvosO0VEFonIahFZKSLW582YBtpUcpANJQeteckExLNuriISCUwHzgEKgSUi8qaq5vqsdi8wU1WfFpFMYDbQXUSigH8C31XVFSLSHqjwKlZjWop5+UUAjO2XGuJITFPg5RXEMKBAVTeoajkwA7io1joKJLrTScB2d/pc4AtVXQGgqrtVtcrDWI1pEbLzi+mZ0ppu7a17q6mblwkiDdjq877QnefrAeBqESnEuXq43Z3fF1ARmSsin4vIz/0dQESmikiOiOQUFxc3bvTGNDOHy6tYtGE3Y615yQTIywThr4O11no/BXheVdOBicBLIhKB0/R1BnCV++8lInLWN3am+oyqZqlqVmqqXTIbczyLNpRQXlnNuP72f8UExssEUQhk+LxP56smpBrXAzMBVHUREAukuNt+pKolqnoI5+riNA9jNabZy84rJi46kmE92oU6FNNE1JkgROQ2EWl7AvteAvQRkR4iEgNcCbxZa50twFnucQbgJIhiYC5wiojEuzesxwC5GGNOiKqSnV/EqN4ptIqy7q0mMIFcQXTC6YE00+22GtCz+apaCdyG82G/Bqe30moRmSYiF7qr3QncKCIrgJeB69SxB3gCJ8ksBz5X1bfr96MZY2qsLz5A4Z7D1rxk6qXObq6qeq+I3IfTs+h7wJ9FZCbwd1VdX8e2s3Gah3zn3e8znQuMOsa2/8Tp6mqMaaDsPKcTh92gNvUR0D0IVVVgp/uqBNoCr4nI4x7GZoxpJPPWFtGvYwJpyXGhDsU0IYHcg/ihiCwFHgcWACer6s3AEOBSj+MzxjTQgaOVLN5YylhrXjL1FMiT1CnAt1V1s+9MVa0WkUnehGWMaSwLCkqoqFIrr2HqLZAmptlAac0bEUkQkeEAqrrGq8CMMY1jXn4RCa2iGNLtRDojmpYskATxNOA7svlBd54xJsypKtl5xZzRJ4XoSCvebOonkL8YcW9SA07TEjaWtTFNQt7O/ewsO2LNS+aEBJIgNrg3qqPd14+ADV4HZoxpuGy3eusYq95qTkAgCeImYCSwDacExnBgqpdBGWMax7y8YgZ2SaRjog2nYuovkAflinDKZBhjmpB9hypYumUPN4/pFepQTBNVZ4JwR3K7HhiIUysJAFX9vodxGWMa6OOCYqqq1cprmBMWSBPTSzj1mM4DPsKpyrrfy6CMMQ03L7+Y5PhoBmVY91ZzYgJJEL1V9T7goKq+AJwPnOxtWMaYhqiuVublFzO6TyqREQHV1zTmGwJJEDVjQe8VkZNwhgbt7llExpgGW729jJIDR615yTRIIM8zPOOOB3EvzngObYD7PI3KGNMg2flFiMDoPpYgzIk7boJwh/8sc8dnmA/0DEpUxpgGyc4v4pT0ZNq3aRXqUEwTdtwmJvep6duCFIsxphGUHixn+da9jLOH40wDBXIP4j0R+amIZIhIu5qX55EZUw/7Dlfw69lr2FhyMNShhNz8tcWoYuU1TIMFcg+i5nmHW33mKdbcZMLE1tJDfO/5JRQUHWBX2RH+cOXgUIcUUtn5RbRvHcPJaUmhDsU0cYE8Sd0jGIEYcyJWbN3L9S/kcLSyipG92vPOqp1MO1RBUnx0qEMLiapq5aO1xZzZvwMR1r3VNFAgT1Jf42++qr7Y+OEYE7h3V+/khzOWkdKmFTOmDudIRTWT/vQJb67YxndP7x7q8EJi+da97D1UYc1LplEE0sQ01Gc6FjgL+BywBGFC5rlPNvLQ27mckpbEs9cOJTWhFarKgM6JzMwpbLEJYl5+ERHWvdU0kjpvUqvq7T6vG4HBQEwgOxeR8SKSLyIFInKXn+VdRSRbRJaJyBciMtHP8gMi8tNAfyDTvFVVKw+8uZppb+VyzoCOzJh6OqkJTldOEeGKrHRWbttH7vayEEcaGvPyixnSrW2LbWIzjetEhpg6BPSpayURiQSmAxOATGCKiGTWWu1eYKaqDsapGPtUreW/B945gRhNM3SovJIfvLSU5xdu4vujevD01UOIi4n82joXDUojJjKCmTlbQxRl6BTtP8LKbfsYa81LppEEcg9iFk6vJXASSiYwM4B9DwMKVHWDu58ZwEVArs86CiS600nAdp/jXowzMJH1WzQU7T/C9c/nsHr7Ph68cCDXjuzud722rWM4d2BH3li+jV9O7E+rqEi/6zVHH+UXA9a91TSeQO5B/NZnuhLYrKqFAWyXBvh+jasZbMjXA8C7InI70Bo4G0BEWgO/AM4Bjtm8JCJTcQcv6tq1awAhmaZo7a79fO8fSyg9WM4z383i7MyOx11/clYGb32xg/dydzHplC5BijL05uUX0zGxFQM6J4Q6FNNMBNLEtAX4TFU/UtUFwG4R6R7Adv762Gmt91OA51U1HZgIvOSW93gQ+L2qHjjeAVT1GVXNUtWs1FS7KdccLSwo4dKnF1JeVc3MH5xeZ3IAOKN3CmnJcbyypOU0M1VUVTN/XTFj+3ZAxLq3msYRSIJ4Faj2eV/lzqtLIZDh8z4dnyYk1/W4zVWquginl1QKzpXG4yKyCbgDuFtErORHC/Pa0kKueW4xnZNief2WkZycHtiDXxERwmVD0vmkoIRtew97HGV4+HzzHvYfqbTqraZRBZIgolS1vOaNOx1IL6YlQB8R6SEiMTg3od+stc4WnG6ziMgAnARRrKrfUtXuqtodeBL4tar+OYBjmmZAVXni3Xx++uoKhvdsx6s3jSS9bXy99nHZkHQAXssJpDW06cvOLyYqQhjVOyXUoZhmJJAEUSwiF9a8EZGLgJK6NlLVSpxCf3OBNTi9lVaLyDSf/d0J3CgiK4CXgetUtXYzlGlBjlZW8ZOZK/jjhwVcPiSdf1w3jKS4+nfZzGgXz6heKby6dCvV1c3/T2pefhFDu7cjIda6t5rGE8hN6puAf4lIzTf4QsDv09W1qepsYHateff7TOcCo+rYxwOBHMs0ffsOVTD1pRw+21jKnef05bYzezeoPf3yrHR+NGM5izbsbtbfrLfvPUzezv3cPbF/qEMxzUwgtZjWAyNEpA0gqmrjUZtGt7X0ENf9YzFbSw/z5BWDuHhwWoP3ed7ATiTGRvHKkq3NOkHMs+6txiN1NjGJyK9FJFlVD6jqfhFpKyIPByM40zIs27KHS55aQMmBcl68flijJAeA2OhILh6cxpzVO9l3qKLuDZqoeflFpCXH0btDm1CHYpqZQO5BTFDVvTVv3NHlJh5nfWMCNmfVDq585lPiYiL57y0jGdGzfaPuf3JWBuWV1fxvxbZG3W+4OFpZxYKCEsb1T7XurabRBZIgIkXky3ELRSQOsHEMTYOoKs9+vIGb//U5Azon8voto+iV2vjfgE9KSyKzc2KzLb2Rs2kPB8urrHnJeCKQBPFP4AMRuV5ErgfeA17wNizTnFVWVfOrN1fz8NtrGD+wEzOmjiDFw7GTrxiawaptZazevs+zY4RKdl4RMVERnN6rca+8jIHAqrk+DjwMDMCpwzQH6OZxXKaZOnjUKbj34qLNTB3dk+nfOY3YaG/rJV00qAsxURG82gyficjOL2JEz/bExwTSIdGY+gm0mutOnKepL8V5sG2NZxGZZquo7AhXPLOI7PwiHrpoIHdPHBCUUc+S42M4b2AnXl+2jSMVVZ4fL1i27D7E+uKDjO1rT08bbxwzQYhIXxG5X0TWAH/GKbwnqjrOnmo29ZW3s4yLpy9gQ/FBnr02K+gD+kzOSmff4Qrezd0V1ON6ad7aIgDG9bf7D8Ybx7uCyMO5WrhAVc9Q1T/h1GEypl4+WVfC5U8vorJamfmD0zmzf90F9xrbqF5OAb9Xm9HN6uy8Irq3j6dHSutQh2KaqeMliEtxmpayReRvInIW/iu0GnNMM5ds5bp/LCatbRxv3DqKk9ICK7jX2CIihMuznAJ+hXsOhSSGxnSkooqF63fb4EDGU8dMEKr6urWdxogAAB7ySURBVKpeAfQH5gE/BjqKyNMicm6Q4jNNlKry27n5/Pw/X3B6r/a8etPpdEmOC2lMXxbwW9r0b1Yv2rCbo5XV1rxkPBVIL6aDqvovVZ2EU7J7OfCN8aWNqXG0soo7XlnOn7MLuHJoBs9dNzQsisilt43njN4pvJpT2OQL+M3LKyI2OoLhPdqFOhTTjNVrTGpVLVXVv6rqmV4FZJq2PQfL+e6zi/nf8u387Lx+PPrtk4mOPJGhz71xeVYG2/YeZuH63aEO5YSpKtn5xYzqleJ5F2HTsoXP/1zT5G3efZBLn17I8q17+eOUwdw6rmHVWL1wbmZHkuKieaUJ36zeWHKQLaWHGGvNS8Zj9nSNaRRLN+/hxhdzqFblnzcMZ1iYNn3ERkdy8aAuvLxkK3sPlZMcH8jYV+El263eas8/GK/ZFYRpsNkrd/Cdv31KQmwU/715ZNgmhxqTh7oF/JbXHgG3aZiXX0SfDm3IaFe/UfaMqS9LEOaEqSrPzF/PLf/6nIFdEvnvzSPp6UHBvcY2sEsSA7s0zQJ+B49W8tmGUuu9ZILCEoQ5IZVV1dz3v1X8enYe55/cmX/fOIL2Hhbca2xXDM1g9fYyVm1rWgX8Fq7fTXlVtTUvmaCwBGHq7eDRSm58MYd/frqFm8b04k9TBje53jQXnZpGTFREk7uKyM4vonVMJFndw7sZzzQPLT5B5O/cz8XTF7B598FQh9IkHCqv5IpnFjF/XQmPXHISd03oH5SCe40tKT6a8QM78UYTKuCnqszLK+KMPinERLX4/7omCDz9KxOR8SKSLyIFIvKNh+tEpKuIZIvIMhH5QkQmuvPPEZGlIrLS/dez5y6S46NZu2s/v55tBWoD8Zd561m1rYy/XD2Eq4Y37arvk7MyKDtSydzVO0MdSkDW7jrA9n1HbHAgEzSeJQgRiQSmAxNwxpGYIiKZtVa7F5ipqoOBK4Gn3PklOEUCTwauBV7yKs6OibHcOq43c1fvYkFBiVeHaRa2lh7ir/M3cOGpXTgnM/gF9xrbyF7tSW8b12TGicjOd6q3Wv0lEyxeXkEMAwpUdYOqlgMzgItqraNAojudBGwHUNVlqlrTB3E1EOs77Glju/6MHmS0i2ParFwqq6q9OkyT99g7eYjAXRP6hzqURhERIVw+JINPCkrYWhr+Bfzm5RcxoHMinZJiQx2KaSG8TBBpOGNI1Ch05/l6ALhaRAqB2cDtfvZzKbBMVY/WXiAiU0UkR0RyiouLTzjQ2OhI7pmYSf6u/by8eMsJ76c5+2zDbt5euYObx/QOedG9xnRZVjoi4V/Ar+xIBTmb9jCun/VeMsHjZYLwd+eydoW0KcDzqpoOTAReEpEvYxKRgcBvgB/4O4CqPqOqWaqalZrasP845w3syOk92/O799ay91B5g/bV3FRVKw/OyiUtOY6po3uGOpxGlZYcxxm9U3htaSFVYVzAb8G6Eiqr1Z5/MEHlZYIoBDJ83qfjNiH5uB6YCaCqi4BYIAVARNKB14FrVHW9h3HiHo/7L8ik7HAFT76/zuvDNSkzc7aSu6OMX07sT1xM0+rOGojJXxbwC997UNn5RSTGRjE4IznUoZgWxMsEsQToIyI9RCQG5yb0m7XW2YIzah0iMgAnQRSLSDLwNvBLVV3gYYxfM6BzIt8Z3pWXPt3Mul37g3XYsLbvcAW/nZvPsO7tOP/kzqEOxxPnDuxIcnw0rywJz2ciaqq3ju6bSlQYVcY1zZ9nf22qWgncBswF1uD0VlotItNE5EJ3tTuBG0VkBfAycJ2qqrtdb+A+EVnuvoJybf2Tc/rROiaSaW/l4oTSsv3pg3WUHirn/gsyw64ya2NpFRXJxYPSeHf1rrBsXly9vYzi/Uete6sJOk+/jqjqbFXtq6q9VPURd979qvqmO52rqqNU9VRVHaSq77rzH1bV1u68mleRl7HWaNc6hh+f05eP15XwwZqgHDJsrS8+wPMLN3FFVkbIhgoNlslZGZRXVfPGsm2hDuUb5rndW0dbeQ0TZHa96sfVI7rRu0MbHn47l6OVTeMpWy888vYa4qIjufPcfqEOxXOZXRI5KS2RV3IKw+7KMTu/mFPSk0hNaDq1rkzzYAnCj+jICO6blMmm3Yd4fsGmUIcTEtn5RXyYV8QPz+rTYj6YrsjKYM2OMlZvLwt1KF/ac7CcZVv22MNxJiQsQRzDmL6pnNW/A3/6sIDi/d94BKNZq6iq5qG3cumR0pprR3YPdThBc6FbwC+cblbPX1dMtWLPP5iQsARxHPecP4CjlVX8dm5+qEMJqhcXbWZD8UHuPX9AiyoKlxQfzYSTOvG/5eFTwG9efjHtWsdwSrp1bzXB13L+95+Anqlt+N6oHsxcupWVhU1r3IATtfvAUZ58fy2j+6ZyZgt8KCucCvhVVysfrS1mTN9UIptgxVzT9FmCqMNtZ/amXXwMD85aHXY3L73wxHtrOVRexf2TBjTbbq3Hc3rP9mS0iwuLcSK+2LaP0oPljLXmJRMiliDqkBgbzc/O60fO5j3M+mJHqMPxVO72Ml5evIVrTu9G7w4JoQ4nJGoK+C0o2B3yAn7ZeUVECIzuYwnChIYliABcnpXBwC6JPDZ7DYfLw6NturGpKtPeWk1SXDR3nNU31OGE1KVDnAJ+r4a4gN+8/CIGd21L29YxIY3DtFyWIAIQGSH86oKBbN93hL/O97wsVEjMWbWTTzeU8pNz+5EUHx3qcEIqLTmOb/VJ5bWcrSEr4Fe8/ygrCvdZ7yUTUpYgAjSsRzsmndKZv3y0nm17D4c6nEZ1pKKKR2avoX+nBKYMzah7gxZgclY62/cd4ZMQDSI1f61Tvt6efzChZAmiHn45cQCqzsA5zcnfP9lI4Z7D3D8p04rBuc7JdAr4hepmdXZ+EakJrRjYJbHulY3xiH0a1ENachw/GNOLWSu2s3hjaajDaRQ79x1henYB4wd2YmTvlFCHEzZqCvi9t3oXew4Gt4BfZVU189cWM7ZvaovsSWbChyWIerppTE86J8Uy7a3VVIfxADOBenxOHpXVyt0TB4Q6lLDzZQG/5cEt4Lds617KjlTa4EAm5CxB1FN8TBR3TejPqm1lYT9MZV0+37KH/y7bxg1n9KBr+/hQhxN2MrskcnJaEq8s2RrUZ2Cy84qIjBDO6GNXdCa0LEGcgAtP7UJWt7Y8PjeP/UcqQh3OCal2hxHtkNCKW8b1DnU4YWvy0Azydu5n1bbgFfCbl19MVre2JMa27N5kJvQsQZyAmuFJSw6U8+cPC0Idzgl5Y/k2Vmzdyy/G96dNq6hQhxO2Ljy1C62iInglZ0tQjrdz3xFyd5RZ85IJC5YgTtAp6clcPiSd5xZsZGPJwVCHUy8Hj1by2Dt5nJqRzCWD00IdTlhLiqsp4Lc9KAX8PlrrDA5ko8eZcGAJogF+Nr4fMZERPPJ2bqhDqZen5hVQtP8ov7ogkwgrAlenyVkZ7D9SyZxV3hfwy84rpktSLH07tvH8WMbUxRJEA3RIiOX2s/rw/pqiLx9sCndbdh/ibx9v5JLBaZzWtW2ow2kSRgSpgF95ZTWfFJQwtn8H695qwoIliAb63qjudGsfz0Nv5VJRVR3qcOr069lriBThF+P7hzqUJiMiQpg8JIOF63ezZbd3BfxyNpdy4GilNS+ZsGEJooFaRUVyz8QBrCs6wL8+3RzqcI5r4foS5qzeya3jetEpKTbU4TQpXxXw8+4qYl5+MTGREYzs1d6zYxhTH54mCBEZLyL5IlIgInf5Wd5VRLJFZJmIfCEiE32W/dLdLl9EzvMyzoY6J7MjZ/RO4Yn31lIa5KduA1VZVc20Wbmkt43jhm/1DHU4TU6X5DhG90nltaWFnhXwy84rYliPdrS2XmUmTHiWIEQkEpgOTAAygSkikllrtXuBmao6GLgSeMrdNtN9PxAYDzzl7i8siQj3TcrkYHkVv39vbajD8WvGkq3k7dzPPRMHEBsdtqcyrE3OymDHviN8vK7x7zdtLT3EuqIDNjiQCSteXkEMAwpUdYOqlgMzgItqraNATTWyJGC7O30RMENVj6rqRqDA3V/Y6tcpgauHd+Vfn20mb2fwHqoKxL5DFfzu3XxG9GzH+JM6hTqcJuvszA60jY/m1ZzGf4J+ntvJwZ5/MOHEywSRBvg22Ba683w9AFwtIoXAbOD2emyLiEwVkRwRySkuDn0voh+f05fEuGimzcoNq+FJn/xgLfsOV3D/pIHWO6YBWkVFcvHgNN7N3dnoTYnz8oro2i6enimtG3W/xjSElwnC3ydR7U/NKcDzqpoOTAReEpGIALdFVZ9R1SxVzUpNDf2leXJ8DD8+uy8L1+/m3dxdoQ4HgIKi/by0aDNXDutKppWObrArhmZQUaW8sazxCvgdqahi4frdjOtn1VtNePEyQRQCvqPPpPNVE1KN64GZAKq6CIgFUgLcNixdNbwrfTu24ZG31wTlydvjcYYRXUNcTCR3ntOyhxFtLP07JXJKehIzcxqvgN/ijaUcrqhirDUvmTDjZYJYAvQRkR4iEoNz0/nNWutsAc4CEJEBOAmi2F3vShFpJSI9gD7AYg9jbTRRkRHcP2kgW0oP8dyCjSGNJTvfeYDvjrP70r5Nq5DG0pxMznIK+K3ctq9R9pedX0SrqAhO72ndW0148SxBqGolcBswF1iD01tptYhME5EL3dXuBG4UkRXAy8B16liNc2WRC8wBblXV0H4dr4cz+qRwTmZH/vxhAUVlR0ISQ3llNQ+9tYZeqa255vRuIYmhubqgpoDfksZ5JmJefjEje7W33mUm7Hj6HISqzlbVvqraS1Ufcefdr6pvutO5qjpKVU9V1UGq+q7Pto+42/VT1Xe8jNML90wcQGWV8vjc/JAc/4WFm9hYcpB7J2USbcOINqqkuGgmntyZN5dv53B5w763bCw5yMaSg9Z7yYQl++TwSPeU1nzvjO68trSQFVv3BvXYJQeO8scP1jGuX6qVbfDI5Vnp7D9ayZzVOxq0n3n5TvXWsX3t92TCjyUID902rjcpbVrxwKzVQe32+rt38zlcUcW9k2o/l2gay4ge7enaLr7BzUzZ+cX0Sm1tI/qZsGQJwkMJsdH8fHw/lm3Zy/+WB6cT1qpt+5ixZCvXjexOr1QrGe2ViAhhclY6n24oZfPuExsP5FB5JZ9u2M1Yu8ozYcoShMcuOy2dk9OSePSdNRw8WunpsVSVabNyaRcfw+1n9fH0WMYp4BchnPCT1YvW76a8stqaAU3YsgThsYgI4YELM9lVdpS/fLTe02O9vXIHizeVcue5/UiKs/GMvdY5KY7RfU+8gF92fhHxMZEM7WHjcpjwZAkiCIZ0a8eFp3bhmfkb2FrqzXgCRyqqeHR2HgM6J3LF0Iy6NzCNYnJWBjvLjjC/ngX8VJV5+cWM6p1Cqyjr3mrCkyWIILlrQn9E4LF38jzZ/zPzN7Bt72F+dUEmkTaMaNCcPaAj7VrH8Go9R5tbX3yAwj2HrXnJhDVLEEHSJTmOm8f05u2VO/h0w+5G3ff2vYd5al4B55/cmRH2NG5QxURFcPGgNN7L3cXuA0cD3i47z7nisPLeJpxZggiiqaN7kpYcx4Ozcht10JnfzMlD1blKMcH3ZQG/evRUy84von+nBLokx3kYmTENYwkiiOJiIvnlxP6s2VHWaGUacjaV8r/l25k6uicZ7awvfSj065TAqelJzFwSWAG//UcqWLKp1Lq3mrBnCSLIzj+5M8O6t+N37+az73BFg/ZVXa08OCuXTomx3Dy2VyNFaE7E5KEZ5O/az4rCugv4LSjYTUWVMs6al0yYswQRZCLC/RdkUnqonD99sK5B+/rP54Ws3LaPuyb0Jz7GxjEOpQtO7UJsdAQzA7hZPS+/iITYKE7rZt1bTXizBBECJ6UlcUVWBs8v3MT64gMntI/9Ryr4zZx8TuuazEWDujRyhKa+EmOjmXhSZ2bVUcBPVcnOL2J0n1QromjCnv2Fhsid5/YjLjqSh9/KPaHtp2evp+TAUX51gQ0jGi4uz8pg/9FK3ll17AJ+a3bsZ1fZUcZY85JpAixBhEhqQit+eFYfsvOLyc4rqte2m0oO8twnG7n0tHROzUj2KEJTXyN6tqNb++MX8Mv+snqrJQgT/ixBhNC1I7vTI6U1D72dS0VVdcDbPTJ7DdGRwi/G9/MwOlNfIsLkrAw+21jKphL/Bfzm5RdxUloiHRJjgxydMfVnCSKEYqIiuPf8AWwoPsiLizYHtM0n60p4L3cXt57Z2z5kwtClp7kF/JZ+8ypi36EKPt+y156eNk2GJYgQO7N/B0b3TeXJ99fW+SRuZVU1095aTdd28Xx/VI8gRWjqo1NSLGOOUcDv44JiqqrVnn8wTYYliBATEe6fNIBD5VX87r21x13334u3sHbXAe45f4CNXxzGJmdlsKvsKPPXfr2AX3ZeMcnx0Qyy+0amibAEEQZ6d0jgmtO78fLiLaze7v9Bqz0Hy/ndu2sZ1bs952Z2DHKEpj7Ocgv4+T4TUV2tfLS2iDF9U62YomkyPE0QIjJeRPJFpEBE7vKz/Pcistx9rRWRvT7LHheR1SKyRkT+KM28L+cdZ/UlOS6aabNy/ZZrePL9tew/UsF9kzKtW2uYi4mK4JLBaby/5qsCfqu276PkQLndfzBNimcJQkQigenABCATmCIiXxskWVV/rKqDVHUQ8Cfgv+62I4FRwCnAScBQYIxXsYaDpPhofnJuPz7bWMqcVTu/tmztrv3887MtXDW8G/07JYYoQlMfk7OcAn6vL9sGOM1LIjDaureaJsTLK4hhQIGqblDVcmAGcNFx1p8CvOxOKxALxACtgGhgl4exhoUpQzPo3ymBR2av4UiF8zSuqvLQW7m0aRXFT87pG+IITaD6dUrg1IxkXnEL+GXnFzEoI5l2rWNCHZoxAfMyQaQBvn39Ct153yAi3YAewIcAqroIyAZ2uK+5qrrGw1jDQlRkBPdPyqRwz2Ge/XgDAO+vKeLjdSX8+Ow+tLUPlybliqwM1hUd4MO8IlYUWvdW0/R4mSD8NZQfqxbylcBrqloFICK9gQFAOk5SOVNERn/jACJTRSRHRHKKi+s35GO4Gtk7hfEDOzE9ez1bdh/i4bdz6dOhDVeN6Bbq0Ew9TTq1M7HREdz9+kpUbXAg0/R4mSAKAd/BkdOBY42ociVfNS8BXAJ8qqoHVPUA8A4wovZGqvqMqmapalZqavP5z3f3xAFUVSuX/mUhm3cf4r5JmVbYrQlKjI1m4smd2VV2lJQ2MZzUJSnUIRlTL15+6iwB+ohIDxGJwUkCb9ZeSUT6AW2BRT6ztwBjRCRKRKJxblA3+yamGl3bx3PDt3pQvP8oZw/oYDc2m7DJWc53pDF9OxBh3VtNE+PZIAKqWikitwFzgUjgOVVdLSLTgBxVrUkWU4AZ+vW+na8BZwIrcZql5qjqLK9iDUe3juuNCFw13JqWmrLhPdrxwzN7M/GUzqEOxZh6k0CGSGwKsrKyNCcnJ9RhGGNMkyIiS1U1y98ya9g2xhjjlyUIY4wxflmCMMYY45clCGOMMX5ZgjDGGOOXJQhjjDF+WYIwxhjjlyUIY4wxfjWbB+VEpBjY3IBdpAAljRROY7K46sfiqh+Lq36aY1zdVNVvPZ9mkyAaSkRyjvU0YShZXPVjcdWPxVU/LS0ua2IyxhjjlyUIY4wxflmC+MozoQ7gGCyu+rG46sfiqp8WFZfdgzDGGOOXXUEYY4zxyxKEMcYYv1pUghCR8SKSLyIFInKXn+U/EZFcEflCRD4QkaAM5xZAXDeJyEoRWS4in4hIZjjE5bPeZSKiIhKU7n8BnK/rRKTYPV/LReSGcIjLXWey+ze2WkT+HQ5xicjvfc7VWhHZG4y4Aoytq4hki8gy9//lxDCJq5v7GfGFiMwTkfQgxPSciBSJyKpjLBcR+aMb8xciclqDD6qqLeKFM+zpeqAnEAOsADJrrTMOiHenbwZeCZO4En2mL8QZgjXkcbnrJQDzgU+BrHCIC7gO+HMY/n31AZYBbd33HcIhrlrr344zPHC4nLNngJvd6UxgU5jE9SpwrTt9JvBSEOIaDZwGrDrG8onAO4AAI4DPGnrMlnQFMQwoUNUNqloOzAAu8l1BVbNV9ZD79lPA828FAcZV5vO2Nc443SGPy/UQ8DhwJAgx1SeuYAskrhuB6aq6B0BVi8IkLl9TgJeDEBcEFpsCie50ErA9TOLKBD5wp7P9LG90qjofKD3OKhcBL6rjUyBZRBo0GHpLShBpwFaf94XuvGO5Hicbey2guETkVhFZj/Nh/MNwiEtEBgMZqvpWEOIJOC7Xpe5l9msikhEmcfUF+orIAhH5VETGh0lcgNNsAvQAPgxCXBBYbA8AV4tIITAb5wonHOJaAVzqTl8CJIhI+yDEdjz1/YyrU0tKEOJnnt9v4iJyNZAF/J+nEbmH8zPvG3Gp6nRV7QX8ArjX86jqiEtEIoDfA3cGIRZfgZyvWUB3VT0FeB94wfOoAosrCqeZaSzON/VnRSQ5DOKqcSXwmqpWeRiPr0BimwI8r6rpOE0oL7l/e6GO66fAGBFZBowBtgGVHsdVl/r8rgPSkhJEIeD7TTIdP5erInI2cA9woaoeDZe4fMwALvY0IkddcSUAJwHzRGQTTpvnm0G4UV3n+VLV3T6/u78BQzyOKaC43HX+p6oVqroRyMdJGKGOq8aVBK95CQKL7XpgJoCqLgJicQrThTQuVd2uqt9W1cE4nxeo6j6P46pLfT9L6ub1jZVweeF8e9uAcwldc+NpYK11BuPcnOoTZnH18Zm+AMgJh7hqrT+P4NykDuR8dfaZvgT4NEziGg+84E6n4DQHtA91XO56/YBNuA/PBuMV4Dl7B7jOnR6A84HnaYwBxpUCRLjTjwDTgnTOunPsm9Tn8/Wb1IsbfLxg/TGEwwvnEnWtmwTucedNw7laAKc5Yhew3H29GSZx/QFY7caUfbwP6mDGVWvdoCSIAM/Xo+75WuGer/5hEpcATwC5wErgynCIy33/APBYMOKp5znLBBa4v8vlwLlhEtdlwDp3nWeBVkGI6WVgB1CBc7VwPXATcJPP39d0N+aVjfH/0UptGGOM8asl3YMwxhhTD5YgjDHG+GUJwhhjjF+WIIwxxvhlCcIYY4xfliBMWBKRKre66CoReVVE4kMUxx3+ji0ir7vxFYjIPp9qqCPrse9bReSqOtYZLiK/P5HY/exrgIh85Ma5RkSebuxjmObFurmasCQiB1S1jTv9L2Cpqj4R4LaR2kjlItynxLNUteQYy8cCP1XVScdYHqWqoS7BAICIfAA8oapvi4gAJ6nqylDHZcKXXUGYpuBjoDc4dbJEZLH7LfivIhLpzj8gItNE5DPgdBEZKiILRWSFu36CiESKyP+JyBK3kN8P3G3HujX9XxORPBH5l1tb/4dAFyBbRLIDDVZECkXkPhFZAFwizngeS9xYXhWROHe9h0XkDnf6ExF5zI01v+ZKRETOFpE3fNb/u3sVsEFEbvU55oNu7O+JyCs1+62lM84DVqhjpZ9jzPW5GioTkatEJEpEnnBj+0KCNL6GCT1LECasiUgUMAFYKSIDgCuAUao6CKgCappoWuOUIBgOLAZeAX6kqqcCZwOHcZ483aeqQ4GhwI0i0sPdfjBwB86Tuz3dY/wRp7TDOFUdV8/QD6rqKFV9FXhVVYe6sazHGa/C74+rqsOAnwH3H2OdvsA5OKUUprlJbwQwCTgVp8Lo0GNs+wQwX0Rmu01nSbVXUNXz3HM7FdiIU/hwKlDkxjYUuFVEutZ1AkzTFxXqAIw5hjgRWe5Ofwz8HeeDagiwxGkhIQ6oGVOhCviPO90P2KGqS+Cr8TRE5FzgFBG5zF0vCadYXjlO3ZpCd73lODVvPmlA/K/4TJ8iItOAZJwih8cqj/5f99+l7vH9eUudMQqKRKQUSAXOAN5Qp0DhURHxu39VfVZE3gHOw6lRNVVEBtVeT0Q64FTAvVRVy9zzNkBErnRXqTlvW44Ro2kmLEGYcHXY/Sb7Jbfd/AVV/aWf9Y/43HcQ/Jc5FuB2VZ1ba79jAd/KvVU0/P/GQZ/pF4EJqrrKbZ4ZcYxtamI43vH9xemvzLNfqroNeA54TkTycArgfcm9YnsFuE9Vc2tmA7eo6geYFsWamExT8gFwmfsNFxFpJ/7HDc8DuojIUHe9BPeDby5ws4hEu/P7ikjrOo65H+dbf0O0Bna6x/1OA/flzyfAhSLSSkQScArNfYM44yxHudNdgLZ8sxz0/wFLVPU1n3lzgVt8tu1Xcx/FNG92BWGaDFXNFZF7gXfFGTSmArgV2FxrvXIRuQL4k/tBdhjnPsSzOE03n7tXI8XUPbbGM8A7IrLjBO5D1Lgf577IFmAVzpgGjUZVF4nIHOALnJLdSwB/YxNMAP4gIkdwrrDuUNVit7kO94b/HcAqt1kJ4G7gr0BXYLm7bhHhMcyr8Zh1czWmGRCRNqp6wL0i+gS4VlW/CHVcpmmzKwhjmoe/i0g/nKuT5yw5mMZgVxDGGGP8spvUxhhj/LIEYYwxxi9LEMYYY/yyBGGMMcYvSxDGGGP8+n/NIbUxV00E1QAAAABJRU5ErkJggg==
"
>
</div>

</div>

</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
